= Abstraction Layered Architecture
:doctype: article
:encoding: utf-8
:lang: en
:toc: left
:sectnums:
:imagesdir: images
:source-highlighter: highlightjs
:highlightjs-theme: Docco

[.float-group]
--
image::BOSS_Great_Wall.jpg[BOSS_Great_Wall.jpg,600, title="In conventional code, we lose our view of the large scale structure", float="right"]

*Engineering the large scale structure of code*
--

// blame J R Spray

John R Spray

Last update: 2020-11-04


*The real quick summary*


Fundamentally, ALA is two architectural constraints when writing software:

--
- The only relationship allowed is a dependency on an abstraction. That abstraction must be significantly more abstract than the abstraction containing the dependency. No other relationships are allowed or needed.

- All abstractions must be small - e.g. 100-500 LOC (or diagram nodes).
--


*The quick summary*


. Chapter 1, "What problem does ALA solve?"

** These two constraints solve the "big ball of mud" problem by providing a pre-worked reference architecture (a meta-structure for code at the largest granularity scale). 

** It pre-solves for the following quality attributes: Complexity, Readability, Maintainability, Testability




. Chapter 2, "What does the structure look like?". Without explaining why, describes the code structure that emerges after applying the two constraints:

** An abstraction is usually a function or class, but can be a small group of functions, classes, delegates, enums, even variables or objects. The group is highly cohesive code that is unrestricted in its internal relationships. An abstraction is usually represented by a source file.

** A small number of discrete abstraction layers emerge. The layers are given the standard names: Application, Domain abstractions, Programming Paradigms, and Libraries. Folders are used for these layers. Dependencies only go down the layers, not across.

** A common pattern that emerges is to explicitly wire together instances of abstractions that will communicate with each other at run-time through even more abstract 'abstract interfaces'.

** The emergent use of ports and how to give classes ports using plain code.

** The emergent use of diagrams to wire instances of abstractions in the top layer using a dependency injection operator, WireTo(). Code is auto-generated from the diagram like: "new A().WireTo(new B());"

** The use of programming paradigms when composing instances of abstractions. Programming paradigms are often implemented with simple, quite abstract interfaces such as "interface IEvent { void Execute(); }".

** Multiple programming paradigms are used in an application. e.g. interfaces for user interface layout, events, data flows, activity flows, state machines, data schemas, and others.

** An emergent property is the direct representation of requirements, like a DSL, which is then directly executable.

** If the Application becomes large, we add a layer called StoryAbstrations, which proovides abstractions to support separate diagrams, plugin style in the Application layer.

** The ALA composition structure is analogous to real world composition structures such as Lego, electronic schematics, molecules. 




. Chapter 3, "Why the structure works". Explains the theory behind the two fundamental architectural constraints:

** Define what we mean by abstraction: A general concept. Abstractions are learnable, stable and reusable. Dependencies are always on stable concepts.

** The constraint that "dependencies are only allowed only on abstractions" results in zero coupling. The code inside all abstractions in the system is zero couples with one another. (So ALA achieves "Zero coupling and high cohesion", not "loose coupling and high cohesion.)

** Zero coupling together with limited abstraction size eliminates complexity.

** Conventional code typically contains both good and bad dependencies. ALA simply eliminates all the bad dependencies.

** Conventional architectural design uses a decomposition method. Decomposition tends to result in coupling. ALA uses a composition method. The set of artefacts being composed with start out with zero coupling.

** Requirements typically inherently contain a graph structure. These graphs should be explicitly represented inside their own abstraction, preferably using a diagram.





. Chapter 4, "Execution models". Explains how the underlying execution for each programming paradigm can be made to actually work.

** Explains the ways that the CPU executes the right code at the right time when the structures that emerge from ALA compose abstraction in an orthogonal way to imperative execution flow.

** UI layout

** UI Navigation

** Dataflow

** Event driven

** Real world time activity flow

** Data schema





. Chapter 5, "Methodology". Describes ALA in terms of where it fits into Agile software development

** The primary methodology is that requirements are simply 'described' in terms of 'invented' domain abstractions.

** An "Iteration zero" is used, important to get a starting set of domain abstractions and programming paradigms. The starting set will set the pattern of the whole design.

** How to go about 'inventing' domain abstraction for the first time in a new domain.




. Chapter 6, "The philosophy behind ALA". Gives the theory of why ALA works from the perspective of complex systems and how our brains work.

** Describes how the two fundamental architectural constraints are designed to mimic how our brains see the real world.

** Composition of a small number of abstractions layers in the real world as an analogy: e.g. atoms, molecules, proteins, cells, bodies.

** ALA leverages how our brains have evolved to use abstractions to understand the real world. This enables us to understand our programs in the same way.

** ALA achieves an optimal level of expressiveness in each layer. This includes the application layer which is just a formal expression of requirements in their details, but nothing else. 

** ALA uses layers instead of encapsulation hierarchies. We want public abstractions for maximal reuse, not private specialized parts for a specialized use.

** ALA does not use 'models' for its structure or architecture. Models, as the term implies, can leave out details arbitrarily. These details are unknowns and will come back to bite us. ALA only leaves out details by putting them inside arstractions, which renders them harmless. (Models differ from diagrams, which ALA can use.)

** An ALA application (top layer) is three things in one: The architecture, the architecture documentation, and the executable.




. Chapter 7, "ALA compared with...". 

** Unsurprisingly, the two fundamental constraints of ALA emerge many of the same architectural styles and patterns we find in software engineering. 

** It usually modifies them.

** Examples: Layers, Dependency injection, Observer pattern, DSLs, Components and connectors.

** It also leaves some significant ones out. For example, MVC. ALA says that UML class diagrams are evil.

** Lists the common large-structure styles and patterns so you can choose the one you are most familiar with to see how ALA encompasses it, usually in a modified way, or contrasts with it. 






Each chapter ends with an example project or two. These projects show the architecture in real code. Unlike most pedagogical sized examples, these examples are progressively non-trivial. Yet because of ALA's power, they remain uncomplicated and easy to understand.      

This web site is a work in progress.

I would like to acknowledge the help of Roopak Sinha at AUT (Auckland University of Technology) in the writing of the paper for ECSA 2018 and  his academic perspective. 

// for web site

link:Abstraction_Layered_Architecture_Paper_ECSA_2018.pdf[ALA Paper presented at ECSA 2018]

// for pdf

// https://AbstractionLayeredArchitecture.com/Abstraction_Layered_Architecture_Paper_ECSA_2018.pdf[ALA Paper presented at ECSA 2018]


== Chapter one - What problem does it solve?



=== The Big Ball of Mud

ALA is an in-the-large strategy to organise code. It provides the constraints needed for the code structure to never degenerate into sphagetti code, or what Brian Foote and Joseph Yoder describe as a "big ball of mud". As the software  life cycle continues, retaining the organisation becomes easier rather than harder. This is because of increasing reuse of software artefacts within the organisation.



=== Existing architectural patterns

There are many existing architectural styles, patterns, or principles: loose coupling and high cohesion, information hiding, layers, decomposition, DSLs, components, aspects, models, event-driven, MVC, composite, inversion of control, functional programming, object oriented design, UML Class diagrams are all examples.

This set is sufficient, but there is no overarching strategy that tells you how to combine tham all in a coherent way. in most cases they are used in an ad-hoc manner that doesn't work. In some cases their use is actually harmful. ALA provides a large scale organisational framework into which all of these fit.

=== An optimal reference architecture

ALA is a reference architecture. It is independent of any specific domain, so it is a general reference architecture. The reference architecture is 'optimal' for certain non-functional requirements. By optimal, I mean that it makes these qualities as good as they can be.

** Complexity
** Readability
** Maintainability
** Testability

If other non-functional requirements are also important, ALA provides a good starting point. Even if the ALA structure must be compromised for other qualities, it is still better to start with these quality attributes optimised and deviate from them as necessary. As it happens, the maintainability resulting from ALA frequently makes other quality attributes easy to achieve as well. For example, in an ALA application it is often easy to make performance optimizations in the execution model that don't affect the application code. Or, you can port an application without changing the application code.  


==== Readability 


[.float-group]
-- 
image::close_up_code.jpg[close_up_code.jpg,400, title="Code quickly becomes a big ball of mud", float="right"]

ALA code is readable, not because of style, convention, comments or documentation, but because any one piece of code appears to you as a separate uncoupled little program. 
--



==== Complexity

There is a meme in the software industry that says that the complexity of software must be some function of its size. This need not be so. With proper use of abstraction it is possible to have complexity that is constant regardless of program size. ALA makes use of this.

anchor:ComplexityGraph1[]

[chart,line,file="complexity_curve.png", opt="title=Complexity,x-label=KLOC,legend=right"]
--
//Big ball of mud
1,	10
2,	20
5,	50
10,	100
20,	200
50,	500

//Loosely coupled
1,	10
2,	14
5,	22
10,	32
20,	45
50,	71
100,100
200,141
500,224
1000,316

//ALA
1,	10
2,	11
5,	12
10,	13
20,	13
50,	15
100,16
200,17
500,19
1000,20

//Code writer's brain limit
1,	100
2,	100
5,	100
10,	100
20,	100
50,	100
100,100
200,100
500,100
1000,100

//Code reader's brain limit
1,	50
2,	50
5,	50
10,	50
20,	50
50,	50
100,50
200,50
500,50
1000,50
--

This is a qualitative graph comparing the complexity of an ALA application with that of a big ball of mud and an average loosely coupled application. This is further explained later <<ComplexityGraph2,here>>.


==== Maintainability

The maintainability effort over time should qualitatively follow the green curve in the graph below because as software artefacts are written, their reuse should reduce the effort required for other user stories. Product owners seem to have an innate sense that we manage to organise our code such that this happens. That is why they get so frustrated when things seem to take longer and longer over time, and they often ask us "haven't we done this before". In practice, too often we follow the red curve. Maintenance eventually gets so difficult that we want to throw it away and start again. We reason we can do better. My experience is that we don't do better when we rewrite. We just create another mess. It is just a psychological bias on the part of the developer caused by a combination of a) the Dunning Kruger effect and b) the fact that it is easier to read our own recently written code than someone else's.

If we apply all the well known styles and principles, the best we seem to be able to manage is the orange curve, which still has maintenance effort continuously increasing with an exponential factor.

However, whenever we have done an experimental re-write using ALA, it comes out spectacularly better.



[chart,line,file="effort_curve.png", opt="title=Effort per user-story,x-label=months"]
--
//Big ball of mud
1,	5
2,	5
3,	6
4,	6
5,	7
6,	8
7,	9
8,	10
9,	12
10,	13
11,	15
12,	17
13,	19
14,	21
15,	24
16,	28
17,	32
18,	37
19,	43

//Cocomo
1,	16
2,	17
3,	17
4,	18
5,	18
6,	19
7,	19
8,	19
9,	19
10,	20
11,	20
12,	20
13,	20
14,	20
15,	20
16,	20
17,	21
18,	21
19,	21
20,	21
21,	21
22,	21
23,	21
24,	21

//ALA
1,	30
2,	21
3,	17
4,	15
5,	13
6,	11
7,	10
8,	9
9,	8
10,	8
11,	7
12,	7
13,	6
14,	6
15,	5
16,	5
17,	4
18,	4
19,	3
20,	3
21,	3
22,	2
23,	2
24,	2
--

ALA is based on the theoretical architectural constraints needed to follow the green curve. 


==== Testability


=== Domain oriented

As has been found useful in other methodologies such as Domain Specific Languages, Domain Driven Design, Model Driven Software Development and Language Oriented Programming, ALA provides a way to be 'domain oriented'. 

But unlike most of the other domain oriented methodologies, ALA provides a way to be domain oriented with ordinary code, and with the same development environment. It is just a way to organise ordinary code to be domain oriented.

=== The software engineer's trap

Typical bright young engineers come out of university knowing C++ or Java (or other C*, low-level, imperative, language that mimics the silicon), and are confident that, because the language is Turing-complete, if they string together enough statements, they can accomplish anything. At first they can. Agile methods only require them to deliver an increment of functionality. There hardly seems a need for a software architect to be involved. And besides, we are told that any design can emerge through incremental refactoring.

image::Cynefin.jpg[Cynefin.jpg,, title="Code can quickly get complex", float="left"]

As the program gets larger, things are getting a little more complicated, but the young developer's brain is still up to the task, not realizing he has already surpassed anyone else's ability to read the code. He is still able to get more and more features working. One day the code suddenly 'transitions'. It transitions from the complicated quadrant into the complex quadrant. And now it is trapped there. It is too complex for the in-the-large refactoring that would be required to make it transition back. This pattern happens over and over again in almost all software.

The incremental effort to maintain starts to eat away and eventually exceed the incremental increase in value. This now negative return causes the codebase itself to eventually lose value, until it is no longer an asset to the business. 

When a new bright young engineer who knows C* arrives, he looks at the legacy codebase and is convinced that he can do better. And the cycle repeats. This is the CRAP cycle (Create, Repair, Abandon, rePlace). ALA is the only method I know that can prevent the CRAP cycle.

=== A short history of ALA

From early on in my career, I experienced the CRAP cycle many times. Each time I wanted to find a way to not fall into it. I would research and use all the architectural styles and principles I could find. I would come across things like 'loose coupling', and I remember asking myself, yes but how does one accomplish that?, and still fail.

I started searching for a pre-worked, generally applicable, 'template architecture' that would tell me what the organisation of the code should look like for any program. I searched for such a thing many times and never found one. Some would say that this is because the highest level structure depends on project specific requirements.

Forty years worth of mistakes later, I finally have that template meta structure that all programs should have. The turning point was when I noticed two (accidental) successes in parts of two projects. These successes were only noticed years later, 15 years in one case and 5 years in the other. They had each undergone considerable maintenance during that time. But their simplicity had never degraded and their maintenance had always been straightforward. It was like being at a rubbish dump and noticing two pieces of metal that had never rusted. "That's weird", you think to yourself. "What is going on here?"

One of them had the same functionality as another piece of software that I had written years earlier. That software was the worst I had ever written. It was truly a big ball of mud, and maintenance had become completely impossible, causing the whole product to be abandoned. So it wasn't what the software did that made the difference between good and bad. It was how it was done.

Analysing the common properties of those two code bases, gave clues that eventually resulted in a theoretical understanding of how to deal with complex systems. This meta-structure is what I now call Abstraction Layered Architecture.

Subsequently, I ran some experiments to see if the maintainability and non-complexity could be predictably reproduced. These experiments, which have worked spectacularly well so far, are discussed as a project at the end of every chapter.


=== Simplify the overwhelming software architecture styles, patterns & principles

Currently the problem of structuring software code to meet quality attributes involves mastering an overwhelming number of software engineering topics. Here are just a few examples:  

* Understandability, Readability, Maintainability, Modifiability, Testability, Extensibility, Dependability, Performance, Availability, Scalability, Portability, Security, Usability, Fault-tolerance
* Views, Styles, Patterns, Tactics, Models, UML, ADL's, ADD, SAAM, ATAM, 4+1, Decomposition
* CBD/CBSE, C&C, Pipes & Filters, n-tier, Client/Server, Plug-in, Microservices, Monolithic, Contracts, Message Bus
* Modules, Components, Layers, Classes, Objects, Abstraction, Granularity 
* Information hiding, Separation of Concerns, Loose Coupling & High Cohesion 
* Semantic coupling, Syntax coupling, Temporal coupling, existence coupling, Dependencies, Interactions, Collaboration
* Interfaces, Polymorphism, Encapsulation, Contracts, Interface Intent
* Execution models, Event-Driven, Multithreaded, Mainloop, Data-driven, Concurrency, Reactor pattern, Race condition, Deadlock, Priority Inversion, Reactive 
* Principles: SRP, OCP, LSP, ISP, DIP; MVC, MVP, etc 
* Design Patterns: Layers, Whole-Part, Observer, Strategy, Factory method, Wrapper, Composite, Decorator, Dependency Injection, Callbacks, Chain of Responsibility, etc
* Expressiveness, Fluency, DDD, Coding guidelines, Comments
* Programming Paradigms, Imperative, Declarative, OO, Activity-flow, Work-flow, Data-flow, Function blocks, Synchronous, State machine, GUI layout, Navigation-flow, Data Schema, Functional, Immutable objects, FRP, RX, Monads, AOP, Polyglot-Programming Paradigms
* Messaging: Push, Pull, Synchronous, Asynchronous, Shared memory, Signals & Slots
* Memory management, Heap, Persistence, Databases, ORMs
* Up-front design, Agile, Use cases, User stories, TDD, BDD, MDSD

Mastering all these topics takes time. Even if you can, juggling them all and being able to use the right ones at the right time is extremely taxing on any developer. Add to that the mastering of technologies and tools, keeping to agile sprint deadlines, and commitment to your team and management, it is an almost impossible task. 'Working code' tends to be what the team is judged on, especially by project managers or product owners who have no direct interest in architecture or even the Definition of Done. They don't want to know about the rather negative sounding term, "technical debt".

ALA works by pre-solving most of these software engineering topics into a single 'meta-style'. This meta-style provides a simple set of architectural constraints. 

Being a pre-worked recipe of the aforementioned list of styles and patterns, ALA contains no truly novel ideas. Some ingredients are accentuated in importance more than you might expect (such as abstraction). Some are relatively neutral. Some are purposefully left out. The biggest surprise for me during the conception process of ALA was that some well-established software engineering memes seemed to be in conflict. Eventually I concluded that they were in-fact plain wrong. We will discuss these in detail one at a time in subsequent chapters. But to wet your appetite here is one meme that ALA definitely banishes to furtherest of evil kingdoms: the UML class diagram. Read on to find out why.

Like any good recipe, the ingredients work together to form a whole that is greater than the sum of parts. The resulting code quality is significantly ahead of what the individual memes do by themselves. It continues to surprise me just how effective, and enjoyable, it is. 


== Chapter two - What does the structure look like?

In this section we describe the anatomy of the ALA structure without trying to explain too much about why it looks that way. That will be covered in Chapter three.

We describe it from several different perspectives. We all have different experiences or different prior knowledge on which we learn new ideas through comparison. So we will each have a different light that comes on. This chapter has about 10 different perspectives, some concrete, some high level, some analogies, and finally some in code. Don't give up if most of them make no sense. Just use the best explains the insight for you. 

=== ALA uses just one relationship type

ALA has a core fundamental premise from which everything else is derived. That premise is to use a single type of relationship:


[plantuml,file="diagram-05a.png"]
----
@startdot
digraph foo {
// size="3!"
subgraph cluster_1
{
label="Abstraction A"
labeljust=l
labelloc=b
style=rounded 
A [ style = invis ];
}
B [label="Abstraction B"; shape = rect; style=rounded ]
A -> B  [dir="both", arrowhead="open", arrowtail="tee", color=green, label=" requires knowledge of to understand"]
}
@enddot
----

That relationship is "requires knowledge of to understand".

B must be more abstract than A. "More abstract" means more general, not specific to A, have a greater scope of reuse than A. (For now just think of abstractions as synonymous with either classes or functions in conventional programming.)

The relationship means that, to read and understand the code inside A, you must know the abstraction B - not how the insides of abstraction B work, just what B does, the concept. The word "abstraction" implies that it should be learnable in a short time.

An example: A is an abstraction that calculates standard deviation. B is an abstraction that calculates squareroot. The code in A "requires knowledge of the [squareroot concept] to understand".

This "requires knowledge of to understand" relationship applies at design-time. So you can never use a relationship for run-time dependencies. And you can never break a module up into pieces arbitrarily, only pull out abstractions. From now on we will call this type of relationship a "knowledge dependency".

Notice how in the diagram the relationship arrow comes from inside A. It is only the code inside A that requires knowledge of the abstraction. 

Architectures generally work by applying constraints. ALA's constraint is that you have this one type of relationship. This fundamental constraint emerges all of ALA's properties and patterns that we will explain in the rest of this chapter. A few of these these are:

. When data or events need to move from one part of a program to another, you can't use a relationship to do it. Abstractions don't know where their data comes from, nor where it goes. This implies using a concept of ports.

. Because the target of a knowledge dependency must be more abstract, abstractions arrange themselves into layers. This is what gives the architecture its name: Abstraction Layered Architecture. Because these dependencies have nothing to do with run-time dependencies, these layers are very different from the ones you might find in a conventional program that uses a layering pattern. Abstraction basically means reusable. As you go down the layers, abstraction increases and so does scope of reuse. 

. Because the target abstraction must be clearly more abstract, the abstraction layers form themselves into discrete levels. Only a small number of abstraction levels are needed. ALA generally uses four levels. The layers are given standard names that describe their level of abstraction, e.g. The Domain Abstractions layer.

. ALA has zero coupling between the code inside all abstractions. Unfortunately there is a meme in the software engineering industry that there must be some coupling between software 'modules' if the system is to do anything. We hear of "loose coupling" as being the target ideal. This is completely incorrect. ALA uses zero coupling. In our A & B example above, the code inside B knows nothing of A. The code inside A, while it knows about the concept of abstraction B, knows nothing about the code inside B. So we already know how to do zero-coupling. ALA just constrains us to do this all the time.

. Relationships are always represented simply by using the name of the abstraction (the same as you would use the name Sqrt). You would never use a line on a diagram to a box representing squareroot. And so it is that in ALA you never use a line or arrow in a diagram to use an abstraction (as we did with A and B above). This has the surprising consequence that a UML class diagram of an ALA program would have no lines or arrows at all. If drawn, it would consist of disconnected classes arranged in space.

. The knowledge dependency relationship differs from the UML class composition relationship, or any UML relationship for that matter. Although it is often implemented as a UML composition relationship (directed arrow with filled diamond), the meaning is far more constrained. It must be "requires knowledge of to understand". In the UML you can use associations for getting data at run-time, but in ALA you can't. 

. A conventional program will typically have many many dependencies. They are there because data, messages, events, execution flow, etc, need to get from one place to another in the program. Or they are there because we have tried to separate responsibilities arbitrarily. None of these dependencies exist in an ALA program. The whole difficult concept of dependency management simply vanishes. So where do these relationships go? How can the program still work?  How is it possible for messages and events to travel around at run-time if there is absolute zero coupling? In later chapters we will go into detail on how this works, but for now, the short answer is that all these relationships become a line of code inside an abstraction in the layer above. 

. In saying ALA has zero coupling, of course there may be leakage coupling. The quality of the abstractions is important. There is no such thing as black and white abstraction or not-abstraction. Abstraction quality is somewhat subjective, because they are for the human brain. For example, the code inside abstraction A could potentially tell how long B takes to execute. If it is sensitive to that, this is not a problem with ALA, but with the leaky abstraction. The design needs to be changed to eliminate the dependency on that leakage, or, if that is not possible, the coupling managed. But for the vast majority of code, the coupling between the insides of any two abstractions really is zero. 

. An abstraction's implementation can consist of a group of artefacts: local variables, enums, function protoypes, interfaces, methods, classes, etc. These artefacts have high cohesion with one another. They are all considered the code for the one abstraction. They interconnect with each other, unconstrained. There are no dependency rules among them inside an abstraction. The only constraint ALA makes is that their total must be small - of the order of 100-500 lines of code. This applies to all abstractions, including the one that is the application itself in the top layer. Later we will discuss the forces that drive this optimal size.

. ALA has no concept of hierarchies or nesting. Abstractions cannot be contained by other abstractions. They are never nested. The reason they are never nested is simple. An abstraction being used must be more abstract than the abstraction using it. Therefore it must be outside the abstraction using it so it can be reused elsewhere. ALA uses abstraction layers instead of encapsulation hierarchies. In this respect abstractions differ from components in that a component can be a specific part of another component. In other words components can be completely contained (conceptually) by the component that uses it. Abstractions in ALA cannot be.

. Abstractions are the units of code in ALA. They are the only type of 'encapsulation' that works for our brains. Programming languages don't support any concept that corresponds with this idea of an abstraction. So we need to improvise to create abstractions in code, even it can't be understood as an abstraction by the compiler. Classes are the main way to implement most of an abstraction, but we need to add the concept of ports to them. Functions can be natural abstractions. (Note that namespaces are not encapsulations, and play no role except to make abstraction names unique). I usually use a source file to represent an abstraction.

. If the code inside an abstraction becomes too large, we factor out an abstraction. The factored out abstraction must be more abstract, and so not have any implicit coupling to the code it came from. It can know nothing of the specifics of the abstraction from which it was factored. It goes in a lower layer, where it can be reused. When the application itself gets too large, we look for abstractions that allow us to make our 'features' separated. For example, if we are building a weather station, we can make an abstraction out of the instance of the display area of the UI, and another for the menu. The different features, thermometer, anonomter etc, can then 'plug-in' to these abstractions.

. Despite the apparent simplicity of the "Standard deviation uses squareroot" example, the constraint of only being allowed to use knowledge dependencies is not trivial to do all of the time. But once the emergent programming paradigms and patterns are practised, it becomes relatively easy.

. There is one aspect of ALA that is hard to master - the invention of appropriate abstractions is relatively difficult. The reason why the "standard deviation uses squareroot" example seems easy is that the squareroot abstraction was already invented, and we know it so well. In ALA you will need to invent your own domain level abstractions. In other engineering disciplines, new abstractions come along only every few years, or hundreds of years sometimes. In software engineering, we have to do it every day in the first two weeks of a project in a new domain, and probably every iteration after that for a few iterations. But all whom I have taught how to do this have found it worth the effort, and all get much better at doing it. Working in the resulting zero-coupled code becomes a joy. 

. The effect of change to any one part of the program, whether in higher layers or lower ones, has greatly reduced ripple effects when compared with conventionally written programs. A ripple generally stops at an abstraction. And since all relationships are just uses of abstractions, ripples usually stay inside a single abstraction. Since abstractions are just concepts they are relatively stable. The quality of the abstractions is important however. The most common change that ripples outside of an abstraction is to make an abstraction more abstract to increase its versatility for greater reuse. This can usually be accomplished without breaking the existing abstraction interface (e.g. by adding optional parameters or properties).

. We know that ALA requires you to break up your entire application only by factoring out abstractions. So what does the application that's left in the top layer look like when this is done? Well if anything abstract has been removed, what remains must be details specific only to this application. Essentially these details equate with the requirements. The application becomes just a formal expression of the requirements. There will be some information there that wasn't perhaps explicitly stated in the requirements, but they were requirements none-the-less. For example, it may not have been stated that a sensor is connected to port 2. Perhaps unusually, an ALA application will have this detail in the very top layer, or at least in a one feature in the top layer (as a configuration parameter to an instance of an adc channel). Or it may not be stated in the requirements that a number displayed on the UI should not change its value frequently - it should be smoothed. So the application will end up with a filter wired into the data-flow. It is an emergent property of ALA that the application itself ends up being just a succinct, formal representation of the requirements. That specification of the requirements also happens to be executable.

=== Code organisation into folders


Now a practical viewpoint of ALA - how it organises code into folders.

I am appalled when I see C programs with folders for .h files and folders for .c. .h files have close cohesion with .c files.   

If you see an ALA application, you will find three to five folders that correspond with the abstraction layers (described in the previous section):

* Application
* StoryAbstractions
* DomainAbstractions
* ProgrammingParadigms
* Library



Continuing with the idea of knowledge dependencies, the class in the Application folder will have knowledge dependencies on the classes in the DomainAbstractions folder. In other words, you need to know what the classes in the DomainAbstractions folder do in order to read the application code. Similarly the classes in the DomainAbstractons folder have knowledge dependencies on the interfaces in the ProgrammingParadigms folder. There are no dependencies between classes within a folder. 

There should also be a readme file that points to this website (or equivalent documentation). In ALA, we are explicit about what knowledge is needed before a given piece of code can be understood (knowledge dependencies). To understand an ALA application, you need a basic understanding of ALA (from this chapter). So that's why there should be a readme file.

In the Application folder, you will often find a diagram. This diagram describes the requirements. The diagram is 'complete' in that it describes all details of the requirements - it is not just an overview. The diagram is itself 'executable'. ALA is just a way of writing requirements that are executable.

It should be quite easy to read the diagram as it only describes the requirements and does not involve itself with implementation. The boxes are instances of the DomainAbstractions (objects). The lines make a specific composition of instances. (Note that the lines in this diagram are not relationships between design-time artefacts. They are nothing more than equivalent to adjacent lines of code.)

There should be a code file that exactly represents the diagram. It is generated from the diagram. So the diagram is the source. However, looking at this code file may clarify how the diagram is represented in code.

Every box in the diagram is an instance of one of the classes in the DomainAbstractions folder. These classes are called abstractions rather than modules or components because they have zero knowledge of each other and zero knowledge about the specific application. Their abstraction level is more general than the application, and so they are reusable within a domain. For now a domain can just mean your company. 

The lines in the diagram represent connections using one of the interfaces from the ProgrammingParadigms folder. There is usually more than one interface, but no more than a few. Each represents a 'programming paradigm' such as event flow, data flow, a UI composition, or a schema relationship. The abstraction level of the ProgrammingParadigms folder is more general again than the DomainAbstractions - each paradigm should be useful for a type of computing problem in many different domains. This is the 'abstract interactions' pattern.

This small set of interfaces allows instances of domain abstractions to be wired together in an infinite variety of ways - the property of composability.



=== How classes are used

This is another practical viewpoint, this time on how classes are used in ALA programs.

In ALA, a class's public interface (it's public methods and properties) are only used to instantiate and configure the class. It is not used for anything the class actually does. The public interface is 'owned' by the class. It is specific to the configuration of that class. The public interface is only used from a class in a layer above. Only that layer knows what should be instantiated, how it should be configured, and how the instantiated objects are composed together to make a system.

All other operations are done through interfaces. Class don't 'own' these  interfaces. They are not specific to any one class. They are not about what any one class does, or needs. They are more general so that typically many different classes will implement/accept them. Objects of different classes can then be connected together using these more general interfaces in a variety of ways. The implication is that classes do not have association relationships. The lines that you would normally see dominating most UML class diagrams are completely absent if you drew a class diagram of an ALA application. 

ALA doesn't need or use inheritance either. So the only relationship between classes is composition. If you drew a class diagram in ALA, you wouldn't draw lines for composition. This is because you are composing abstractions. You wouldn't draw a line to a square-root function every time you used it. It's the same thing when using any abstraction. So it turns out that if you did try to draw a class diagram in ALA, it would have no lines at all. So there's no point.

Any given class will typically implement/accept more than one of the generic interfaces. For the data-flow interfaces at least, think of them as I/O ports. This is the interface segregation principle, except that we do not refer to the other objects as clients. Only the class in the layer above (that uses the public interface) has the status of a client. The objects to which an object is wired are peers.

=== Abstraction Layers

In contrast to the previous two sections that talk about the use of folders and classes, this section gives the most abstract perspective we will use. I introduce it now because it is the one that gives ALA its name.

This figure shows the abstraction layers:

image::Layers.png[Layers.png, title="The four ALA layers", width=75%]

The first problem in understanding abstraction layers is understanding what abstraction means. Unfortunately the software industry has misused the word to the point where we get things upside down. This comes about because it sees hardware or alternatively the database at the bottom, and since hardware and databases are 'concrete', we argue are the least abstract. And so we build things on top of those that supposedly get more abstract. Whatever is at the very top, we argue, being the farthest away from the concrete silicon, must be the most abstract.

This thinking is completely wrong. We will look in depth at what 'abstract' means in a later section, but for now, just suspend everything you think you know about abstraction. In ALA we will say that 'more abstract' means 'more ubiquitous', 'more reusable' and 'more stable'. The application, at the top, is the least abstract. Also suspend everything you think you know about layers. In ALA, the hardware is never at the bottom. And neither is the database. Your programming language is.

Because this perspective probably doesn't really connect with anything you already do, we will just list three key takeaway points from this section. These will become clearer later. In ALA:

. The only dependencies you are allowed are on abstractions (shown as green arrows on the figure) and referred to as 'knowledge dependencies' or 'design-time dependencies' (as opposed to run-time dependencies).

. The first three abstraction layers are Application, Domain Abstractions, and Programming Paradigms.

. The layers get more abstract as you go down, and therefore more ubiquitous, more reusable, and more stable.


=== Four important SW engineering ideas brought together

ALA is the bringing together of four important software engineering ideas. All are absolutely essential: 

* Abstraction
* Composition
* Direct expression of requirements
* Polyglot Programming Paradigms (execution models)

Surprisingly, none of these four are particularly main-stream (relative to other memes in SW engineering). And I have never seen all four used together anywhere else, so that is what makes ALA unique. Using all four together is incredibly powerful. 

(Polyglot = 'uses multiple different')




=== Executable Description of Requirements

If I had just two minutes to explain what ALA is, this is the perspective I would use: 

This perspective puts the focus on your input information - the requirements. ALA is a methodology that finds a way to directly describe requirements. It describes all the details in the requirements. Instead of having two artefacts, one for requirements capture and one for software source, ALA combines them as a single document and a single source of truth. BDD (Behavioural Driven Design) does something similar, but only achieves it for requirements and their tests. ALA goes one step further and makes the expressed requirements also the solution.

The description of the requirements itself has no implementation details. It just describes all details of requirements. The amount of code that describes requirements is typically about 2% of the entire application. When requirements change, you only need to change this 2%.

The description of the requirements is executable. Even though the description has no implementation details, it still executes directly. The expressed requirements is also the application.


=== Self documenting architecture

The executable description of requirements in the top layer is also the architecture or the design. (I do not make a distinction between architecture and design.) There is no separate artefact or documentation of the architecture, no model, no "high level" design. The same artefact that describes the requirements and is executable is also the application's architecture. One source of truth for everything.


=== Create and Compose

If I had ten minutes to explain what ALA is, this is the perspective I would use.

A common clich√© for tackling complexity is "divide and conquer". Now here is a surprise. In ALA we do not divide and conquer. Instead we "Create and Compose". 

Here are a few examples of composing:

* When we write code in a general purpose programming language, we are composing with statements. Statements are low level (fine grained) elements and only support a single programming paradigm, which we could describe as 'imperative', but by composing instances of them in different ways we can create something. The structure is linear or a tree.

* In functional programming, we are composing with functions, so the elements are higher level things that you create. But the programming paradigm is still imperative. The structure is linear or a tree.

* When programming with monads, we are composing with amplified data types. These are usually low-level elements. But the programming paradigm has changed from imperative to data-flow. The structure is usually linear. (You don't need to understand or use Monads to use ALA. however,   
<<Monads,See my method to understand Monads in Chapter Six>>

* When programming using the UML class diagram, we are composing high-level classes. The programming paradigm is associations. The syntax is graphical. The structure is a network.

////
footnote:[See my method to learn monads in Chapter Six]. 
////

* When programming with XAML, we are composing with fundamental UI elements. The programming paradigm is UI layout.


Let's list the different properties present in these composition methods:

* low-level/high-level - A fixed set of fundamental elements versus elements that you can create.
* Programming paradigm: The meaning of a composition relationship is fixed in each case. It can be Imperative, Data-flow, UI layout etc. 
* Linear/Tree/Network: The structure built by the composition relationships can be linear, a tree structure or a general network. 
* Syntax: The syntax for the composition relationship can be using spaces, dots or boxes and lines and we can use various types of bracketing or indenting for the text form of tree structures.

In ALA, we are setting up the top layer so we can do composition that

* Composes high-level elements that you create.
* Allows use of many programming paradigms, and allows new ones that you can create.
* Uses the same syntax for all composition relationships.
* Allows linear, tree or network structures.

ALA can therefore be described as 'generalised create and compose'. 

Generally, compositions are 'instances of abstractions' 'connected' together in a specific way. This can be thought of as a graph. A graph is most easily imagined as a box and line drawing. In the common examples of composition that we mentioned above, sequential execution flow, monads, UI layout etc, the composition using text readily supports graphs that are linear or small tree structures. Arbitrary graph structures can usually be done by adding connections in a special way - by naming some of the nodes and then connecting by their identifier. However this method is somewhat inconvenient and unreadable in text form. ALA therefore can use diagrams to allow compositions to be arbitrary graphs. We are going to need that in any non-trivial application.

To support generalised composition, ALA dedicates the top layer to the composition itself, a layer below it for the abstractions from which instances can be composed, and a layer below that for the different types of composition paradigms. 
The middle layer is usually plain old classes and the bottom layer is usually plain old interfaces, although there are many other ways to do ALA. 


=== Layers instead of hierarchical decomposition

In the previous section, we discussed how ALA uses 'Create and Compose' rather than 'Divide and Conquer'.

In this section, let's have a look at the other side of that coin and explore what is wrong with decomposition.

Consider this phrase, often found near definitions of software architecture.

[WARNING]
====
"[red]#*decomposition*# of a system into [red]#*elements*# and [red]#*_their_*# [red]#*relations*#".
====

Notice the word 'their', which I have italicised to emphasis that the relations are inferred to be between the said elements. It implies that the elements know something about each other. It implies they collaborate. This is a really bad meme. ALA is the antithesis of this meme.

Here is how to reword the meme for ALA:

[TIP]
====
"[green]#*abstractions*# and [green]#*composition*# of their [green]#*instances*#".
====

Strictly speaking the wording of the decomposition meme does not preclude this meaning, but it is at best misleading. This seemingly subtle shift causes a huge change in the structure, as described in the two contrasting diagrams below: 


==== ALA structure is not this

An architecture based on decomposition into elements and their relations looks something like this:

image::Slide8.jpg[Slide8.jpg, title="Decomposition into elements and their relations", align="center"]

The figure shows five modules (or components) and their relations (as interactions). Study almost any piece of software, and this is what you will find (even if it adheres to the so-called layering pattern).

The structure generally can be viewed as 'clumping'. Like galaxies, certain areas have higher cohesion, and so go inside boxes. Other areas are more loosely coupled, and so are represented by lines between the boxes. The difference between high cohesion and loose coupling is only quantitative.

Software health in this type of architecture is effectively management of the resulting coupling between the cohesive clumps. Allocate code to boxes in such a way as to minimize coupling. This coupling management has two conflicting forces. One is the need to have interactions to make the modules work as a system. The other is to minimize the interactions to keep the modules as loosely coupled as possible. As maintenance proceeds, the number of interactions inevitably increases, and the interfaces get fatter. The clumping is gradually eroded. Any so-called encapsulations become more or less transparent.

Various architectural styles are aimed at managing this conflict. Most notably:

* layering pattern
* MVC pattern
* Dependency rules
. Avoid circular dependencies.
. Avoid high fan-in and high fan-out on a single module.
. Avoid dependencies on unstable interfaces.

Note that none of this 'dependency management' actually avoids circular coupling. To some extent there will always be 'implicit coupling' in both directions between modules of a decomposed system. This is because the modules are the opposite of abstractions - specific 'parts' designed to interact and therefore collaborate. For example, a function of a decomposed system will tend to be written to do what its caller requires even if there is no explicit compile-time dependency on its caller. So circular coupling may be avoided at compile-time, but will still be present at design-time. That is why in the diagram above, couplings are drawn from the insides of each of the modules in both directions. This indicates that the code inside has some inherent design-time collaborative coupling. To the compiler or a dependency graphing tool, the lines may appear to be in one direction, and therefore 'layered', but it is not telling you the whole story of the coupling.


==== ALA structure looks like this

When you use abstractions instead of modules, the qualitative difference is that there are no interactions, no collaboration, no coupling between your abstractions at all:

image::Slide9.jpg[Slide9.jpg, title="Abstraction do not interact", align="center"]

The word 'modules' has been changed to the word 'abstractions'. All the dependencies are gone. And with them all their problems, and all their management. The implicit coupling that we talked about earlier is also gone. It no longer has a 'clumping' structure. Loose coupling is replaced with zero coupling.

The obvious question now is how can the system work? Where do all the  interactions between elements that we had before go? The answer is they become normal code, completely contained inside one additional abstraction:

image::Slide10.jpg[Slide10.jpg, title="Abstractions and composition of their instances", align="center"]

Interactions or collaboration should never be implemented in your abstractions. That just destroys them as abstractions. They are implemented inside another new abstraction at a different, more specific, abstraction level. Being contained inside that new abstraction the interactions are not coupling. They are just a composition of instances. They are cohesively together in one place where they belong because they are the specific information about the specific application. That small amount of code has all the knowledge about the specific application. The abstractions no longer know about the specific application.  

ALA overturns the conventional meme about decomposition into elements and their relations. It is unnecessary to write software that way. The only relationship that remains is the 'use of an abstraction'. This is, of course, a dependency but it is a good dependency. We will discuss from the point of view of good and bad dependencies in a later section. For now, dependencies are good if we want more of them. The more of them the better. For example if you have a library function or class, say squareroot, the more it is used the better, because the more useful the library function must have been. This type of dependency, the 'use of an abstraction', is the only one you need to build a system.


[TIP]
====
Software engineering should [red]#*not*# be about [red]#*managing coupling*#.

It should be about [green]#*inventing abstractions*#. 
====



anchor:DSL1[]

=== DSLs

ALA's succinct expression of requirements in the top layer sounds similar to the way requirements might be represented in a DSL (Domain Specific Language). Under the broader definition of a DSL, ALA's domain abstractions layer is a DSL. But ALA is also different from a DSL. ALA, as its name suggests, is fundamentally about layering of abstractions. It layers them in a small number of layers, according to their abstraction level. When you do this, the top two layers emerge as the specific application and the domain. Therefore ALA happens to converge on the same solution as DSLs for these top two layers.

In coming to this same solution from a different direction it has a different emphasis than a DSL has. It does not pursue the idea of an external DSL (new syntax), nor even the syntactic elegance of DSLs. It doesn't move application development away from the developer as DSLs are often designed to do. You don't get a different language such as XAML that a UI specialist designer can learn. These things may still be desirable qualities and ALA does not preclude them, it is just not what ALA is about. ALA says that just getting the abstraction layering right is enough to deal with complexity and maintainability.

As a DSL, in ALA you usually just wire together plain old objects, or functions in a way that is confined by a grammar. The classes (the domain abstractions) and the 3rd layer interfaces collectively form the DSL. The grammar is defined by which classes use which interfaces. This sets the rules for composition.

By the way, ALA also emerges other already discovered architectural styles such as CBE (Component Based Engineering), and composability. These are discussed later.

=== SMITA (Structure Missing in the Action)

The problem in most large code bases is that the system structure, the in-the-large structure, is not explicit. It is distributed inside the modules themselves. If there is any collaboration between modules, it is implicitly hidden inside them. Finding this structure, even for a single user story can be time consuming. I have often spent a whole day doing that, doing countless all-files searches, just to change one line of code. Many developers I have spoken to can identify with this experience.

It can get a lot worse as the system gets larger. In a bizarre twist, the more loosely coupled you make the elements, the harder it gets to trace a user story through them (because of the indirections). Some people conclude that loose coupling and being able to trace through a user-story are naturally in conflict.

I call this situation SMITA (Structure Missing in the Action). This hidden structure is sometimes partially brought out as a model, a sort of high-level documentation of the internal structure. But such models are a secondary source of truth.

ALA completely eliminates this problem and this conflict. The structure is explicitly coded in one place, without any indirections. Yet the abstractions are zero-coupled. 


=== Diagrams vs text

// TBD - there are two sections called Diagrams vs Text

In ALA we will often use a diagram instead of text for the source code in the application (top) layer. 

Text is effective only when the relationships between instances of abstractions (words in the text) is a linear sequence or a relatively shallow tree (represented by indenting). If the relationships are an arbitrary graph or a deep tree, diagrams are far more effective. Becasue of this, part of what ALA is about is easily supporting programming with diagrams (sometimes called models, but I will avoid this ambiguous term). ALA diagrams show everything in an applciation, UI, event flow, dataflows, state machines, etc. 

If a diagram is used, it is the 'source'. A code form of the diagram is generated from it for execution.

We will delve into greater detail on why our brains work better with diagrams, and graphing tools to support diagrams in chapter three.

=== Real world metaphors

==== Atoms and molecules

Here are two atom abstractions:
image:oxygen.png[Oxygen atom, 200, title="Oxygen atom"]
image:hydrogen.png[Hydrogen atom, 200, title="Hydrogen atom"]

Instances can be composed to make a molecule:
image:water_molecule.jpg[Water molecule, 300, title="Water molecule"]


If water was implemented in the same way we typically write software, there would be no water molecule per se; the oxygen atom would be modified to instantiate hydrogen atoms and interact with them. Even if dependency injection is used to avoid the instantiating, it is still unlikely that a water abstraction would be invented to do that, and there would still be the problem of the oxygen module being modified to interact with hydrogen's specific interface. Either way, the oxygen module ends up with some implicit knowledge of hydrogen. And hydrogen probably ends up with some implicit knowledge of oxygen in providing what it needs. 

This implicit knowledge is represented by the following diagram. The relationship is shown coming from the inner parts of the modules to represent implicit knowledge of each other.

[plantuml,file="diagram-o-h.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
subgraph cluster_o { 
style="rounded"
margin="16"
Oxygen [style="setlinewidth(0)"]
}
subgraph cluster_h { 
style="rounded"
margin="16"
Hydrogen [style="setlinewidth(0)"]
}
edge [color=red]
Oxygen -> Hydrogen [dir="both", arrowhead="dot", arrowtail="dot"]
}
@enddot
----



While oxygen and hydrogen are modules, they are not abstractions because oxygen is implicitly tied to hydrogen and vice-versa. They can't be used as building blocks for any other molecules.

To keep oxygen as abstract as it is in the real world, an interface must be conceived that is even more abstract than oxygen or hydrogen. In the molecule world this is called a polar bond.

The corresponding software would look like this:


image::Slide15.jpg[Slide15.jpg, title="", align="center"]

The water molecule has a "uses instances of" relationship with the two atoms, and the atoms have a "uses instance of" relationship with the even more abstract polar bond. Polar bond is an example of what we call an 'abstract interaction'.

==== Lego

The second real world metaphor is Lego. Shown in the image below is the same three layers we had above for molecules, atoms and bonds.

image::Slide16.jpg[Slide16.jpg, title="", align="center"]

The domain abstractions are the various lego pieces, instances of which can be assembled together to make things. Lego pieces themselves have instances of an abstract interface, which is the stud and tube. There is a second abstract interface, the axle and hole. We also call the abstract interface the 'execution model' and here with the lego metaphor we start to see why it can be thought of in this way - when the model runs, stud and tube interface executes the holding of the model together and the axle and hole interface executes turning.

==== Electronic schematic

The third real world metaphor comes from electronics. The abstractions are electronic parts, instances of which can be composed as a schematic diagram:  

image::Slide17.jpg[Slide17.jpg, title="", align="center"]

In this domain, the abstract interfaces (execution models) are both digital signals and analog voltage levels.

==== A clock

The forth and final real world metaphor is a clock. In this diagram, we show the process of composition of abstractions to make a new abstraction. The process is a circle because instances of the new abstraction can themselves be used to make still more specific abstractions. Each time around the circle adds one layer to the abstraction layering.

image::Slide18.jpg[Slide18.jpg, title="", align="center"]

Let's go round the circle once. We start with abstract parts such as cog wheels and hands. Instances of these have abstract interfaces that allow them to interact at run-time, such as spinning on axles and meshing teeth. The next step is to instantiate some of these abstractions and configure them. For example, configure the size and number of teeth of the cog wheels. Next comes the composition step, where they are assembled. Finally we have a new abstraction, the clock. Instances of them can be used to compose other things such as a scheduling things during your day, but that is a whole different abstraction. 

There are many other instances of this pattern in the real world, and in nature. In fact almost everything is composed in this way.


=== Example project - Thermometer

In this example project, we will first do it a version using functions, then later we will do a version using classes. The ALA layering rules work the same for both.  

// Applying ALA to functional composition means three things:

// *  Functions (or small groups of them) are abstractions.

// For our purpose here, an abstraction means that our brain can easily learn (by reading the function name or a comment) and retain what a function essentially does. It means that when other programmers are reading your code where a function is called, they don't have to 'follow the indirection' - they can stay with the code unit they are in, and read it like any other line of code. It means a single responsibility. It means it knows nothing about the content of any other abstractions. It means reuseable, and it means stable. The name of the function should not be generic ProcessData, or CalculateResult. It should not be the name of the event that caused it to be executed like PulseComplete. If it calculates a result, it does not know where that result goes. It does not directly call another abstraction at the same level. Instead, it either returns it, or calls a function that was passed to it (like the functional programming guys do).

// * Functions go in a small number of discrete abstraction levels.

// This implies that function call depth is at most three (not counting library functions at a 4th level).

// The first level function contains all knowledge about the application requirements. No implementation here, just describe the requirements in terms of other functions.

// The second level is functions that contain knowledge about reusable operations in the problem domain. It has all the abstractions needed to make it possible for the first level to describe the requirements. No function at this level knows anything about the specific application. An example would be calculate mortgage repayments, or filter data.

// The third level functions are at an even greater level of abstraction, things that would be potentially reusable in many domains. It should have the abstraction level of the types of programming problems being solved. Examples might be communications, persistence, logging. None of these functions can have any knowledge of the specific application, nor the domain. So the persistence functions are not persistence of specific domain objects. With configuration, they would know how to persist anything.  

// A function that doesn't clearly belong at one of these abstraction levels should be split in two. Specific application knowledge generally becomes configuration parameters in the higher layer of a more abstract function in the domain layer.

// For completeness, a 4th level would be your programming language library. Nowhere in these levels is the underlying hardware, nor data. Later we will see where they go, but for now forget all preconceived notions of layers such as UI, business logic and Database. In ALA, these are not layers, just abstractions in the domain layer (that know nothing about each other) that get wired together by the application in the top layer.  

// * The top layer just describes the requirements.

// The top layer describes requirements and that's all it does (like a DSL). It composes functions from the lower layers, and configures them for a specific purpose according to the requirements. 

Functions have an execution model we are already familiar with, making this first example easier to understand. However, keep in mind that, for whole programs, this execution model does not usually make a good programming paradigm. Another rule of ALA is that we accommodate any programming paradigm, and we use the one that best expresses the requirements. 

Nevertheless, functional composition is a passable programming paradigm for a tiny, dedicated embedded program in a micro-controller such as our thermometer. Lets have a look at the type of code I typically see:


==== Bad code

.configurations.h
[source,C]
 #define BATCHSIZE 100
 
.main.c
[source,C]
 #include "configurations.h"
 void main()
 {
    int temperatures[BATCHSIZE];
    ConfigureTemperaturesAdc();
    while (1)
    {
        GetTemperaturesFromAdc(temperatures); // gets a batch of readings at a time
        ProcessTemperatures(tempertures)
    }
 }

.process.c
[source,C]
 void ProcessTemperatures(int adcs[])  
 {
    float temperature;
    for (i = 0; i<BATCHSIZE; i++) {  
        temperature = (adcs[i] + 4) * 8.3; // convert adc to celcius  
        temperature = SmoothTemperature(temperature);  
        ResampleTemperature(temperature);
    }
 }

.Resample.c
[source,C]
 void ResampleTemperature(float temperature)  
 {
    static int counter = 0;
    counter++;
    if (counter==15)
    {
        DisplayTemperature(temperature);
        counter = 0;
    }
 }

.smooth.c
[source,C]
 // smooth the reading before displaying
 float SmoothTemperature(float temperature) 
 {
    static filtered = 0;
    filtered = filtered*9/10 + temperature/10; 
    return filtered;
 }

.adc.c
[source,C]
 #include "configurations.h"
 void ConfigureTemperaturesAdc()
 {
    // configure ADC port 2 to do DMA BATCHSIZE values at a time
 }
 float GetTemperaturesFromAdc(int temperatures[]) 
 {
    for (i = 0; i<BATCHSIZE; i++) {
        temperature[i] = Port(2);  / pseudocode here for the port access
    }
 }

////
<1> function name is specific to this application, destroying it as a potential abstraction
<2> functions are collaborating to implement the 100 samples at a time requirement
<3> details from requirements appearing inside functions (all the constants), destroying potential abstractions
<4> function name doesn't describe an abstraction
<5> function has three responsibilities, process 100 samples at a time, convert to Celsius, and Filtering
<6> function composition in wrong level (only the application knows this needs doing
<7> function composition too deep (function composition should be shallow)
<8> Temporal problems - if adc readings take 1 ms, main loop time is 100 ms
////

At first this code wont look that bad, only because the whole program is so small.

As we are taught to do, different responsibilities of the thermometer implementation have been separated out into smaller pieces that we can understand, although ProcessTempertures appears to have three responsibilities. However, all the pieces are in some way collaborating to make a thermometer. They are all, therefore, coupled in some way, either explicitly or implicitly. So, we have to read all the code to understand the thermometer. Scale this up to 5000 lines of code, and we will have a big mess.


We are going to refactor the program using the ALA strategy:

* every piece of knowledge about 'being a thermometer' will be in one function
* That 'Thermometer' function will be at the top
* That function will do nothing else itself
* how to do things will be put into other functions
* those function will not know anything about thermometer
* those functions will, therefore, be more abstract than a thermometer 

==== Toward better code




.application.c
[source,C]
 #define BATCHSIZE 100
 void main()
 {
    int adcs[DMABATCHSIZE];
    float temperatureCelcius;
    float smoothedTemperatureCelcius;
    while (1)
    {
        GetAdcReadings(adcs, 2, DMABATCHSIZE);  // port=2
        for (i = 0; i<BATCHSIZE; i++) {
            temperatureInCelcius = OffsetAndScale(adc, offset=4, slope=8.3); 
            smoothedTemperatureCelcius = Filter(temperatureCelcius, 10); 
            if (SampleEvery(15)) 
            {
                Display(FloatToString(smoothedTemperatureCelcius, "#.#"));
            );
        }
    }
 }



.offsetandscale.c - (domain abstraction)
[source,C]
 // offset and scale a value
 void OffsetAndScale(float data, float offset, float scale) 
 {
    return (data + offset) * scale;
 }



.filter.c - (domain abstraction)
[source,C] 
 // IIR 1st order filter, higher filterstrength is lower cutoff frequency 
 float Filter(float input, int strength)  
 {
    static float filtered = 0.0; 
    filtered = (filtered * (strength-1) + input) / strength
    return filtered;
 }



.resample.c - (domain abstraction)
[source,C] 
 // Returns true every n times it is called
 bool SampleEvery(int n)  
 {
    static counter = 0; 
    counter++;
    if (counter>=n)
    {
       counter = 0;
       rv = true;
    }
    else
    {
       rv =  false;
    }
    return rv;
 }


The code now begins to be arranged into two abstraction layers, the application layer and the domain abstractions layer. The application is now the only function that knows about being a thermometer. (It is still doing some logic work - the 'for loop' and 'if statement', which we we will address soon.) 

All the other functions are now more abstract - GetAdcReadings, OffsetAndScale, SampleEvery, Filter, FloatToString, and Display. Notice how the work thermometer is removed from their names, and none of them contains constants that are specific to a thermometer. 

These abstract functions give you four things:

* Abstract functions are way easier to learn and remember what they do
* Abstract functions give *design-time* encapsulation i.e. zero coupling. *Compile-time* encapsulations can still have a lot of intrinsic coupling (collaboration)
* Abstract function interfaces are way more stable - as stable as the concept of the abstraction itself
* Abstract functions are reusable


Now lets go one more step and create an abstraction to do what that for loop does: This may seem like a retrograde step, but we need to understand this mechanism to move to our final goal of pure composition of abstractions. We want to move the 'for loop' out into its own abstraction, but we don't want to move the code that's inside it. We accomplish this by putting the code inside in a function and passing it to the for loop as a function:  


.application.c
[source,C]
 #define DMABATCHSIZE 100
 void main()  
 {
    int adcs[DMABATCHSIZE];
    float temperatureCelcius;
    float smoothedTemperatureCelcius;
    ConfigureAdc(2, DMABATCHSIZE)
    while (1)
    {
        GetAdcReadings(adcs, 2, DMABATCHSIZE);  // port=2 
        foreach(adcs, func);
    }
 }
 void func(float adc)
 {  
    temperatureInCelcius = OffsetAndScale(adc, offset=4, slope=8.3); 
    smoothedTemperatureCelcius = Filter(temperatureCelcius, 10); 
    if (SampleEvery(15)) 
    {
        Display(FloatToString(smoothedTemperatureCelcius, "#.#"));
    );
 }



.foreach.c
[source,C]
 void foreach(int values[], void (*f)(int))
 {
    for (i = 0; i<sizeof(values)/sizeof(*values); i++) {
        (*f)(values[i]);
    }
 }




Now we created a nasty symbolic indirection, func. Symbolic indirections that are not abstractions are bad. So lets go ahead and remove that by using an anonymous function directly as the second parameter of foreach: 




.application.c
[source,C]
 #define DMABATCHSIZE 100
 void main()  
 {
    int adcs[DMABATCHSIZE];
    float temperatureCelcius;
    float smoothedTemperatureCelcius;
    ConfigureAdc(2, DMABATCHSIZE)
    while (1)
    {
        GetAdcReadings(adcs, 2, DMABATCHSIZE);  // port=2 
        foreach(adcs, (adc)=>{
            temperatureInCelcius = OffsetAndScale(adc, offset=4, slope=8.3); 
            smoothedTemperatureCelcius = Filter(temperatureCelcius, 10); 
            if (SampleEvery(15)) 
            {
                Display(FloatToString(smoothedTemperatureCelcius, "#.#"));
            );
        });
    }
 }


It uses he lambda syntax '()=>{}', which if you are not already famiar with, is worth getting used to because we will end up using it a lot in ALA programs to get code into the right layers.

The next thing we want to do is get rid of the while loop, get rid of indenting, and stop handling the data that is being passed from one function to another. All those intermediate holding variables, adcs, temperatureCelcius, etc are too much like work, and not just composing our thermometer from abstractions.

The while loop and all the indenting are there only because we have execution flow tied in with our composition flow. 

For this we will use monads in an intermediate step. Don't worry if you don't understand monads, we don't really need this step to understand our final goal. But for those who do know monads, it is interesting to visit this step to see why the functional programming guys invented them. 

////
<1> The application function is readable in isolation (without having to go and read code inside any of the abstractions.
<2> The application describes the thermometer, has all the details of the thermometer, and does nothing else. It delegates all the actual work to the domain abstractions. The application knows nothing of how the abstractions work, only what they do.
<3> None of the abstractions know anything about each other or anything about the application. They don't know they are being used to make a thermometer. They are readable in isolation. It easy to remeber what they do. They are more stable. They are reusable.
<4> Application knows the detail of how many ADC readings to get at a time for performance, but not that the adc uses dma to do that. 
<5> Application knows the conversion factor from ADC to Celsius but not how to do offsetting and scaling.
<6> Application knows the amount of filtering needed to get a smooth thermometer but not how to do filtering.
<7> The emphasis is on 'abstraction' not on 'zero side effects'. Filter and SampleEvery are good abstractions despite having a side effect.

These are more properties of the abstraction layered version:

* The application can easily be rewired to do things like the following examples:
** swap the order of processing of the SampleEvery and the filtering to improve performance
** insert a new data processing operation between say the scaling and the filter
** add a logging output destination
** switch to a different type of ADC or display
** add adapters or wrappers for using 3rd party components

* If the requirements of the thermometer change, no domain abstractions would change - because they don't know anything specific about thermometers.  

* In this 'functional composition', at run-time, data comes up into the application code layer and back down into the domain abstractions layer at each step. That's why the application has some local variables to store the data temporarily at various points during the processing. In most other programming paradigms we will use, the data will not come up to the application layer at run-time. Instead, it will go directly between the instances of the domain abstractions. The application will be concerned with wiring them together, not with handling data.
////

////

==== Composing with lambda functions

In the previous code, the application code was handling the data at run-time. It was using those intermediate variables to store the data it received from each function, and then passing that data to the next function. But it wasn't doing anything with the data. It would be much nicer if the application just did the job of composing the functions, but the data passed directly from one to another at rin-time.

This can be accomplished (in a awkward manner) using anonymous lambda functions. Each function has the next function passed into it:




.application.c
[source,C]
 #define DMABATCHSIZE 100
 void main()
 {
    ConfigureAdc(Port=2, DMABATCHSIZE)
    while (1)
    {
        GetAdcReadings(Port=2, DmaBatchSize=DMABATCHSIZE, (values) => 
            {
                foreach(values, (value)=> 
                    { 
                        OffsetAndScale(value, offset=4, slope=8.3, (value)=>
                            {
                                Filter(value, 10, (value)=>
                                    {
                                        SampleEvery(value, 15, Display);
                                    }
                                );
                            }
                        );
                    }
                );
            }
        );
    }
 }






It also allows us to take the for loop logic out of the application and use an abstraction instead, "foreach".
It gets us closer from a composition of abstractions point of view, but all that indenting is impractical. And we needed almost empty lambda functions just to contain the other functions. We need a fluent syntax to express the composition. Lets see how it looks using monads.

////

==== Composing with monads

.application.c
[source,C]
....
 void main()
 {
    program = new ADC(port=2, batchSize=100)
    .foreach()
    .OffsetAndScale(offset=4, slope=8.3)
    .Filter(strength=10)
    .SampleEvery(15)
    .NumberToString(format="#.#")
    .Display();
    
    program.Run();
 }
....



Monads have allowed us to separate execution flow from composition flow. The composition flow in this case is the data-flow paradigm. Data will flow from the ADC to the display, so that is directly represented by the composition. How it executes is now separated out, but we will go into how that works shortly. Lets first understand the 'composition' and why this is so important.

Even if you don't understand how the monads work, you can see that syntactically the program is now very nice because all it does is compose instancesofabstarctions, and configure them with constants to be a thermometer. The composition is not declarative it is data-flow, because dataflow suits how to describe the thermometer.

////
It suits where a part of a program has all of these characteristics:

. dedicated CPU 
. process a job as fast as it can in computer time
. doesn't have to wait for anything while it is being done
. nothing else needs doing while this is happening
. the sequence is known ahead of time (proactive not reactive)


An 'algorithm' is an example of something that suits functional composition.

It is common to use multi-threading as the solution to the first four problems in the bullet list. That is a really bad and dangerous way to force what is fundamentally the wrong programming programming paradigm to do the job. Multiple threads are good to solve a small class of performance problems only. The programming paradigms we will use throughout the examples in this book are way better at expressing solutions than multiple concurrent threads exchanong messages. End of rant.

////

We are using the word 'composition' here to mean the things we are joining together in adjacent lines of code. It can also mean joining boxes with lines in a diagram. Think of a composition as analogous to the adjacent notes in a music score, which are always played successively. If the lines of code are statements or function calls, we are composing things for successive synchronous execution by the CPU. 

Here we are composing for successive processing of data, or Data-flow composition. How it actually executes has been abstracted away and is handled separately. 

Also notice that the first statement just builds the program. Then the second statement sets it running. This two stage aspect of monads is common in all the programming paradigms we will use in ALA. It is because the underlying execution flow is not the same as the flow of the program. We first wire it up, and then we tell it to 'execute'.

The while loop code version we had above handled the data itself. Each function returned the data which was then passed into the next function. The monad code doesn't do that. Instead, it creates and wires together objects which will, at run-time, send the data directly from one to another. This does not mean that the abstractions themselves know anything about each other - they are still zero coupled. 

Lastly two paragraphs about how monads actually execute - the execution model. Don't worry if this doesn't make sense. 

Each function in the program statement (the function after each dot) executes once when the program starts. They are not executed when the program is running. Each of these functions first instantiates an object (using new), and secondly wires that object to the previous object. 

The functions wire the objects together using a common abstract interface. Common interfaces used for this type of programming paradigm are like IEnumerable or IObservable. These interfaces support iteration of data, what we call a stream. If using the IEnumerable interface, there is a simple method in the interface that pulls data from the previous object. If using the IObseravble interface, there is a simple method in the interface that pushes data to the next object. 



==== Composing with objects


////
The most common programming paradigm we will likely want to use is Data-flow. When we compose domain abstractions together using this paradigm, we mean that at run-time data will pass between adjacently wired instances. There may be waits, thread swaps, or IO along the way. It may take days for the data to flow through. But the flow is directly expressed as adjacent lines of code. A Data-flow implementation used in functional programming is monads. We wont learn further about monads here (many have attempted to explain monads and failed), except to say that this is what the Thermometer example might look like using them. 
////

Here is the same program as above, but where we are using new ourselves to create the instances of abstractions, and explicitly wiring them together ourselves.  

.application.c
[source,C]
....
 void main()
 {
    program = new ADC(port=2,batchSize=100)
        .WireIn(new Foreach())
        .wireIn(new OffsetAndScale(offset=4, slope=8.3))
        .wireIn(new Filter(strength=10))
        .wireIn(new SampleEvery(15))
        .WireIn(new NumberToString(format="#.#")
        .wireIn(new Display());
       
    program.Run();
 }
....

It's slightly longer than the monad version. You can see that we are using plain old objects. But we will have a big advantage by doing it this way soon. 

The wireIn method is doing dependency injection. 

The WireIn method returns the new object, so it is possible to string WireIns together. This is called fluent syntax. 

==== Composing using multiple programming paradigms:


Monads allowed us to compose using the data-flow programming paradigm. But what if we want to compose the UI? What if we want to compose the flow of navigation around an application? What if we want to compose transitions in a statemachine? ALA prescribes that we be able to do all this in the one application - whatever paradigms are the  best way to express the requirements. 

Some instances of abstraction will need to take part in multiple paradigms, such as both UI and dataflow. When we boil down the description of our application to pure composition, our composition will often be a network. And when you have a network, your composition is best described by a diagram. 

To illustrate this let's add some UI to our thermometer:

image::ThermometerDiagram.png[ThermometerDiagram.png,500, title="Thermometer application complete with UI"]


The diagram has a UI composition as well. Once we have this diagram, it is easy to conceive how we might add features. For example, we could add a button into the UI, and wire it a switcher abstraction that changes between Celcius and faranheit.

For UI part of the composition, the lines obviously don't mean data-flow - they mean 'display inside'. So now different lines in our diagram have different meanings. Here is how that diagram is represented as text. 

.application.c
[source,C]
....
 void main()
 {
    FloatField temperature;
 
    program = new ADC()
        .WireIn(new Foreach())
        .wireIn(new OffsetAndScale(offset=4, slope=8.3))
        .wireIn(new Filter(10))
        .wireIn(new SampleEvery(100))
        .WireIn(new NumberToString()
        .wireIn(temperature = new FloatField());
    
    mainwindow = new Window()
       .wireTo(new Label("Temperture:"))
       .wireTo(temperature);
    
    mainwindow.Run();
 }
....

There are two programming paradigms here - the meaning of the wiring is data-flow in some parts, and UI layout in other parts. This is all done in the one cohesive piece of code that represents the thermometer application, and has all details which could be associated with the concept of a thermometer.

The example projects in later chapter will use a range of different programming paradigms and consequently 'composition' will mean different things. Sometimes we will use custom programming paradigms - whatever allows us to describe those requirements in the best way.


=== Calculator



This project came from a workshop on ALA. Apart from being a cool example of the use of ALA, the calculator itself is cool. This calculator is in Github, as a work in progress, so you can clone it or download it, run it, and look at any of the details of how it, or any of the domain abstractions work here: https://github.com/johnspray74/ReactiveCalculator[https://github.com/johnspray74/ReactiveCalculator]

The development was done in a hurry for the workshop, so here we tell the story of the development as well as how the calculator is designed. 

When I was first asked to do the workshop, I needed to think of a suitable pedagogical sized project. It was suggested to me to do a calculator. Ok, I thought, if we have the domain abstractions in place, and a rehearsed application, we should be able to write a calculator application in a workshop. 

When we think of a calculator application, we usually imagine a simulated version of a handheld calculator with a one line display and a keypad. We certainly could have built that calculator (primarily using a state machine programming paradigm). But that problem has already been solved by Miro Samek. Besides, such a calculator would be boring and useless.

As an aside, I once had a love affair with HP calculators. The first programmable anything I ever owned was a calculator. I have owned many top end models at one time or another, and even own some SwissMicro modernized copies. But as their displays got larger, I became more and more disappointed with how they used that display real-estate. They just used it as a stack. The calculator I wanted shows the algebraic expression (formula) you used to get the result (so you can check what you did). You could edit the formula. You could label your formulas. You could use the result of one formula in another. When you change a formula or label, all results would be updated in situ. You could enter in RPN style but have it displayed in textbook or algebraic. The HP prime was the pinnacle of this disappointment. What a waste of space.  

So I drew a sketch of what I thought the HP Prime should have been. Here is the actual sketch: 

image::CalculatorRequirements.png[Calculator3.png, 900, title="Calculator requirements"]


Here is a screenshot of the working calculator as it was two half-days later:

image::CalculatorScreenshot.png[CalculatorScreenshot.png, 900, title="Calculator screenshot"]


The first step in the design of the calculator was to express the requirements (UI plus behaviours), inventing any needed abstractions to do so. Here is the actual first sketch: 

image::Calculator2Rows-HandDrawing.png[Calculator2Rows-HandDrawing.png, 900, title="Calculator (2 Rows only shown)"]

As we shall see, this diagram is practically executable code. The calculator is practically done. We don't know if the invented domain abstractions will work yet, but let's go through how this calculator works anyway. 

First notice how the entire calculator is here. Every detail about this particular calculator cohesively works together, so it all belongs together. This is an important aspect of ALA designs. All the UI and all the data flows to make a working calculator are in this one diagram. What is not here is the details we left to the domain abstractions. None of these abstractions is specific to a calculator. They can be used for all sorts of things. Even the Formula abstraction would be useful in any application where a calculation needs to be changed at run-time. For example an insurance application may need configurable calculations.

The left side shows two instances of the abstraction, Horizontal. These arrange their children horizontally in the UI. To the left of those (not shown) is an instance of Vertical, which arranges the two Horizontals vertically. And to the left of that would be an instance of MainWindow.   

Each Horizontal has 3 instances of TextBox and one Text. The TextBoxs allow you to enter a string. The abstraction, Text, can only display a string. I see at this point, I hadn't put in the TextBox for the description. 

===== How the calculator works

We can ignore the use of labels for a moment and just enter a formula containing constants into the first row TextBox. Let's say we type in "2+1". The string "2+1" goes along the data flow wire to the StringFormat instance on its port 0. The StringFormat is configured with the format string "({1}=>{0})". StringFormat uses this format string in the same way as an interpolated string in C#. The {0} is substituted with the string coming in on port 0. The {1} is substituted with the string coming in on port 1. Since we have no string on port 1, the output from the StringFormat will be "()=>2+1". This is simply a lambda expression with no parameters. This string is fed into the instance of Formula. Formula is an abstraction that knows how to evaluate a lambda expression. Actually it will accept just a formula (such as "2+1" as well). We can ignore the other input of Formula for the moment. Formula will evaluate "()=>2+1" and produce the number 3 on its output. This output is a data-flow of type double. This number is fed to an instance of NumberToString, and from there it goes to the instance of Text that knows how to display a string.

Now let's follow the use of labels in the calculator. Let's put the labels "a" and "b" into the TextBoxs for labels on the two rows. "a" and "b" are fed to the Concat instance. Concat's input port can have any number of string data-flows wired into it. In this diagram it has only two. What Concat does is concatenate all its inputs adding a separator. In this case the separator is configured to be a comma. The output of the Concat is "a,b". The concatenated list of labels is fed into port 1 of both StringFormat instances. 

Now let's put the formula "a*3" into the 2nd row of the calculator. The output of the StringFormat for that row will be "(a,b)=>a*3". That lambda expression will be fed to the Formula instance, which will evaluate it, using the first value on its input port for the value of 'a'. The output will appear on the corresponding Text in the 2nd row.

So that's all there is to understanding how the calculator works. At this point it takes a leap of faith that the abstractions can all be made to work, and that the two programming paradigms used, the UI layout and the data-flow, can be made to work. Not withstanding that, all the information required in the design of the calculator is captured.

At this point I drew little drawings of all the invented abstractions. Actually I reused TextBox, Text, Vertical, Horizontal and FormatString from a previous project. And I had already made the UI and data-flow programming paradigm interfaces in previous projects, so I reused them as well. Of course all those reused domain abstractions used those interfaces. 




image::CalculatorDomainAbstractionsHandDrawings.png[CalculatorDomainAbstractionsHandDrawings.png, 300, title="Calculator Domain Abstractions"]

I see I forgot to draw Concat. I had to write that one. Here is its template as it was in my Xmind templates diagram.

image::CalculatorStringConcatTemplate.png[CalculatorStringConcatTemplate.png, 400, title="StringConcat template"]

The two ports are both drawn on the right hand side unfortunately - a limitation of using Xmind as the drawing tool. Drawing the templates makes the ports clearer ready for implementation.  

==== Implementing the domain abstractions


Many abstractions are trivial to implement because they are zero coupled with anything. They are like tiny stand-alone programs. Here is the full code for StringConcat.

.SringConcat.cs
[source,C#]
....
using ProgrammingParadigms;
using System;
using System.Collections.Generic;
using System.Linq;

namespace DomainAbstractions
{
    /// <summary>
    /// Outputs the input strings concatenated together
    /// Whenever an input strings changes, a new output is pushed.
    /// ---------------------------------------------------------------------------------------------------------
    /// Ports:
    /// 1. List<IDataFlowB<string>> inputs: inputs (indefinite number of string inputs)
    /// 2. IDataFlow<string> output: output
    /// </summary>



    public class StringConcat
    {
        // Properties ---------------------------------------------------------------
        public string InstanceName { get; set; } = "Default";
        public string Separator { private get; set; } = "";

        // Ports ---------------------------------------------------------------
        private List<IDataFlowB<string>> inputs;
        private IDataFlow<string> output;


        /// <summary>
        /// Outputs a boolean value of true when all of its inputs are true. Null inputs are treated as false.
        /// </summary>
        public StringConcat() { }

        // This function is called immediately after each time the inputs port is wired to something
        private void inputsPostWiringInitialize()
        { 
            inputs.Last().DataChanged += () =>
            {
                var result = "";
                bool first = true;
                foreach (IDataFlowB<string> input in inputs)
                {
                    if (!first) result += Separator;
                    first = false;
                    result += input.Data;
                }
                output.Data = result;
            };
        }

    }
}
....


The code in Concat is straightforward if you know C#, except for a few conventions which are to do with the use of ALA (which I was already proficient with):

. We put a property "InstanceName" in every domain abstraction. It's not required, but the reason is because abstractions get reused. So you are likely to end up with multiple instances of an abstraction all over your application. If you name the instances, it makes debugging a lot easier because you can see it in the debugger and know which instance you are in.

. All the IO for the abstraction is in a section called "Ports". Usually an abstraction would have some ports that are private fields of the type of an interface, and some that are an implemented interface. It just so happens that StringConcat has no implemented interface ports.

. The two ports are private, and yet they get wired by the application code to other objects. This may seem a little bit magic. The reason they are private is to indicate they are not for use by anything else. The application will use a method called WireTo() to achieve the wiring. WireTo is an extension method on all objects. It uses reflection to find and assign to these "port" fields.

. Notice that the "inputs" port uses IDataFlowB (not IDataflow). The B on IDataflowB indicates a tricky workaround for a limitation in the C# language. What we would have liked to do is implement IDatFlow. But we would have needed to implement IDataFlow multiple times. You can't do that in C# (although there is no reason why not in theory, and hopefully all languages will have this feature to support the concept of ports one day).

. Notice that the method, inputsPostWiringInitialize, is private and apparently unused. When the WireTo operation wires a port "xyz" it looks for a private method called xyzPostWiringInitialze and invokes it immediately. This gives us the opportunity to set up handlers on any events that may be in the interface. In this case, the IDataFlowB interface has a DataChanged event (that tells us when there is new data on the inputs).    

. It doesn't make sense to use a StringConcat without wiring its output to something. So the line "output.Data = result" will throw an exception if the application has not wired it. Often times, abstractions have ports that are optional to wire, in which case we would use "outputs?.Data = result"


For reference, here is the IDataFlow interface, which lives in the ProgrammingParadigms folder, and is used by most of the domain abstractions including the StringConcat abstraction:


.IDataFlow.cs
[source,C#]
....
namespace ProgrammingParadigms
{
    public interface IDataFlow<T>
    {
        T Data { get; set; }
    }
}
....

As you can see, this interface is simple, but its importance in giving us a data-flow programming paradigm is huge. It allows objects to be wired together so that data can flow from object to object without the abstractions knowing anything about each other. Note that IDataflow uses a 'push' execution model. This means that the source always initiates the transfer of data on its output (by using 'set'). The IDataFlowB interface is a little more complicated, so we wont go into how it works just now. But it achieves exactly the same purpose of the data-flow programming paradigm, just in a different way that allows more than one input port of the same type. .


The other domain abstraction I needed to write for the first time was Formula. Here is the template as used in Xmind: 


image::CalculatorFormulaTemplate.png[CalculatorFormulaTemplate.png, 500, title="Formula template"]


Once again, one of the input ports is shown on the right when we would prefer it to be on left.

Formula can be configured with an optional C# lambda expression when it is instantiated by the application, for example:

.Application.cs
[source,C#]
....
new Formula() {Lambda = (x,y) => x+y; }
....

If used in this way, the formula is fixed at design-time. But its real power comes from the fact that it can take a formula as a string at run-time. Formula has an input data-flow port called "formula". 

The Formula abstraction has to parse the formula string and then evaluate it. I used Roslyn to do this in a few lines of code. These lines of code took me a few hours to figure out however: 

.Formula.cs
[source,C#]
....

using Microsoft.CodeAnalysis.CSharp.Scripting;
using Microsoft.CodeAnalysis.Scripting;
using static System.Math;

namespace DomainAbstractions
{
    using LambdaType = Func<double, double, double, double, double, double, double>;

    public class Formula
    {
        public LambdaType Lambda { private get; set; }


        // Other code omitted from here


        private async void Compile(string formula)
        {
            var options = ScriptOptions.Default;
            options = options.AddImports("System.Math");
            try
            {
                Lambda = await CSharpScript.EvaluateAsync<LambdaType>(formula, options);
            }
            catch (CompilationErrorException e)
            {
                Lambda = null;
            }
        }
    }
}
....

As you can see, currently the Formula abstraction can only handle formulas that use a maximum of six parameters. The calculator application can use any number - it's just that any one formula is limited to using only six.

The rest of the code in the Formula abstraction is mostly dealing with this requirement of exactly six parameters used by LambdaType. But that's all internal to the abstraction. An instance of the Formula abstraction can handle any number of operands from zero to many. The Formula abstraction is also tolerant of the string on the formula input port being either just a formula such as "2*(3+1)" (implying it's not using any operand inputs), or a proper lambda expression such as "(x,y,z)=>x*(y+z).

Now that we have our needed domain abstractions, let's return to the application layer, and see if we can get this calculator running.


==== Hand wiring the appication code from the diagram

First here is the startup code for a wired ALA application. It is very simple:



.Application.cs
[source C#]
....
namespace Application
{
    public class Application
    {
        private MainWindow mainWindow;

        [STAThread]
        public static void Main()
        {
            Application app = new Application();
            app.mainWindow.Run();
        }

        private Application()
        {
            // mainWindow = WireHelloWorld();
            mainWindow = Calculator2RowHandWired();
        }
    }
}
....



Here is an ALA Hello World application


.Application.cs
[source C#]
....
private MainWindow WireHelloWorld()
{
    return new MainWindow().WireTo(new Text("Hello World"));
}
....

Ok, now we are ready to hand wire the hand drawn calculator diagram shown above:


.Application.cs
[source C#]
....
private MainWindow Calculator2RowHandWired()
{
    // To understand this code, you need the wiring diagram of the two row calculator

    // First instantiate instances of abstractions we need to give names to. The rest can be anonymous.
    StringConcat stringConcat = new StringConcat() { Separator = "," };
    DataFlowConnector<string> stringConcatConnector = new DataFlowConnector<string>(); // Connectors are needed when there is fan-out or fan-in in the diagram
    stringConcat.WireTo(stringConcatConnector, "output");
    Formula[] formulas = { new Formula(), new Formula() }; // instantiate both the formulas up-front because we need to cross wire them


    MainWindow mainWindow = new MainWindow("Calculator")
        .WireTo(new Vertical()
            .WireTo(WireRow(stringConcat, stringConcatConnector, formulas[0], formulas))
            .WireTo(WireRow(stringConcat, stringConcatConnector, formulas[1], formulas))
            );
    return mainWindow;
}


private Horizontal WireRow(StringConcat stringConcat, DataFlowConnector<string> stringConcatConnector, Formula formula, Formula[] formulas)
{
    // To understand this code, you need the wiring diagram of the two row calculator

    // first instantiate objects we need to give names to.  The rest can be anonymous.
    Text result = new Text(); 

    // Wire up a calculator row
    Horizontal row = new Horizontal()
        .WireTo(new TextBox()
            .WireTo(new DataFlowConnector<string>()
                .WireFrom(stringConcat, "inputs")
            )
        )
        .WireTo(new TextBox()
            .WireTo(new StringFormat<string>("({1})=>{0}")
                .WireTo(stringConcatConnector, "inputs")
                .WireTo(formula
                    .WireTo(new DataFlowConnector<double>()
                        .WireFrom(formulas[0], "operands")
                        .WireFrom(formulas[1], "operands")
                        .WireTo(new NumberToString()
                            .WireTo(result)
                        )
                    )
                )
            )
        )
        .WireTo(result)
        .WireTo(new TextBox());
    return row;
}
....


Commentary on this wiring code

* The code is written in "fluent style". This is possible because the WireTo extension method returns its 'this' parameter, allowing you to use .WireTo() multiple times on an instance.

* The parts of the diagram that have a tree structure can be wired by using more .WireTos immediately inside the brackets of another WireTo. This is what causes the indented code.

* The previous two points allow much of the wiring to be done without having to think up names for the instances. The instances are anonymous just as they were on the diagram.

* Where the diagram has cross wires that formed a cycle, we need to give instances names so that we can complete all the wiring to them.

* Sometimes the WireTo method is given the port name of the first object. These are used when WireTo may get the wrong port if it were left to use the port types alone. (If an abstraction has multiple ports of the same type, WireTo doesn't know which port to use.)

* Most abstraction have ports that can only be wired to one place, and ports that can only be wired from one place. (The UI abstractions are exceptions, for example, Horizontal can be wired to multiple children.) The hand drawn wiring diagram has several places where the wiring either 'fans out' from a port or 'fans in' to a port. Unfortunately C# does not support the concept of ports, so we improvise to make them work in normal C# code. The way this improvisation works for fan-in and fan-out is to use a connector.

** For fan-out you wire the output port to a new Connector. Then you can wire the connector to multiple places.

** For fan-in, the abstraction, instead of implementing the port, uses a list field of a type like IDataFlowB. The 'B" on the end means the flow of data is reversed from IDataFlow. Now to wire such an inputs port to an output port also requires a connector (a second use for connectors). When wiring an IDataFlowB, you wire from the input to the connector (the opposite way to the direction of data flow unfortunately). 

* As a convenience, you can use WireFrom. It reverses the two operands being wired compared to WireTo.


Handwritten wiring code like teh above can be managed for small applications. It is easy to get it wrong though. The code is not readable from the point of view of understanding teh application. That's what the diagram is for. So every time you make a change to the requirements, you need to do it on the diagram, then update the hand-generated code. You are still better off doing this than not using ALA. If not using ALA, the relationships shown in our explicit diagram still exist. You just go without the diagram, and your hand-generated code is obscured and distributed inside your modules. And you end up with lots of relationships between those modules that come from the implicit diagram.

But we don't have to hand generate code. At the time of writing a hand written graphical IDE is under development. 

Here is the calculator row part of the diagram, which was successfully used to auto generate code:


image::CalculatorRow-GALADE.png[CalculatorRow-GALADE.png, 800, title="CalculatorRow abstraction internal wiring"]

Before we had that tool, we used Xmind to do diagrams from which we could generated code. This is the approach described in the next section. 



==== Automatic code generation from the diagram

Here is the diagram of the 2-row calculator as it was originally entered into Xmind. You can click on the image to get a bigger version.

image::Calculator2Rows.png[Calculator2Rows.png, 1000, title="Calculator drawn in Xmind (two rows version)", link=images/Calculator2Rows.png]


Xmind is not the perfect tool to do this, but it has one huge advantage - it lays itself out. This is so important that it's why we use it (until our new tool is ready). We will put up with the disadvantages, and the necessary conventions until then. Those conventions are documented in the wiki section of the project in Github here: https://github.com/johnspray74/ReactiveCalculator/wiki[https://github.com/johnspray74/ReactiveCalculator/wiki]

Entering the hand-drawn version of the diagram is a simple matter of copying and pasting the Xmind templates for the abstractions to the right place in the diagram. This connects most of the needed wiring from port to port. Xmind supports tree structured diagrams, so any cross tree wiring was done by using the red lines, which are quick to put in with a shortcut key.

The Xmind version of the diagram is pretty much identical to the hand drawn version. The colored boxes are instances of abstractions. All the other nodes attached around those colored boxes are the ports. The < and > signs in the ports are significant, and tell the automatic code generator which way to wire the instances. The asterisks are also significant, and tell the code generator that many wires can be wired to the one port.

The diagram done, it's time to generate the code. A tool called XmindParser does this. It can be downloaded from the Github project main page. Here is the tool in use to generate a calculator from the diagram.

image::CalculatorXmindParserTool.png[CalculatorXmindParserTool.png, 800, title="XmindParser tool in use"]

The tool can put the generated code into your Application.cs file if you give it special markers like the one below.



.Application.cs
[source,C#]
....
private void Calculator2Rows()
{
    // BEGIN AUTO-GENERATED INSTANTIATIONS FOR Calculator2Rows.xmind
    // END AUTO-GENERATED INSTANTIATIONS FOR Calculator2Rows.xmind

    // BEGIN AUTO-GENERATED WIRING FOR Calculator2Rows.xmind
    // END AUTO-GENERATED WIRING FOR Calculator2Rows.xmind
}
....

The markers contain the name of the Xmind diagram they get code from. This allows several diagrams to be used for one application.

I usually put the markers inside a function so that all the instantiated objects are private to the function.

Here is the code again with three lines of generated code shown in each section.


.Application.cs
[source,C#]
....
private void Calculator2Rows()
{
    // BEGIN AUTO-GENERATED INSTANTIATIONS FOR Calculator2Rows.xmind
    Formula Formula1 = new Formula() { InstanceName = "Formula1" };
    Formula Formula2 = new Formula() { InstanceName = "Formula2" };
    Horizontal id_24914ab245484fe1b70af8020ca2e831 = new Horizontal() { InstanceName = "Default" };
    // END AUTO-GENERATED INSTANTIATIONS FOR Calculator2Rows.xmind

    // BEGIN AUTO-GENERATED WIRING FOR Calculator2Rows.xmind
    mainWindow.WireTo(id_b02d2caea938499b997b9bfcb80fb0e9, "iuiStructure");
    id_b02d2caea938499b997b9bfcb80fb0e9.WireTo(id_24914ab245484fe1b70af8020ca2e831, "children"); 
    Formula1.WireTo(dfc1, "result");
    // END AUTO-GENERATED WIRING FOR Calculator2Rows.xmind

}
....


Completing the diagram had taken another morning of work. But the calculator was now working and I was ready for the workshop.

I made a diagram with six rows, but it was getting pretty large, and the duplication was pretty clumsy.


==== Calculator with 10 rows

The 6-row calculator is powerful compared to any normal calculator, but still wouldn't do jobs like the one shown here which has 11 rows:

image::CalculatorNRowsScreenshot.png[CalculatorNRowsScreenshot.png, 800, title="Later version of the calculator to support an unlimited number of rows"]

So it was time to do some maintenance, and solve that problem of the repetition in the diagram at the same time. During this maintenance, none of the existing abstractions changed. Their ports stayed the same. Their internals were improved a little in some cases but nothing significant. Formula was modified internally so that it could handle more than six operand inputs, although any one formula can still only use six of them.

There were two major changes though. One was to put the repeated wiring for a calculator row inside its own abstraction. This abstraction is called "CalculatorRow". This abstraction is less abstract than the Domain abstractions it uses, but more abstract than the application, which will use it multiple times. Other version of the calculator alos reused it. So it goes into its own layer between the two. This new layer is called "Requirements Abstractions". We don't make new layers lightly, but we had had the experience in a larger project that the diagram got too large. We needed to factor out some of it as 'Feature level abstractions'. These abstractions needed a new layer between the Application layer and the Domain abstractions layer. So I was reasonably happy to make use of this new layer in the calculator to reduce a now quite large diagram.

Here is the Xmind template for the CalculatorRow abstraction showing its ports:

image::CalculatorRowTemplate.png[CalculatorRowTemplate.png, 800, title="CalculatorRow requirements abstraction"]


The implementation of CalculatorRow was done with a diagram using the new Graphical ALA tool which was shown earlier.


When you implement an abstraction by an internal diagram, there needs to be some extra code to wire from the ports (shown in the template above) to the internal wiring. I found this code quite tricky the first time and it took me a while. But there is a pattern to it. The new tool will be able to automatically generate this code as well, but for now I did it by hand.

I tested the completed CalculatorRow abstraction by making an application that uses it twice:


image::Calculator2ARows.png[Calculator2ARows.png, 1000, title="Calculator drawn in Xmind using the new CalculatorRow requirements abstraction", link=images/Calculator2ARows.png]

Because this test calculator has only two rows we can directly compare it with the 2-row calculator above and see how the two rows are now represented by two instances of this new CalculatorRow abstraction. However we are still not there to building a calculator with 10 rows. If we were to instantiate CalculatorRow 10 times, it would need 100 wirings in Xmind to connect all ten results to every rows input. Having thought the 36 wirings of the 6 row calculator was nuts, there was no way I was going to do 100 of them by hand.

So the next step was to invent a domain abstraction called 'Multiple'.

What 'Multiple' does is you instantiate it in your application and configure it with the number you want. In this case N:10. Multiple has a port called factory which uses a new interface called IFactory. Then what you do is add a small Factory class inside any abstraction that you want multiple instances of. In this case we want multiple instances of CalculatorRow, so I added a small class to that abstraction called CalculatorRowFactory. CalculatorRowFactory implements IFactory (which resides in the Programming Paradigms layer). Multiple can now create many instances of the abstraction that is wired to it. But these instances now have to be wired into the rest of the wiring in the application diagram as needed. To accomplish that, multiple is configured with two methods. These methods, which are part of the application, know how to wire the new instances into the rest of the wiring.

Here is the Xmind template for Multiple:

image::CalculatorMultipleTemplate.png[CalculatorMultipleTemplate.png, 500, title="CalculatorRow requirements abstraction"]

Using the new Multiple abstraction, we can now build a 10-row calculator. Here is the new diagram: 

image::Calculator10Rows.png[Calculator10Rows.png, 1000, title="Calculator drawn in Xmind using the new Multiple domain abstraction to create as many rows as we like", link=images/Calculator10Rows.png]

You can see inside the instance of Multiple that it is configured to make 10 of whatever is attached to its factory port. The CalculatorRow abstraction is shown next to the CalculatorRowFactory so you can see what it makes. You can see inside Multiple the two methods that Multiple calls when it makes a new instance. These methods are used to wire the CalculatorRow into the rest of the application wiring.

Getting to this point had taken another two Saturday mornings of work. It was mainly spent on thinking out the patterns for how the internal wiring inside CalculatorRow should get wired to CalculatorRows own border ports. Also in the initial attempt I had allowed temporal coupling to creep in between abstractions. It mattered whether the application wiring was done first. And if you let coupling creep in bugs will happen. The temporal coupling was resolved by making CalculatorRow not care whether or not the external wiring is done when it is instantiated.    

==== Calculator with N rows

Wouldn't it be cool if the calculator started with say 4 rows, and had a button for adding additional rows? You will notice that the Multiple abstraction template above has a port called addRow. It takes an IEvent. If it receives an event on that port at run-time, it will create another row and call the lambda wiring functions to get that row wired in.

Here is the calculator wiring with the button added to the UI. This is the calculator from which the screen shot shown above was taken.

image::CalculatorNRows.png[CalculatorNRows.png, 800, title="Later version of the calculator to support an unlimited number of rows"]

I wanted the Button to be at the bottom, so I added another instance of Vertical to act as the wiring point for new row to be attached to the UI. The output of the Button is another programming paradigm interface called an IEvent. 

Here is the source code of IEvent:

.IEvent.cs
[source,C#]
....
namespace ProgrammingParadigms
{
    public interface IEvent
    {
        void Execute();
    }
}
....

Again, considering that this interface enables a whole programming paradigm, it is extremely simple and abstract, consisting of only a synchronous function call. It allows any objects that can produce events to be wired to any object that can receive event. In the CalculatorNRows example, it allows a Button to be Wired to a Multiple. When the Button is pressed, Multiple creates a new row.  

There is one major Programming Paradigm that we have not explained yet. It is the one that allows UI instances to be wired together. The meaning of wiring two UI objects together is that one contains the other. Here is the IUI interface that implements this programming paradigm.

.IUI.cs
[source,C#]
....
using System.Windows;

namespace ProgrammingParadigms
{
    public interface IUI
    {
        UIElement GetWPFElement();
    }
}
....

The interface simply allows a containing UI instance to get the WPF (Windows Presentation Foundation) element from the contained UI instance it is wired to.

Making Multiple able to add rows to the calculator at runtime took yet another Saturday morning. But it was worth it to solve the challenge of learning how to change the wiring at run-time. The wiring diagram now statically describes how it dynamically changes itself.

That concludes the story of the development of the calculator using ALA. The full source code, and all the diagrams for every version along the way are in the Github project at
https://github.com/johnspray74/ReactiveCalculator[https://github.com/johnspray74/ReactiveCalculator]


// TBD why not use #defines?

== Chapter three - Why the structure works

In the previous chapter we described what the structure, the anatomy, of ALA looks like as if we were dissecting a dead body. We see where things are but we don't yet understand why they are there. In this chapter we explain why that structure works. Why does this way of organising code result in software that meets those non-functional requirements we listed in Chapter one?



=== A thought experiment

Imagine you are reading the following function, abc123, and trying to understand it:

 float abc123(float[])
 {
     ...
     b = xyz789(a)
     ...
 }

 float xyz789(float)
 {
     ....
     // complicated code
     ....
 }

You don't know what xyz789 is. It may as well be called fubar (fubar stands for messed up beyond all recognition), so you follow the indirection, an inconvenience at the least because you are really just wanting to understand abc123. You have to mentally stack where you were in abc123, including everything you understand about it so far. 

You begin reading the code at xyz789. It only has about 20 lines but it is complicated. A comment mentions that it uses a CORDIC algorithm and gives a reference. But before following that indirection as well, you note that xyz789 has the following properties:

* a module
* has a simple interface
* encapsulated
* uses nothing but what is in the interface
* no side effects
* hides information
* probably separates two concerns
* is small
* follows the coding guidelines
* has comments

Despite having all these great properties that we are taught that all software should have, we are forced to read both functions to understand the code. They are effectively fully coupled - understanding the code involves understanding the total code in the two functions.  

Now we will make a simple change that causes both functions to become abstractions. 


 float StandardDeviation(float[])
 {
     ...
     b = SQRT(a)
     ...
 }

 float Sqrt(float)
 {
     // complicated code
 }

Suddenly understandability is absolutely transformed! The code inside the each of the two functions goes from fully-coupled to zero-coupled. 

* In the downward direction, coupling goes to zero because the standard deviation function need only know the concept of the squareroot abstraction, not the code inside it.

* In the upward direction, coupling goes to zero because squareroot is more abstract and therefore can't know anything about the more specific Standard deviation abstraction above it. 

There are other benefits too:

* Abstraction and stability go hand in hand. The Sqrt abstraction is as stable as the concept of squareroot. That's a pretty stable concept. So, all dependencies in an ALA program are toward the more stable.  

* Abstraction and reuse go hand in hand (as poited out by Krueger). The more abstract abstraction on the bottom is reusable. Code reuse in this ALA programs increases markedly.  

The complicated code inside SQRT no longer matters. It is completely isolated by the abstraction. If your brain already knows the SQRT concept (I had to choose one that I knew you already knew), there is no need to follow the indirection when reading the code inside StandardDeviation. The reader just continues reading the next line of code after the Sqrt invocation as if Sqrt is just like any other line of code in their base language. That's what abstraction does.

All those other properties we listed above made no difference by themselves. That was because they all describe compile-time properties. They are still good to have, but they are insufficient. The abstraction property is the only one that works when our brain, and not the compiler, is reading the code. The quality of abstraction is subjective. Software engineers must invent good quality abstractions. No compiler or tool can check that quality, although, as Robert Martin points out, the number of reuses of an abstraction can be used as a measure.


With this new understanding, we will now define the word dependency to be compile-time relationships, and coupling to be the design-time or understanding-time relationships. One is what the compiler sees, the other is what our brain sees. 

Using these definitions, you can have coupling without dependencies (sometimes called implicit couling). But the reverse is also true - it is possible to have dependencies without any coupling. ALA makes use of this by simply making a constraint that we can only use this type of dependency. When you do that, every artefact (abstraction) in the program is zero-coupled with one-another. 

Doing this isn't always easy because unfortunately there are many established architectural methods, patterns and styles that break this constraint. On the other hand, applying this constrain emerges some patterns that we will immediately recognise. DSLs and dependency injection are two examples. We will also emerge some less well known ones that are none-the-less not novel. There already exists an "abstract interfaces" pattern, for example.

There are two situations that commonly cause coupling:

. In the above example, if xyz789 is just a source or destination for messages, then abc123 cannot be an abstraction because it cannot be reused without dragging xyz789 with it. abc123,as an abstraction, doesn't care where the data comes from or goes to. To fix this, xyz789 must be passed into abc123 by something else above both of them. This can be passing in a function, passing in an object (dependency injection), or other mechanism such as the WireTo operator that we will use a lot in our ALA example projects.
+
A benefit over and above the zero coupling is that the data flow relationship between abc123 and xyz789 used be hidden inside abc123. In ALA that relationship has to be an explicit line of code (inside another abstraction above) that wires together two instances. There, it will be cohesive with other similar relationships that work together in a collaborative way to make the application. 
+
Often these collected together wirings form a graph, making diagrams rather than code an even better way to describe the application.

. If xyz789 provides a part of the implementation of abc123 such that it is specific to abc123, then xyz789 is more specific than abc123. This is because abc123 could be reused many times, whereas xyz789 could only ever be used once (only by abc123). xyz789 needs to be more abstract than abc123 or it will be coupled to it.
+
This is contrary to what we are taught. We are taught to "divide and conquer" or to separate out the responsibilities in abc123. If we do this arbitrarily, we will end up with specific pieces (such as UI and business logic) which are highly coupled with each other, and with the specific application. We need to work hard to separate only by finding abstractions - potentially reusable artefacts. Then we configure instances of those abstractions for each specific use by passing application details into them.  

In summary, ALA's starting premise is a constraint. The constraint is that you can only use one type of dependency - a dependency on an abstraction that is more abstract. This results in zero coupling throughout the abstractions of the entire program. 

The rest of this chapter expands on the points we mentioned briefly in this first section. 

=== Abstractions are design-time encapsulations

[IMPORTANT]
====
*Abstractions* are the human brain's version of *encapsulation*.
====

The maintainability quality attribute is often thought of in terms of ripple effects of change. I don't think that is quite the right way to look at it. I have often had to make changes across a number of modules in poorly written code. The changes themselves just don't take that long. The problem I see is the time you have to spend understanding enough of the system to know where to make a change, even if it is one line of code. To make that small change with confidence that it wont break anything can take a long long time. The problem, in short is coupling. Even if the change is one line of code (which it often is), you may have had to understand a lot of code to figure that out. You have to understand all the code that is potentially coupled to that one line of code, which is essentially the complexity.

Unlike modules or encapsulation, abstractions contain and hide complexity at design-time. They give boundaries to how far you have to read code to understand code.


==== Abstractions and Instances

[IMPORTANT]
====
All *software architectures* should contain *two concepts* for its *elements*  equivalent to *abstractions* and *instances*.
====

ALA makes abstraction and instances fundamental. 

Abstractions are separate, zero coupled, design-time elements. Abstraction, therefore, cannot exchange data themselves. The concept of instances must be added. An instances is nothing more than the use of an abstraction by referring to its name. 

Object oriented programming does has these two concepts in classes and objects. Functional programming has the two concepts in terms of the function definition and the function invocation. But many discussions on software architecture seem to combine them into one term, such as modules, components or layers. They may implicitly contain the separate concepts, as components may, but not having them explicit will inevitably lead to confusion. 

The problem is that when we become vague about the difference, we will create dependencies, such as to get or put data, between abstractions that should just be using two instances in a line of code somewhere. Adding dependencies between abstractions destroy them as abstractions. Composing two Instances of abstractions does not. If we don't have two separate and clear terms for abstractions and instances, we will end up with no abstractions.  

Nearly all architectural styles have this problem. For example, in layering, we put 'modules' into layers and then create unnecessary dependencies to move data between them. No, put abstractions into one layer. Then compose instances of them inside a new abstraction in the layer above to get the instances talking to each other.  

Another common example of the problem is the UML, which already has the separate concepts of objects and classes. But we tend to ignore objects and create associations between classes instead. The most important idea that OOP brought us was the idea of classes and objects. It has been ruined by the UML. Instead of associations between classes, instantiate objects and wire them together. Do that completely inside another class in the layer above. 


=== Good versus bad dependencies

We can distinguish two types of dependencies. One is run-time dependencies. These are dependencies in the code that are there because one module will need another module to be present at run-time for the system to work. The other is design-time dependencies. These are dependencies on the knowledge you must have to even understand a given piece of code. I will often refer to this type as a "knowledge dependency" or "use of an abstraction". It is also sometimes called "semantic coupling".

 
[WARNING]
====
[red]#*Run-time dependencies are bad*#.
====
[TIP]
====
[green]#*Design-time knowledge dependencies on abstractions are good*#.
====

A simple example of a run-time dependency is a module that calculates the average rainfall then calls a display module to display the result. The Display module needs to be present at run-time. But to understand the code that calculates the average rainfall requires no knowledge about displays, nor even where the result will be sent. The dependency is only there to make the system work at run-time.

A simple example of a design-time knowledge dependency is some code that calculates the average rainfall. It uses an abstraction that takes a data stream as input and outputs a running average. To understand the rainfall code needs knowledge of averaging filter. This is a design-time, or knowledge dependency. Any application needing to reduce data to an average could use the same abstraction. 

We find both types of dependencies in conventional code. A typical program is chock full of the run-time dependencies. But whether a knowledge dependency or a run-time dependency, they all just look like a function call or a 'new' keyword. We generally don't distinguish between them. In fact we are not normally taught to tell the difference. They are all just called dependencies. We lump them together when we talk about dependency management, loose coupling, layering, fan-in & fan-out, or circular dependencies. Dependency graphing tools just show them both. 

These two different types of dependencies are not just good and bad. They are really good and really bad. So it's doubly important that we learn to tell the difference. What's more it's entirely possible to build a system using only the good dependencies. 

A knowledge dependency is good because it's only dependent on an abstract concept. Abstractions are easy to learn. The more dependencies you have on an abstraction, the more abstract it is,and the more reuse you are getting.

Run-time dependencies are bad because they completely destroy abstractions. They are bad because they cause explicit and implicit coupling. And they are bad because they obscure the structure of the application by distributing that structure throughout its modules. Instead, we want that structure to be explicit and in one place.

[TIP]
====
[green]#*In ALA we eliminate all run-time dependencies*#.
====

Consider the diagram below:

[plantuml,file="dependency-diagram.png"]
----
@startditaa --no-separation --no-shadows --scale 1.1
Application



/----\     /----\     /----\     /----\     /----\
| A  |     | B  |     | C  |     | D  |     | E  |
|ADC |<----|Avg |<----|Conv|---->|Accu|---->|Disp|
|    |     |    |     |    |     |    |     |    |
\----/     \----/     \----/     \----/     \----/


key:   <----(Depends On)


@endditaa
----

There are four run-time dependencies.

Now consider this diagram.


[plantuml,file="dependency-diagram-1.png"]
----
@startditaa --no-separation --no-shadows --scale 1.1

       /---------------------------\
       |Application                |
       |                           |
       | A --- B --- C --- D --- E |
       |                           |
       \---------------------------/


--------------------------------------------------
Abstractions

/----\     /----\     /----\     /----\     /----\
| A  |     | B  |     | C  |     | D  |     | E  |
|ADC |     |Avg |     |Conv|     |Accu|     |Disp|
|    |     |    |     |    |     |    |     |    |
\----/     \----/     \----/     \----/     \----/


--------------------------------------------------
Programming Paradigms

                    /---------\
                    |         |
                    |IDataflow|
                    |         |
                    \---------/
@endditaa
----

There are five knowledge dependencies (the top layer uses five abstractions in the second layer), but no run-time dependencies (because the connections between the instances are completely inside another abstraction).

The letters used in the top layer represent instances. (In UML they would be underlined.) You never draw arrows for knowledge dependencies - only ever refer to the abstraction by its name. (Just as you would never draw an arrow to a box representing the squareroot function - you would just use SQRT by its name.)

In common programming languages, the run-time dependencies in the first diagram and the knowledge dependencies in the second diagram are both syntactically written in the same form, either new A() or just a function call, A(). The only difference is in where those function calls or new keywords are. This simple change makes a huge difference in the quality of the code.



==== Comparison of good versus bad dependencies.


.Comparison of two approaches
[width="100%",options="header,footer"]
|====================
| Run-time dependencies version | Knowledge dependencies version
| Knowledge about the specific application is spread through all modules. | Knowledge about the specific application is only in one place. The abstractions no nothing of each other or the specific application. 
| The class or function names A, B, D and E will relate to what they do (which is fine). For example, they may be the specific hardware chips used in the case of drivers. The calling module must know these names, creating a fixed arrangement between the modules. The modules are loosely coupled. | No peer abstractions refer to these names. There is no fixed arrangement between abstractions. Abstractions are zero coupled. The code that knows that a particular hardware chip is used in this application is where it belongs, in the application code.
| Since there is a fixed arrangement, responsibilities can be blurred. For example, it may be unclear whether to add something to B or C. Or C can make assumptions about details in B, causing collaborative coupling. | With no relations between abstractions, responsibilities are clear. Something to be added clearly belongs in one or other of the abstractions, or in a new abstraction. C cannot make any assumptions about some details of B. It cannot have collaborative coupling with B 
| Although there is no explicit dependency from, for example, B to C, the fixed arrangement is likely, over time, to make B implicitly collaborate with C (do what C requires), resulting in implicit coupling. | No implicit coupling can develop over time because there is no relationship between them. B cannot collaborate with C (do what C specifically requires), or have implicit coupling with C.
| The arrangement between A, B, C, D and E is not obvious in the code. It is buried inside of B, C and D. | The arrangement between instances of A, B, C, D and E is explicitly coded in one place.
| Only A and E can potentially be abstractions. | All of A, B, C, D and E are abstractions.
| Arbitrarily, only the two ends of the data flow chain can be reused independently . | All of A, B, C, D and E are independently reusable.
| Difficult to insert another module between, say, B and C. | Easy to insert a new instance of some operator between B and C, etc. 
| If the observer pattern is used (in the mistaken belief that it reduces the coupling), it only mirrors the same problems. For example B would now have a dependency on C when it registers. But because it adds indirection, the observer pattern makes the program even harder to understand. | If the observer pattern is used (as the means to implement the wiring between the instances), the receivers do not do the registering, the application does (not strictly the observer pattern). The abstractions themselves don't get more difficult to understand because, being abstractions, they only have knowledge as far as their interfaces anyway. The application does not get harder to understand either. The arrangement of the instances is still explicitly and in one place.
| If dependency injection is used with automatic wiring, the arrangement is still somewhat fixed, but is now even more obscure. All classes can still be collaborating with one another. A smell that this is happening is that over time the interfaces, IA, IB, ID and IE change as the requirements of the system change.  | If dependency injection is used, the application does the wiring explicitly. It is the only place that should know who will talk to whom at run-time for this specific application. There are no specific interfaces between pairs of modules to change over time, because they all just use a stable abstract interface.  
| Each module has its own interface. But they are all doing essentially the same thing, getting data. | Uses a single more abstract interface called IDataflow.  
| The arrangement between the modules cannot easily be changed, both because the wiring code is buried inside the modules and because the interfaces are essentially specific to pairs of modules. | The composition can very easily be changed. Instances of abstractions can be re-wired in any combination.
| There is no diagram of the arrangement between A, B, C, D, E, or if there is, it is likely a high level overview, lacking in detail, and a second source of truth that gets out of date. | There is a diagram. It is the one source of truth. It includes all details about the specific application.
|====================


During code creation, run-time dependencies are easily introduced, and never seem too terrible at the time. But when they accumulate to hundreds or even thousands of them, as they do in most typical applications, that's when the system, as described on the left side of the table, just appears as a monolith.

==== Notes

The application level module either moves the data between the instances of A, B, C, D, E itself, or wires them together using the even more abstract interfaces, such as the one shown called IDataflow. These abstract interfaces are not specific to any of A, B, C, D or E. This is the abstract interactions pattern. The interface design is such that there could potentially be many abstractions that implement it or accept it, or both.

If dependency injection is used, I prefer not to use XML for the explicit wiring. XML is not very readable, and it only handles tree structures. If you must use text, use normal code. But there are situations where a diagram is the only readable way to go. I will go into these in a later section.

When you are comparing the left and right sides of the table above, you may be wondering, where did the free lunch come from? Where did the runtime dependencies go? Is this some kind of magic? How can the program work without them? Or haven't I just moved them somewhere else? No there are no tricks. The answer is that we have been taught to do programming in a very bad way. The knowledge that A will talk to B, B to C etc is there, but it is now in ordinary code, not as dependencies between anything. They are no longer dependencies because that code is fully contained in one place, inside a single new abstraction. Doing this makes a huge difference to any code. If you haven't yet got your head around this, keep reading because we will present the same insight in other ways.

The only dependencies we have used on the right side of the table are knowledge dependencies: 

. The application should and must 'know' at design-time what abstractions it needs to compose to make a specific application.

. The domain abstractions should and must know what kind of abstract interfaces to use for its inputs and outputs. 

==== No loose coupling

Since our conventional programs are typically full of coupling of all sorts, this constraint on the architecture will obviously change how we write programs significantly. But surprisingly, things quickly get easier, not harder with these constraints, a lot easier.

When we say _no_ loose coupling, it means there is _zero_ coupling. Zero coupling between the details contained inside any two abstractions. Abstractions are therefore free floating little independent programs. To understand any part of the code involves understanding only that part of the code.

[TIP]
====
[green]#*To understand any part of the code should involve understanding only that part of the code.*#.
====


==== Knowledge dependency layers

The one type of dependency allowed is when you use an abstraction.

The code inside an abstraction in a higher layer makes use of an abstraction from a lower layer.  

We call it a knowledge dependency because to understand the code in the higher layer, you must know about the abstraction. You don't have to know about the details inside the abstraction, you just need to know about the abstraction. This is the way the world works and the way our brains have evolved to make sense of it. And it's the way we need to structure our programs.

When we write our programs using only knowledge dependencies, all the knowledge needed to understand a piece of code is explicit. It is right there in any function calls or new keywords. There is no knowledge needed from anywhere else, because there is no implicit coupling. 

In ALA, knowledge dependencies form the layers. There are no run-time dependencies present, so that is why the ALA layers are significantly different from the layers you would normally find in a program trying to use the layering pattern. 


The bottom layer is your general purpose programming language. You must know its abstractions such as if-else statements before you can understand any layer above. You can generally learn this once for a whole career.

You also need to know the next layer, which is at the abstraction level of programming paradigms. Examples are data-flow, state machines, database schemas, and UI trees. You would generally learn these as needed for different programming problems. A given domain will typically make use of several of them.

You also need to know the next layer, the domain layer where you have useful building blocks for solving problems in a specific domain. You would learn these when you start a new job.

Finally we come to the top layer. Its abstraction level is a single application. The abstraction is what the user sees - a tool that does a job by meeting a set of requirements. The abstraction level of the top layer is the details of the requirements.

To get the insight of ALA, you need to throw away any previous conceptions of layering you may have had as these will contain run-time dependencies. Think of run-time dependencies as just wiring in the top layer, tipped on its side.

==== Stability of dependencies.

Because all dependencies used in ALA are just 'uses of abstractions', dependencies are always toward the more stable. Even if the implenetation details inside an abstraction change, the abstraction itself stays stable, because an abstraction is just an idea. ALA therefore naturally conforms with the Stable Dependencies Principle (depend in the direction of stability) and the Stable Abstractions Principle (Entities should be as abstract as they are stable). 

==== Dependency fan-in and fan-out

One of the guidelines sometimes used for dependencies is that a class that has high fan-in should not have high fan-out. The argument goes that a class with high fan-in should have high stability but one with high fan-out would have low stability (presumably because dependencies are thought to be things that cause changes to propagate). Knowledge dependencies, becasue they are on abstractions do not have this property. An abstraction is something that insulates its dependants from its internal details. In ALA, it is perfectly fine, in fact really really good if a class in the middle layer can indeed have both high fan-in and high fan-out. It simply means that it is both useful to its users in higher layers, and making use of even more abstract things in lower layers. 

If you think about your programming language as the bottom layer (on which everything depends), every reusable class you write has both high fan-in and high fan-out. This meme that not having high fan-in and high fan-out for the same class does not apply to knowledge dependencies. And if you apply it to run-time dependencies, what the meme should say is zero fan-in and zero fan-out.

==== Circular dependencies

Of course in ALA, with only knowledge dependencies present in the system, and the abstraction layering being formed from them, you obviously cannot have circular knowledge dependencies. Nor would that even make sense. (Well actually it can make sense when we use knowledge recursion, in the same way that a mathematician might use recursion to define something. We will visit that in the last chapter.) 

Since there are no run-time dependencies, the issue of circular dependencies with them does not arise at all.

But let's just take look at the wiring that we create inside the application. (This is the wiring up of instances of abstractions to make a composition.) Can this wiring be circular? Yes it can, with the proviso that the execution model handles the execution of it in the way you intend. The execution model is a completely different story and is covered in the next section. In principle it is absolutely fine to have circular wiring. The electronics guys could not do without it - they call it feedback. And programs need it too. So why use a programming system that makes it awkward by constantly having to breaking the circle somewhere so there is no circle at at compile-time, but allowing the circle at run-time? ALA simply eliminates all that non-sense. 

That concludes our discussion on why the ALA structure works from the point of view of good and bad dependencies.


=== Expression of requirements

We have previously discussed this aspect of ALA in terms of structure. It is the top layer. And we have used this aspect as the starting point in the method to develop the example projects. But why does the succinct description of requirements in that top layer work?

In conventional software development, we typically break a user story (or feature or functional requirement) up into different implementation responsibilities. For example, layers like GUI, business logic and database, or a pattern such as MVC (Model, View, Controller). But a user story or feature actually starts out as cohesive knowledge n the requirements. And its not a huge amount of cohesive knowledge, so it doesn't need breaking up. Cohesive knowledge, knowledge that is by its nature highly coupled within itself should be kept together. All we need to do to keep it together is find a way to describe it so that it is executable. Don't try to do any implementation, just get it described in a concise and complete form. If you can do that, the chances are you will be able to find a way to make it execute. 

In ALA we want to find a way to express the user story with about the same level of expressiveness as when the user story was explained in English by the product owner. The language he used would have contained domain specific terms to enable him to explain it concisely. The same thing ought to be possible in the code. Anything that does not come directly from the requirements and starts to look like implementation detail is separated out. It comes out into abstractions. These abstractions typically contain knowledge of how user stories in general are implemented - how things can be displayed, how things can be saved, how data can be processed.

It turns out that abstractions that know how to implement useful things for expressing user stories are not only reusable for different user stories, but can be reusable for other applications. In other words, they are domain level abstractions. A typical user story might be composed of several of them, some to implement the user story's UI, some to implement the user story's business, and some to implement the user story's saving of data. A user story instantiates the abstractions, configures them with the specific knowledge from the requirement, and then wires them together.

Most maintenance is probably changing, adding or fixing user stories or features. When those features are described entirely in one place instead of distributed through a lot of modules, you have a direct understanding of how the user story is represented by code, and therefore of how to change it or fix it.

Of course application code makes heavy use, in fact is entirely composed of, instances of domain abstractions. When fixing a bug, it quickly becomes clear if the application code itself doesn't represent the requirements as intended, or one of the abstractions is not doing its job properly. Again the maintenance is easy.







=== Composition versus decomposition

Here we revisit the important idea introduced in section 2.6 to do with the pitfalls of thinking in terms of hierarchical decomposition. 

In decomposition methods, we are taught to decomposes the system into smaller elements or components with relations between them. Then decompose those into still smaller ones. The process continues until the pieces are simple enough to understand and implement. Each decomposition is completely contained inside its parent component, so it forms a fractal or hierarchical structure.  

[WARNING]
====
[red]#*Decomposition*# of the [red]#*system*# into [red]#*elements*# and their [red]#*interactions*#.
====

The decomposition approach is often the de facto or informal method used by developers because it is encouraged by many architecture styles and patterns, for example components or MVC. It is the method used in ADD (Attribute Driven Design). Indeed some definitions of software architecture sound like this meme:


* From Wikipedia quoting from Clements, Paul; Felix Bachmann; Len Bass; David Garlan; James Ivers; Reed Little; Paulo Merson; Robert Nord; Judith Stafford (2010:
+
 "Each structure comprises software elements, relations among them, and properties of both elements and relations."

* IBM.com
+
 "Architecture is the fundamental organization of a system embodied in its components, their relationships to each other, and to the environment, and the principles guiding its design and evolution. [IEEE 1471]

* synopsys.com
+
 "Architecture also focuses on how the elements and components within a system interact with one another."

* From an article on coupling by Martin Fowler  https://www.martinfowler.com/ieeeSoftware/coupling.pdf
+
 "You can break a program into modules, but these modules will need to communicate in some way‚Äîotherwise, you‚Äôd just have multiple programs."

* Loose coupling and high cohesion

Is loose coupling the best we can do? We are told that modules or components must collaborate in some way. It seems reasonable and even self-evident. So why is it completely wrong? It's becasue we are thinking in terms of decomposition. There is another way - composition.

To be fair, some of the examples above are vague enough to be interpreted in either way. But all are misleading in that they are suggestive of the idea of decomposition.

To fix the problem, we should re-word the meme:


[TIP]
====
[green]#*Expression*# of the [green]#*requirements*# by [green]#*composition*# of [green]#*abstractions*#.
====

All four big words are changed and some are exact opposites. Indeed, the architecture that comes out of this method is "inside out" when compared to the decomposition method.

Let's contrast two pseudo-structures: one that results from the decomposition approach and one that results from the composition approach. 

==== Decomposition of the system into elements and their interactions

This diagram shows a decomposition structure. The outer box is the system. It shows decomposition into four elements, and then those in turn are decomposed into four elements each. 

image::Slide11.jpg[Slide11.jpg, title="Decomposition Structure", align="center"]

The outer elements correctly only refer to the outer interface of the components - their package or namespace interface, facade, or aggregate root - however you want to think of it. Encapsulation is used at every level of the structure to hide implementation details.

The elements are labelled with numbers to emphasise that they are not good abstractions. Of course, in practice these elements have a name. 

The next diagram shows the same structure but with parts relevant to a user story marked in red. This is the "their interactions" part of the "The decomposition of your system into elements and their interactions".

image::Slide13.jpg[Slide13.jpg, title="Tracing a User story", align="center"]

The diagram shows both decomposition relationships (boxes inside boxes) and interaction relationships (lines).

==== Expression of the requirements by composition of abstractions

This diagram shows a composition structure. 

image::Slide14.jpg[Slide14.jpg, title="Composition Structure", align="center"]

Only 'composition' relationships are present. We have shown some of them as lines even though you wouldn't normally draw them. For example, the one from [underline]#c# to C. In practice we wouldn't normally draw a diagram like this at all - the abstractions would be just referred to by name. But here we are trying to make a combined diagram of the meta-architecture and the specific architecture. The meta-architecture is the three layers, and the knowledge dependencies that go from the higher layers to the lower layers. The specific architecture consists of the diagrams inside the user stories in the top layer, the specific composition of instances.

Note that although we use lines in the diagrams in the top layer, those lines do not represent dependencies.


==== Comparison of the two approaches

.Comparison of Decomposition vs Composition approaches
[width="100%",options="header,footer"]
|====================
| Decomposition | Composition
| image:Slide13.jpg[Decomposition structure, title="Tracing a User story", align="center"] | image:Slide14.jpg[Decomposition structure, title="Composition Structure", align="center"]

|Hierarchical (fractal) structure |  Layered structure

|Elements become less abstract as you zoom in. They are specific parts of specific parts. They have no use in another part of the decomposition. | Parts become more abstract as you go down the layers. They are reusable in many parts of the application.  

| Elements have no use in another part of the application. | Elements are reusable in many parts of the application.  

| Hides details through encapsulation, which works at compile-time. | Hides details through abstraction, which works at design-time.

| Encapsulates abstractions | Encapsulates instances of abstractions.

| Inner parts are increasingly private. They are encapsulated in increasingly smaller scopes. These private parts still need to be known about at design-time to understand the system  (unless they happen to also be good abstractions). | Lower layers are increasing public. Only the abstractions themselves are needed to understand the system.

| Dependencies go in the direction from the outermost element to the innermost. This is the direction of less abstract and therefore less stable. | Dependencies go down the layers. This is the direction of more abstract, and therefore more stable.

| Dependencies also exist between parts at the same hierarchical level | There are no dependencies between abstractions at the same layer.

| Encourages the same element to be used for both abstraction and instance - often called a module or component. | Clearly has two distinct types of elements - abstractions and instances.

| Elements are loosely coupled. | Abstractions are zero coupled.

| Discourages reuse. 16 elements all different from each other. | Encourages reuse. Only 5 abstractions. 16 instances of those five abstractions. 

| SMITA - Structure missing in the action. If you are interested in a particular user story, you will typically have to trace it through multiple elements, multiple interfaces, and their interactions across the structure. An example of this is shown by the diagram with the red lines. | Eliminates this problem. The structure is explicit and in one place.

| Coupling increases during maintenance. This is because details are not hidden inside abstractions, only encapsulations. Any of them can be needed at any time by an outer part of the structure. So as maintenance proceeds, more of them will need to be brought into the interfaces, increasing the coupling as time goes on. | Coupling remains at zero during maintenenace. Abstractions represent ideas, and ideas are relatively stable even during maintenance. All the dependencies are relatively unaffected.  An operation called generalizing an abstraction is sometimes done. This increases the versatility, reuse and ubiquity of abstractions over time. 

| Complexity increases as the system gets larger. | The complexity stays constant as the system gets larger. Each abstraction is its own stand-alone program. If we choose an ideal granularity of say 200 lines of code, the complexity in any one part of the program is that of 200 lines of code.  

| The maintenance cost (effort per user story or effort per change) increases over time. This is because complexity is increasing. Changes will tend to have ripple effects, but that isn't the biggest problem. Even if a change ends up being in one place, reasoning about the system to determine where that change should be can require reasoning across the system. | The maintenance cost reduces as the system grows. This is because as the domain abstractions mature, the user stories become less and less work to do - they simply compose, configure and wire together instances of existing domain abstractions.  
|====================


==== Transforming a decomposition structure into a composition structure

* The structure turns inside out. Abstractions are found in the inner-most encapsulations. These are brought out to be made public, reusable, ubiquitous and stable at the domain abstractions layer.  
* The parts of the inner encapsulations that are specific to the application are factored out to become configuration information in the application layer, which it uses when instatiating abstractions.
* Dependencies that existed between encapsulated elements for run-time communications are eliminated. They become simple wiring up of instances inside the application. 


==== Smells of decomposition

* Hierarchical diagrams

The tell-tale sign that this is happening is when we draw hierarchical diagrams. Boxes contained inside boxes. Even if we don't draw them that way, the 'containment' or encapsulation is still implied. This is what package and component diagrams do. ALA has no use for package diagrams in the logical view. (However, they are still relevant in other views. There are several good reasons to have separately deployable binary code units such as exes or dlls.)

* The dependency graph has many levels

If you have avoided circular dependencies, your application can be viewed as a (compile-time) dependency graph. Because it has run-time dependencies, it will have many 'levels'. These are not the hierarchical encapsulation levels, but just the strings of run-time dependencies within each level. In a composition system, the dependency graph will have a low number of layers.  

* Encapsulation without abstraction

Encapsulating details without an abstraction causes module or component boundaries to look relatively transparent at design-time. Their interfaces will tend to be specific to pairs of modules, and will tend to get increasingly wide as the software life cycle proceeds.

* Modules have responsibility for who they communicate with

Either the sender knows who to send messages to, or, if using publish/subscribe, the receiver knows who to receive messages from. Understanding the system requires reading inside the parts to get the interconnection knowledge.

* Compile-time indirection

If you find yourself doing many 'all files' searches to trace the flow of data or execution, this is a decomposition smell. The connections between the decomposed elements are mostly in the form of direct function calls or new keywords, and the name of another module. You have to find all these symbolic connections to trace through the system. In a composed structure, these connections are just adjacent elements in the text, or lines on a diagram. In both cases they are annonymous.

* Run-time indirection

To avoid circular dependencies, many of the Compile-time indirections would have been changed to run-time indirections. This is often done using observer pattern of automatic dependency injection. 

There is a meme that says something to the effect that such indirection is a two edged sword. On one hand it reduces coupling but on the it makes the structure even harder to see than it was when you has 'all files' searches. You may have to resot to a run-time debugger to see where the bugger goes next. At first this seems reasonable. It seems that you must always have this compromise between explicit structure and loose coupling. However it is just a result of decomposition., and unnecessary.

[TIP]
====
In ALA, there is no conflict between indirection and an explicit structure.
====

In a composition structure, at the top layer, all the structure is explicit in the form of the wiring. This is where all the design-time knowledge about the interactions between instances belongs, and where you can trace messages through the system at design-time with neither 'all files' searches, nor a debugger. When a message is processed by an instance of an abstraction, you know what that abstraction is supposed to do. You can tell if an issue is in the application or if an abstraction is not doing what is expected of it. 

When you drop down inside an abstraction, you are now in a different program, bordered by its inputs and outputs. You don't need to know where the execution flow goes outside its I/O ports to understand how it works because an abstraction has no knowledge of anything outside. If the abstraction calculates the squareroot and doesn't do it correctly, you only need to debug to its interfaces.

=== Diagrams vs text

The fundamental rules of ALA don't prescribe the use of diagrams. But diagrams often emerge.
So why do we often use a diagram instead of text in the application (top) layer of an ALA application?

It's because in any non-trivial program, there is structure inherent in the requirements that forms a graph. If you have UI that graph is a tree - still representable with indented text. But the UI must have connections. (These particular connections are often called bindings.) They need connections with data. They need connections with event handlers. These connections must be done symbolically if using text. The connections go further. There are connections to business logic and to some form of persistent data model, and from there to real databases or files. There are arbitrary connections for navigating around different pats of the UI. If text, most of these connections must be done symbolically. On the way, they may need to connect arbitrarily with things that process, reduce, or combine. There may be states involved, with arbitrary transitions needed between those states. There may be activities that have to happen in a prescribed time sequence, which by itself is representable as a linear instructions in text. But there are often loops or alternative routes through the sequence, which is representable as indented text. But then there is always some connection between the activities and some data or the outside world. If text, these connections must generally be done symbolically. 

All these connections are inherent in the requirements. Like or not, they form a graph. And this graph structure is somewhere in your code.

As we said, in text from, this graph needs to use at least some symbolic connections. That is, we can represent some of the graph with indenting and judicious use of anonymous functions or classes, but in general we will need to represent many of the connections by using names of variables, functions or objects.

This is bad enough. In fact this is already really, really bad compared with how the electronics guys do things.

But it gets much worse. In most conventional code, we take all these symbolic connections and distribute them evenly through the files/modules/classes/functions. Now the graph is totally obfuscated. The graph is highly cohesive. Why do we make it harder for ourselves by breaking it up?

But it gets much worse. Graphs have circles in them. There is nothing wrong with that, it's inherent in the connections in the requirements. But circles are at odds with dependency rules. So now what we do is break the cyclic dependencies using principles like dependency inversion or observer pattern. The connections don't go away. We just further obfuscated them. These connections are now done at run-time by code written somewhere else. This is the so called indirection problem.

What a mess we have got into!

ALA tells us how to fix this entire mess. It's really quite simple. ALA breaks up your application by factoring out abstractions. When you have done that to the maximum extent, what's left behind is nothing but the specifics of the requirements, including that (highly coherent) graph.

Now you can choose to go ahead and represent that graph in text in one place, using many symbolic connections, and you would already be way, way better off than how we write conventional code. But even better is to do what the electronics guys do, and just build the tools to handle the graphs as diagrams properly.

==== Diagrams and text are not equivalent


Diagrams and text are sometimes thought of as equivalent - and it's a matter of personal preference which you use. I do not agree with this. From the point of view of how our brain's work best, they are different, and each is powerful at its own job.

Consider an electronics engineer who uses a schematic diagram. Ask him to design a circuit using text and he will think you a simpleton. Electronics naturally has a network structure that is best viewed and reasoned about as a diagram. If you turn a diagram into a textual list of nodes and connections, the brain can no longer work with it directly. It is constantly interrupted to search for symbolic references when it should be free to just reason about the design. 

Most software naturally has an arbitrary network structure. Think about whenever you are working with legacy code - how often to you need to do "all files searches" or "find all references". And even those are foiled by indirections. Try designing or reasoning about a state machine without using a diagram.

Text can readily be used to compose elements in a linear chain or sequence. It is excellent for telling stories. White space is the normal connector between the elements. Sometimes periods or other symbols are used instead. Text can also handle shallow tree structures, simply by using indenting. Compilers may use brackets, usually () or {}. Interestingly, the brackets work for the compiler, but not for the brain. The brain doesn't see them, it just sees the indenting. So I personally don't agree that Python's significant indenting is a mistake as many do. 

When the tree gets deep, the indenting is too deep for our brains to follow. So text is only suitable for linear structures and shallow trees. Structured programming and XAML are examples of tree structured code represented successfully in text.

Text becomes troublesome when there are arbitrary connections across the structure forming a mesh. It must be done with matching names, labels or identifiers. Most imperative programs are actually not a tree structure because of the variables. They must be done with labels. Local variables in a small scope are not too much of a problem. It only requires an editor that highlights all of them. For large scopes we end up spending too much time finding and trying to remember the connections, resorting to many all-files searches. It is a cumbersome way to try to reason about what is usually a simple structure when viewed as a diagram. 

(When we talk about labels, we are talking about labels that are used for connecting two or more points. These labels are not abstractions. References to the names of abstractions are absolutely fine, and we don't draw lines for them even if we are using a diagram. We just use a box with the abstraction name inside it.)

When we need to compose instances of abstractions in an arbitrary network structure, our brains work much better using a diagram. The brain can readily see and follow the lines between the instances of the abstractions. Unlike with text labels, the lines are anonymous, as they should be. Lines don't need encapsulation. To understand all uses of a variable in text, we need an encapsulation scope. To understand all places connected by a line, the brain just sees all the lines instead. Generally lines connect only two points or ports, but sometimes may connect three or four. More than that, and it starts to smell as if a new abstraction may be waiting to be discovered. The spacial positioning of elements is also something the brain readily remembers. So, diagrams can qualitatively do things that text simply cannot.

ALA does not require a diagram per se. It only requires abstraction layering, and it's quite possible for a user story to just consist of a linear sequence of abstracted operations. For example, a sequence of movements by a robot or a "Pipes and Filters" sequence of operations on data. However, ALA is polyglot with respect to programming paradigms because user stories will generally combine multiple programming paradigms: UI, event-flows, data-flows, state machines, data schemas, etc. These aspects of a user story tend to be naturally interrelated (inherent in the requirements), which is what causes the resulting relationships among its instances of abstractions to be a network. Diagrams, then, embrace the bringing together of all these different interrelationships of a user story in one place and view.   


==== Diagramming tools

The ALA design process (which is describing your requirements and inventing the needed abstractions as you go) is an intense diagram generating activity, especially the first time in a new domain. It requires all your focus. I have found that hand drawing the diagram on paper is not good. The diagram quickly gets into a messy state which requires redrawing, and that interrupts your flow. I have found that a diagramming tool that constantly needs you to control the layout, such as Visio, is also not good.   

So until there is a better tool, I have been using Xmind because as a mind-mapping tool, it is designed to not get in your way as you are creating. It lays itself out as a tree structure, and then allows cross connections on the tree to be added using a key short-cut at the source and a mouse click at the destination node. It has its limitations, however I use some simple conventions to get around these. For example, I use '<' and '>' to represent input and output ports.

Furthermore, the tree structure allows easy hand translation of the diagram into indented, fluent style code. 

More recently we use a simple tool that takes Xmind files and generates the code automatically.

And even more recently, we have in progress a purpose built graphical IDE for ALA.

See the end of this chapter for an example project using Xmind.


// TBD review from here

....
Thoughts on the essentials of a diagramming tool.
  
It would have the low driving overhead of a mind mapping tool. As with a mind-mapping tool, you control the logical layout, and the tool does the actual spacial positioning. It would primarily use keypresses, but allow mouse clicks where it makes sense, for example, to specify the destination of a 'cross connection'. The tool would route the cross conenction for you.

A tree topology can be done with simple key presses. The tree would capture the primary relationships between instances, on their main ports.

You can make mutiple trees for different user stories that are disconnected logically, but for the purpose of automatic layout, are connected to the main tree (just an invisible line).

Abstractions are defined in a separate panel as stand-alone boxes with ports. Once a new abstraction is  defined, it can be instantiated in the diagram by its abstraction name with auto completion. Boxes represent these instances of abstractions with the ports still lablled around their boundary.

The abstractions are fully inegrated with the classes in the code. This is in both directions. So for any existing classes, the IDE shows them with their port, and fully supports the entry of constructor arguments and properties.

In the other direction, if you create a new abstraction in the tool. You can specify its ports and their types and names. You can specify the constructor arguments and properties and their default values. It will create/modify a template for that class.cs.

The tool's purpose is to aid creativity in the ALA process of representing a user story, inventing new abstractions as you go. Of course the tool would also automatically generate the wiring code.
....

In my experience, a low overhead drawing tool is essential during the iteration zero design phase and during subsequent maintenance.   


=== Composability and Compositionality

We have referred to the property "composability" a few times. By composability, we refer to the ability to create an infinite variety of applications by combining instances of a finite number of domain abstractions in different arrangements.

This is a very important property in ALA. Composability uses the Principle of Compositionality which states: In mathematics, semantics, and philosophy of language, the principle of compositionality is the principle that the meaning of a complex expression is determined by the meanings of its constituent expressions and the rules used to combine them. 

Jules Hedges says of this property "I claim that compositionality is extremely delicate, and that it is so powerful that it is worth going to extreme lengths to achieve it." 

The consequence of compositionality for software is that once a reader knows a finite number of abstractions, together with their rules of composition (grammar), they are able to understand a potentially infinite number of compositions, on first reading.

In software engineering, it is described by a pattern called "Abstract Interactions" or "Configurable Modularity" by Raoul de Campo and Nate Edwards - the ability to reuse independent components by changing their interconnections but not their internals. It is said that this characterises all successful reuse systems, and indeed all systems which can be described as "engineered". 

ALA has these properties by using domain abstractions and programming paradigm interfaces.

As mentioned earlier, there are other software systems that have composability, usually using the data-flow paradigm, such RX (Reactive Extensions), or more generally monads. Most composability systems are restricted to a single paradigm. For ALA to have the correct level of expressiveness of all requirements, when inventing and composing domain abstractions, a variety of 'connection paradigms' are needed. Some examples of these are discussed in the next chapter on execution models.

We can make an analogy with Lego bricks. Some Lego parts have the familiar little stud and tube connectors. Some will support axles and holes connections, either tight or loose. These different ways of connecting Lego parts are analogous to different programming paradigms and different ways for parts of the model to 'execute' at run-time. 

If the domain were for building model toys (the Lego domain), the non-ALA method would start with the imagined toy and decompose it into parts specific to that one toy. The solution would be brittle and hard to change and no other toys would be possible without the same huge effort all over again. The ALA method is to invent a finite set of building blocks and the mechanisms by which they connect. Then the initial toy can be easily changed, and other toys are possible with little effort.

=== Some real dependency graphs

Our example project for this chapter is a real legacy application (that was maintained for approximately 10 years) that we decided to re-write using ALA. Normally, for reasons I won't go into here, I would never re-write an application. Maintenance had become difficult with this legacy code, and we wanted to run a research experiment to see if a rewrite using ALA could be successful. It would also give us a good basis for comparative metrics of the two code bases.

The original application has around 30 KLOC. Rather than look at any of the details of the application itself, we present here dependency graphs generated by Ndepend for the old legacy application and new ALA application.

==== Legacy application dependency graphs

One of the core tenets of ALA (as discussed in Section 3.2) is "Composition using layers" instead of "Decomposition using encapsulation". Unfortunately Ndepend is designed with the assumption that the application should be built using the latter approach. It likes to present a decomposition structure, starting with assemblies (packages) at the outermost level, then namespaces, and then classes. I'm not sure why it considers namespaces a viable encapsulation mechanism because they don't provide encapsulation. Anyway, here is the namespace dependency graph for the main assembly of the legacy version of the application, as it comes out of ndepend.

image::old-datalink/namespaces.png[namespaces.png, title="Legacy application - namespaces", link=images/old-datalink/namespaces.png]

This graph is quite large, so if you like you can right click on it, and open it in a new tab in your browser. The red arrows are dependencies in both directions.

Each box represents a namespace. The thickness of the arrows is proportional to the number fo dependencies. The size of the boxes is proportional to the number of lines of code in the namespace.

If we drill down into the largest namespace, UIForms, we see the class relationships between classes inside that namespace:


image::old-datalink/classes-in-uiforms-namespace.png[classes-in-uiforms-namespace.png, title="Legacy application - classes in uiforms namespace", link=images/old-datalink/classes-in-uiforms-namespace.png]

Here you can see that ndepend is trying to make out the layers. The layers are vertical columns, going from left to right. I have left them vertical even through ALA abstraction layers are usually drawn horizontal because they come out more readable on the page. Again there are many dependencies in both directions drawn in red.

Here are the classes inside the DataStructure namespace:

image::old-datalink/classes-in-datastructure-namespace.png[classes-in-datastructure-namespace.png, title="Legacy application - classes in datastructure namespace", link=images/old-datalink/classes-in-datastructure-namespace.png]

Again, Ndepend is trying to make out the layers from left to right.

There is one class called Device which actually looks like it might be a good abstraction.


As mentioned, namespaces provide no useful decomposition structure. They do not make abstractions in themselves, nor do they implement a facade pattern or an aggregate root type of pattern with even logical encapsulation. Any classes inside each namespace can have unconstrained relationships with any classes in any other namespace.

So Ndepend is giving us a false picture here, because it is omitting all dependencies that go in or out of the namespaces. To really get an idea of what the big ball of mud looks like, I configured Ndepend to use a query that gives me all the classes in all the namespaces. Here finally is what this application truly looks like: 

image::old-datalink/classes-in-all-namespaces.png[classes-in-all-namespaces.png, title="Legacy application - all classes in all namespaces",link=images/old-datalink/classes-in-all-namespaces.png]

This graph is very large. Right click on it, and open it in a new tab in your browser, so you can zoom in to see the dependencies in the background. It is truly frightening. Ndepend had no chance to find the dependency layers. There may be vaque onion type layers going outwards from the middle. It makes readily visible why continued maintenance on this application is so difficult. You have to read a lot of code to find even a tiny part of this hidden structure.

The developer who maintains the application tells me this is a fair projection of the complexity that he has to deal with.

To be fair, some of the dependencies in this diagram are 'good' dependencies (as described in Section 3.1 on good and bad dependencies). For example, the box near south-east called ScpProtocolManager has a lot of dependencies coming into it, which means it is possibly used a lot and therefore is a potential good abstraction. Ndepend does not know about the concept of good and bad dependencies, but if it did I would have it just display the bad ones.   


==== New ALA application dependency graphs

Here is the equivalent Ndepend generated class dependency graph for the new ALA version of the application.

image::new-datalink/classes-in-all-namespaces.png[classes-in-all-namespaces.png, title="New ALA application - classes in all namespaces", link=images/new-datalink/classes-in-all-namespaces.png]

Ndepend has tried to find the three ALA layers which are vertical and go from left to right. Only the Application sits in the top layer. The DomainAbstractions layer contains the next two columns of classes and a few from the next column. And the ProgrammingParadigms layer contains the rest on the right. Actually there were a couple of bad dependencies present when this graph was generated which have since been fixed. (There should be no dependency between Panel and OptionBox, nor between Wizard and WizardItem.) With these removed, the graph would form into the three abstraction layers. 

The newly rewritten application is a work in progress at this point. However, as features are added, this is all the dependencies you will ever see. The Application already uses most of the domain abstractions we will ever need, and the domain abstractions already use the programming paradigm interfaces they need. There are a few DomainAbstractions to be added, but this is essentially what the  class dependency graph will look like.  


This graph has the classes from all namespaces. But just for interest, here is ndpend's namespace dependency graph.


image::new-datalink/namespaces.png[namespaces.png, title="New ALA application - namespaces", link=images/new-datalink/namespaces.png]

Remember in ALA, we do not use decomposition, so namespaces do not represent decomposition of the system. They represent layers. You can clearly see the three layers. The wiring namespace also goes in the programmingparadigms layer.


Let's drill inside the domain abstraction namespace to see the interdependencies within that layer. We expect to see no dependencies:


image::new-datalink/classes-in-domainabstractions-namespace.png[classes-in-domainabstractions-namespace.png, title="New ALA application - classes in DomainAbstractions namespace", link=images/new-datalink/classes-in-domainabstractions-namespace.png]


Ok here we see the two previously mentioned bad dependencies, and two other dependencies. They are on delegates or enums in the same source file, and so don't count as bad dependencies.

And finally, let's drill into the ProgrammingParadigms namespace

image::new-datalink/classes-in-programmingparadigms-namespace.png[classes-in-programmingparadigms-namespace.png, title="New ALA application - Classes in Programming Paradigms namespace", link=images/new-datalink/classes-in-programmingparadigms-namespace.png]

Again we see a few dependencies on delegates in the same source file which are ok. There is a couple of connector classes that depend on interfaces in this same layer. I consider them part of the interface from the programming paradigm point of view. They are in the same source file as a cohesive unit.

As of this writing, the new ALA version of the application is still a research project, but so far everything has gone smoothly with two weeks spent doing the description of the requirements as a diagram, and three months so far spent writing the domain abstractions. So far there are no issues getting it to actually execute. It is expected that we will actually commercialize the project soon and replace the old application.


==== The application's diagram

As we said in this chapter, diagrams can be an important aspect of ALA when the user story naturally contains a network of relationships among its instances of abstractions. In this application this is the case. There are UI relationships between elements of the UI. There are data-flow relationships between UI elements, data processing elements, and data sources. There are event-flows from UI to wizards and between wizards and the SaveFileBrowser. and there are minor data-flows such as a the filepath from the file browser to the csvFileReaderWriter.

Here is a sample section from the application diagram that shows all the relationships that implement the user story:

image::DatalinkApplication.xmind.png[DatalinkApplication.xmind.png, title="Xmind being used to design an application", align="center"]

This diagram was drawn using Xmind. It shows a single user story.  There is a UI with a menu item or a tool bar to start the user story. It then displays a browse dialogue to specify the location of the file. When the filepath has been selected, it gets data off a device on a COM port, using a protocol, and writes it to a CSV file. The data is also routed to be shown on a grid on the UI.

The user story diagram makes use of four different programming paradigms (which become four different interface types). Firstly there is the UI structure consisting of the window with its menubar, grid etc arranged inside it. Secondly, there is an event connection for when the menu is clicked which opens the browse dialog. Thirdly a data-flow connection carries the output of the browse dialog, a string containing the selected filepath, to the CSVFileReaderWriter. Another data-flow connection carries characters between the COM port and the SCPProtocol and another carries SCPcommands from the SessionDataSCP. The forth programming paradigm is a table data flow that carries dynamic columns and rows of data from the SessionDataSCP object to the grid object in the UI and to the CSVFileReaderWriter. 

Having drawn the diagram to represent the user story, we need to make the diagram execute. When we started this particular project we had no tool for automatically generating the code from the diagram, but during the project, one of the interns wrote a tool to do this. It parsed the Json output from Xmind and generated C# wiring code equivalent to what we will show below.

However, at first we were hand generating code, and it is instructive to know what this hand generated code looks like, just so we know how the diagram actually executes. 

When we were hand generating the code, it was important that the code was readable from the point of view of seeing how it corresponds exactly with the diagram. (It wasn't important that the code was readable from the point of view of seeing how the user story works - that was the job of the diagram.)  We had various conventions to support the one to one matching of diagram and code. One of these conventions was to indent the code to exactly mirror the tree structures in the diagram. Another was that whenever a new instance of an abstraction instantiated, all its ports would be wired immediately, and they would be wired in the order they were declared in the abstraction. This implies a depth first wiring strategy, analogous to walking the diagram tree depth first. Any ports with cross connections (the red lines in the diagram) would also be wired to their destinations at the time the abstraction were instantiated. If the destination instance did not already exist it would be pre-instantiated. 

Using these conventions, it is a simple matter to hand generate the code below from the diagram.


....
using System;
using System.Windows.Media;
using DomainAbstractions;
using Wiring;


namespace Application
{
    class Application
    {
        private MainWindow mainWindow = new MainWindow("App Name") { Icon = "XYZCompanyIcon"};

        [STAThread]
        public static void Main()
        {
            new Application().Initialize().mainWindow.Run();
        }

        private Application Initialize()
        {
            return this;
        }

        private Application()
        {
            var getInfoWizard = new Wizard("Get information off device") { SecondTitle = "What information do you want to get off the device?" };
            Grid DataGrid;
            var sessionDataSCP = new SessionDataSCP();
            var csvFileReaderWriter = new CSVFileReaderWriter();

            mainWindow
            // UI
                .WireTo(new Vertical()
                    .WireTo(new Menubar()
                        // XR3000
                        .WireTo(new Menu("File")
                            .WireTo(new MenuItem("Get information off device") { Icon = "GetDeviceIcon.png", ToolTip = "Get session data or LifeData or favourites from the device\nto save to a file or send to the cloud" }
                                .WireTo(getInfoWizard)
                            )
                            .WireTo(new MenuItem("Put information onto device") { Icon = "PutDeviceIcon.png" })
                            .WireTo(new MenuItem("Exit") { Icon = "ExitIcon.png" })
                        )
                        .WireTo(new Menu("Tools"))
                        .WireTo(new Menu("Help"))
                    )
                    .WireTo(new Toolbar()
                        // XR3000
                        .WireTo(new Tool("GetDeviceIcon.png") { ToolTip = "Get information off device" }
                            .WireTo(getInfoWizard)
                        )
                        .WireTo(new Tool("PutDeviceIcon.png") { ToolTip = "Put information onto device" })
                        .WireTo(new Tool("DeleteDeviceIcon.png") { ToolTip = "Delete information off device" })
                    )
                    .WireTo(new Horizontal()
                        .WireTo(new Grid() { InstanceName = "Sessions" })
                        .WireTo((DataGrid = new Grid() { InstanceName = "DataGrid" })
                            .WireFrom(sessionDataSCP)
                        )
                    )
                    .WireTo(new Statusbar()
                        .WireTo(new Text() { Color = Brushes.Green }
                            .WireFrom(new LiteralString("Connected to device"))
                        )
                    )
                );


            getInfoWizard
                .WireTo(new WizardItem("Get selected session files") { Icon = "IconSession.png", Checked = true }
                    .WireTo(new Wizard("Select destination") { SecondTitle = "What do you want to do with the session files?", ShowBackButton = true }
                        .WireTo(new WizardItem("Save selected sessions as files on the PC") { Icon = "SessionDocumentIcon.png", Checked = true }
                            .WireTo(new SaveFileBrowser("Select location to save data") { Icon = "SaveIcon.png", InitialPath = "%ProgramData%\XYZCompany"}
                                .WireTo(csvFileReaderWriter)
                            )
                        )
                        .WireTo(new WizardItem("Send records to NAIT") { Icon = "NAIT.png" })
                        .WireTo(new WizardItem("Send sessions to NLIS") { Icon = "NLIS.png" })
                    )
                    .WireTo(getInfoWizard)
                )
                .WireTo(new WizardItem("Get Lifedata"));

            var comPorts =
                new ComPortAdapter()
                    .WireTo(new SCPProtocol()
                        .WireTo(new SessionDataSCP()
                            .WireTo(DataGrid)
                            .WireTo(csvFileReaderWriter)
                        )

                    );

        }
    }
}
....

We used a 'diagram first' rule to keep the diagram and code in sync. Change the diagram first, then change the wiring code.

As of this writing, a graphical IDE is being developed for these types of ALA applications.







=== Example Project - Coffee machine

Robert Martin posed an interesting pedagogical sized embedded system problem about a coffee maker in his book ‚ÄúAgile Software Development: Principles, Patterns and Practices‚Äù. The original chapter is called ‚ÄúHeuristics and Coffee‚Äù.

In the original chapter, the worked solution to this problem uses decomposition into three modules that collaborate or interact with one another. The ALA solution follows the opposite philosophy. It has three abstractions (which correspond with the three modules), but they do not collaborate or interact with one another. Being abstractions, they don't know anything about each other. As domain abstractions, they also know nothing about the coffee machine. The coffee machine is then constructed (as another abstraction in the top layer) that makes use of the three domain abstractions. 

This example uses different execution models from the 'consistsof' and 'dataflow' ones that we used in previous examples. Here we will use some extremely simple, yet quite interesting electronic-signal-like execution models that have a simple main-loop polling type implementation, just as Robert Martin's original solution also had.

Reading an ALA application requires first knowing the pre-requisite knowledge you need from lower layer abstractions. So before presenting the application, let's first familiarise ourselves with the abstractions we need from the domain layer, and the Programming Paradigms layer.

==== Domain abstractions layer

Here are the three domain abstractions:

image::Coffee%20Maker%20Domain%20Components.vsd.jpg[Coffee Maker Domain Components.vsd.jpg, title="Coffee maker domain abstractions"]

Take a moment to look at these three abstractions:

-- The UI has a lamp you can control, and a push button which outputs an event (should have been two separate abstractions).

-- There is a WarmerPlate. It tells you whether or not a container is on the warmer plate, and whether or not it is empty. It controls its own heater. 

-- There is a  Boiler. It can be turned on or off. It will tell you when it is empty of water. And you can stop water flow instantly with a steam release valve. It will turn its own heater off if it runs out of water, or the valve is opened. 

That's all there is to know about the three domain abstractions.

==== Programming Paradigms layer

We have three programming paradigms

-- live-data-flow (works like an electronic circuit)

-- events

-- simple state machine

The API for the Programming Paradigms layer is described in the key on the right of the diagram below. It gives you all the knowledge from this layer to be able to read the diagram. So, for example, a solid line is a data-flow; the rounded box is state with the states enumerated inside it.

The details of how to turn the diagram into code is explained in a project document, also provided in the Programming Paradigms layer.


==== Application layer

Now that we have understood the knowledge dependencies in all lower layers, we can read the diagram that resides in the top layer, the application layer:



image::Coffee%20Maker%20Dataflow%20diagram.vsd.jpg[CoffeeMaker Dataflow diagram, title="Coffee maker solution"]

The diagram to the left is the application itself. Instances of the three domain abstractions, UI, Boiler and Warmer plate are shown as boxes.

Follow me now as we go through the user stories by looking at the lines on the diagram:

* When the UI push button is pressed, we set the state to Brewing, provided the Boiler has water and the pot is on the Warmerplate. 

* When the state is brewing, it turns on the boiler, and coffee making starts.

* If someone takes the pot off, the valve is opened to momentarily release pressure from the boiling water, which stops the water flow. 

* When the boiler becomes empty, the state is set to Brewed. When the state is Brewed, the light in the UI is turned on.

* When the coffee pot is replaced empty, the state goes back to the idle state where we began.

That's all there is to reading this application. The code for the coffee machine can be read and understood in about one minute. Compare that with reading other solutions to the coffee machine problem.

Note that the paragraph above is pretty much a restatement of the requirements in English. It could have been the requirements. The amount of information in the English form (or the diagram form) is about the same, thus the Domain Abstractions gave us the correct level of expressiveness. Further confirmation of this is if the level of expressiveness allows us to modify it.

For example, say a requirement was added that a coin device was to enable the machine to be used. The coin device is an abstraction that provides an output when a coin is given, and has a reset input. Looking at the diagram, and being able to reason about its operation so easily, you can see that the coin device's output would intercept the Pushbutton using another instance of an AND gate. And to reset the coin device, you could use the boiler empty output event.

==== Execution

To make it actually execute, we apply the manual procedure documented in ‚ÄúExecution models.doc‚Äù. This document is in the Programming Paradigms layer. It will generate these 6 lines of code:

    if (userInterface.Button && warmerPlate.PotOnPlate && !boiler.Empty) { state = Brewing; } userInterface.Button = false;
    boiler.OpenSteamReleaseValve = !warmerPlate.PotOnPlate;
    boiler.On = state==Brewing;
    if (boiler.Empty && !prevBoilerEmpty) { state = Brewed; } prevBoilerEmpty = boiler.Empty;
    if (warmerPlate.PotEmpty && !prevPotEmpty) { state = Idle; } prevPotEmpty = warmerPlate.PotEmpty;
    userInterface.LightOn = state==Brewed;
 

There is a one-to-one correspondence between the lines in the diagram and the lines in the code. 

As you can see, the execution model is a simple one. The 6 lines of code are continually executed in a loop. This execution model is effective and appropriate for this small application.

The 6 lines of code can be built into a complete program shown below:

....
 #ifndef _COFFEE_MAKER_H_
 #define _COFFEE_MAKER_H_
 // Coffee Maker domain abstraction
 #include "CoffeeMakerAPI.h"  // original hardware abstraction supplied by hardware engineers
 // Knowledge dependencies :
 // "PolledDataFlowProgrammingParadigm.doc" -- explains how to hand compile a data flow diagram of this type to C code
 // Following are 3 Domain abstractions that the application has knowledge dependencies on
 
 
 
 #include "UserInterface.h"
 #include "Boiler.h"
 #include "WarmerPlate.h"
 
 
 
 class CoffeeMaker
 {
 private:
    enum {Idle, Brewing, Brewed} state;
    Boiler boiler;
    UserInterface userInterface;
    WarmerPlate warmerPlate;
    bool prevBoilerEmpty, prevPotEmpty;
    void _Poll();
 public:
    CoffeeMaker()
        : state(Idle), prevBoilerEmpty(boiler.Empty), prevPotEmpty(warmerPlate.PotEmpty)
    {}
    void Poll();
 };
 #endif //_COFFEE_MAKER_H_
....
 
....
 // CoffeeMaker.c
 // This is not source code, it is code hand compiled from the CoffeeMaker application diagram
 #include "CoffeeMaker.h"
 
 void CoffeeMaker::_Poll() <1>
 {
    if (userInterface.Button && warmerPlate.PotOnPlate && !boiler.Empty) { state = Brewing; } userInterface.Button = false;
    boiler.OpenSteamReleaseValve = !warmerPlate.PotOnPlate;
    boiler.On = state==Brewing;
    if (boiler.Empty && !prevBoilerEmpty) { state = Brewed; } prevBoilerEmpty = boiler.Empty;
    if (warmerPlate.PotEmpty && !prevPotEmpty) { state = Idle; } prevPotEmpty = warmerPlate.PotEmpty;
    userInterface.LightOn = state==Brewed;
 }
 
 
 
 void CoffeeMaker::Poll()
 {
    // get inputs processed
    userInterface.Poll();
    boiler.Poll();
    warmerPlate.Poll();
    // run application
    _Poll();
    // get outputs processed
    userInterface.Poll();
    boiler.Poll();
 }
....

<1>  The 6 lines of code appear in the "CoffeeMaker::_Poll()" function.


If you are using a diagram as we are in this solution, you always change the diagram first when the requirements change. It provides the expressiveness needed to see the application‚Äôs requirements represented in a clear, concise and coherent way. There the logic can be ‚Äòreasoned‚Äô with. It is not documentation, it is the source code representation of the requirements, and executable, both important aspects of ALA.

The next step is to implement the three abstractions. These are straightforward using the same execution model as was used for the application, so are not shown here.

The resulting application passes all of Martin's original acceptance tests plus a number of additional tests of behaviour gleaned from his original text.







== Chapter four - Programming paradigms

=== Introduction to execution models

ALA fundamentally begins with the premise of abstraction layers, with each layer significantly more abstract than the one above. So it is interesting to observe how these layers seem to emerge typical usage patterns, which in turn give rise to their names: Application layer, Domain abstractions layer, Programming Paradigms layer, and so on.

image::JacquardLoom.jpg[JacquardLoom.jpg, 400, title="Jacquard loom as a programming paradigm", float="right"]

The layer below the domain abstractions is really interesting in this respect. After the application has arranged and joined instances of domain abstractions to __represent user stories__, we now want them to actually execute. There are multiple ways things can execute:

* simple events
* data-flows
* UI layouts
* states machines
* data schemas
* functional programming
* etc.

These are all quite abstract concepts which suggests a new layer below. The domain abstractions need to use them extensively. So they make a new layer below the domain abstractions layer. Within the layer we will design interfaces for all these execution models so we will sometimes think of it as the execution models layer. But from the point of view of the application writer who is combining instances of abstractions, they look like programming paradigms. So we call the layer the "Programming Paradigms layer".

The ways that programs can actually execute are by no means limited to the ones listed above. Slightly more custom ones such as "ConsistsOf" can be invented as needed (when they better express the requirements). We did this with the 'IConsistsOf' paradigm that we used in the project example for game scoring at the end of chapter two. 

The "programming paradigms" layer may also contain other abstractions useful for building domain abstractions, such as a 'Persistence' abstraction. 

It is an essential part of ALA to not only be able to have programming paradigms, but to use multiple programming paradigms in the same application, and in the same user story. This is referred to as polyglot programming paradigms. For most user stories, the most common paradigms needed are a combination of data-flow, UI layout, data schema and activity. 

image::TaxonomyProgrammingParadigms.png[TaxonomyProgrammingParadigms.png, title="Taxonomy Programming Paradigms - cited from Van Roy"]

We will seldom make use of the 'imperative' programming paradigm - the execution model of the native CPU hardware and most so-called high-level languages. Imperative means sequential, synchronous, execution flow of instructions or statements. (This paradigm does have a place in algorithms, however.) 

Some programmers are so used to thinking in terms of sequential synchronous execution that it can be difficult to think in terms of other programming paradigms. Or, you keep wanting to know what the equivalent sequential synchronous code is in order to understand what is going on under the covers, in terms of what you already understand. Instead it is better to let go and just think in terms of the new programming paradigms. Certainly it is nice to know what is going on under the covers from a performance or resourcing point of view. But from a logical point of view, it is better to start expressing requirements directly in a range of new programming paradigms.

Within each programming paradigm, there are generally some variations on how they can actually be made to execute. 

The following sections are a selection of some of the more common programming paradigms. It is not an exhaustive list. There are no doubt many other possibilities waiting to be invented that better allow succinct expression of requirements. 


=== Synchronous events

We start with events because we want something that we can understand starting at the code level up. In this way we can get a concrete point of view of how these execution models can work. IEvent is the implementation of this simple yet very powerful and useful programming paradigm.

Here is the interface. 

....
namespace ProgrammingParadigms
{
    public interface IEvent
    {
        void Execute();
    }
}
....

As you can see the interface for this execution model is very simple indeed - it's just a synchronous method call. Indeed it will be used to replace normal method calls between peer modules in conventional code.

Let's complete our understanding at the code level by making two domain abstractions called A and B that use the interface:



....
using ProgrammingParadigms


namespace DomainAbstractions
{

    class A
    {
        private IEvent Finished;
    
        public void Start()
        {
            // do my work
            Finsihed.Execute();
        }
    
    }
    
    
    
    class B : IEvent
    {
        IEvent Execute()
        {
            // do my work
        }
    }

}
....


Now we can write an application

....
using DomainAbstractions

class Application
{
    var program = new A().WireTo(new B());
    program.Start();
}
....


This will instantiate one instance of each of our domain abstractions, and wire them together. (If you have not seen the WireTo abstraction before, it is an extension method that uses reflection to search in class A for a private variable with a type that is an interface. It then sets it pointing to the instance of B if B implements the same interface. WireTo is not central to the current discussion, the IEvent interface is.  WireTo is discussed in more detail in the example projects of chapters 2 and 3.) 

Despite it's simplicity, the IEvent interface is a powerful abstraction that has a huge impact on the quality of the architecture. The programming paradigm it gives us is, effectively, the UML Activity diagram.

Notice just how abstract IEvent is. It's highly reusable, it's not specific to any domain abstraction or the application. It just knows how to transmit or receive an event. Because it is so abstract, it is stable. This makes it ok to have many domain abstractions depend on it.

Many domain abstractions will use it, either by accepting the interface (as Class A does) or by implementing the interface (as Class B does). Then many instances of those domain abstractions can be connected together in an infinite variety of ways. This is called compositionality.     

The interface fully decouples domain abstractions, because they only have to know about this interface. They do not need to know about each other. Unlike normal method calls, senders don't know who they are talking to. 

The IEvent interface could be contrasted with the observer pattern (publish/subscribe) which also claims to achieve decoupling. However the observer pattern only reverses the dependency of a normal method call. Instead of the sender knowing about the receiver, the receiver has to know about the sender. If the sender and receivers are peers the observer pattern does not solve the problem. The IEvent interface decouples in both directions. The job of 'subscribing' is correctly moved to the application layer, because only the application should have the knowledge of what should be connected to what.

There is normally a downside associated with decoupling, and that is that it becomes harder to follow the flow of control through the modules. That downside does not apply for the IEvent interface (or ALA in general). The reason is that the connections are still explicit - they are in the application layer that is wiring everything together. 

In summary, the event driven programming paradigm used to connect instance of abstractions has the following properties over a conventional method call or observer pattern used between peer modules. 

These properties are:

* sender decoupled from receiver
* receiver decoupled from sender
* connections between instances are still explicit
* wiring is all brought to one place instead of being distributed inside modules
* compositionality

=== State machines

To get used to how different these programming paradigms can be, let's go now to something completely different - state machines. We wont be going into understanding them at the code level because we want to support hierarchical state machines, and the code for that is a little bit non-trivial, but we do want to get an understanding of how state machines are just another programming paradigm that allows us to wire together instance of abstractions. The meaning of the wiring is different than what it was for the event programming paradigm. 

I assume a basic understanding of what state machines are.

[.float-group]
-- 
image::FSM-generic.png[FSM-generic.png, title="State machine execution model", float="left"]

At first it can be difficult to express the solution to a requirements problem as a state machine, even when the state machine is a suitable way to solve the problem. It takes some getting used to the first time. But it only takes a little bit of practice to begin to master it.
--

I once had to express a set of user stories that involved different things that could happen from the outside, either through the UI or other inputs. I knew these were the kind of user stories that were nicely expressed by a state machine, but I had no idea where to start. I only knew that the previously written C code to do the job was a big mess that could no longer be maintained. But I started drawing the state machine, first on paper and then in Visio, and everything started to fall into place very nicely. Before I knew it I had represented what used to be 5000 lines of C code by a single A3 sized state machine diagram. This diagram so well represented the user stories that it was easy to maintain for years to come. This experience was a big factor in the final conception of ALA.   

Here is the diagram.

image::BigStateMachine.pdf.jpg[BigStateMachine.pdf.jpg, title="My first significant state machine for a real embedded device"]

Notice that the diagram makes heavy use of hierarchical states (boxes inside boxes). These turn out to be important in most of my state machines.

State machine diagrams are drawn in their own unique way. The boxes of the diagram are instances of the abstraction "State". The lines on a state machine diagram are actually instances of another abstraction, "Transition". Out of interest, to relate a state machine diagram to a more conventional ALA wiring diagram, you would replace all the lines on the state machine with boxes representing instances of Transition. The event, guard and actions that associate with a transition then go inside the transition box to configure it. Lines would then wire the transition box to its source state instance and destination state instance. Hierarchy is drawn on the state machine by boxes inside boxes, but in the conventional ALA wiring diagram, the boxes would be drawn outside with lines showing the tree structure. This analogous to the tree structured wiring we have used in previous examples for expressing UIs, which are actually 'contains' relationships. 

The graphical tool being developed will allow the drawing of hierarchical state machines. It will internally transform it to conventional wiring of instances of states and transitions. Interfaces called something like ITransitionSource, ITransitionDestination and IHiercharical would be used to make it execute. It is a simple matter to write code inside the state and transition abstractions to make them execute that would be adequately efficient for most purposes. 

How to make hierarchical state machine execute in an optimally efficient way is a non-trivial problem, but I have worked out the templates for what the C code should look like. Generating this code is a topic for another web page.

 
=== Imperative

Now that we have a bit of a feel for different types of programming paradigms, let's cover the Imparative one, becasue it's the one we all know and use all the time (when we shouldn't).

Imperative is the one provided by your programming language. It exists because it reflects the way the underlying machine works, not because it suits the expression of most user stories. Because it works the same way as the underlying machine, the imperative programming paradigm is efficient at runtime. This can be important for typically a small amount of the total code.

Impareative means that connected elements are executed consecutively and synchronously as fast as the CPU can execute them. The connected elements are language statements, especially function or method calls. Functions and methods are executed 'synchronously', which means that execution is always passed with the messages. The receiver of a message gets both the message and the CPU resource to process it. The sender automatically waits until the receiver finishes using the CPU resource and returns it. 

The imperative paradigm is only suitable when you know ahead of time the order that things will happen, and those things should happen as fast as possible in CPU time. There is not real-time or temporal concerns other than having the entire routine execute as quickly as possible. It is the paradigm to use to execute short running algorithms.


=== Event driven

We now return to 'Event driven' in the wider sense of the term than the synchronous event driven paradigm using the IEvent interface we discussed earlier.

'Event driven' is an overloaded term in software engineering because it generally means both 'asynchronous' and 'decoupled'. Let's clarify these two aspect separately.

==== coupled/decoupled
 
One perspective of 'Event Driven' is simply 'breaking out' of the imperative 'synchronous & coupled' paradigm. In Imperative programming, function calls are  both synchronous (because the caller waits for it to return before continuing its own execution) and coupled (because the function caller refers directly to the function in another module or class by its name). 

'Event driven' usually means both 'asynchronous' & 'decoupled'. Asynchronous means the receiver of the message can handle the message in it's own time. And the sender can do other things immediately. Decoupled means the sender does not name the recipient of the message. In most implementations if Event driven, the receiver usually names the event it is interested in. (Note that while this is considered 'decoupled' in Event Driven programming, it is not considered decoupled enough in ALA because the receiver (as an abstraction) still has to know about events in the outside world. In ALA we would use a fully decoupled implementation of the event driven programming paradigm.) 

These two notions, synchronous/asynchronous and coupled/decoupled are actually independent of each other. All four combinations are possible, and sensible. In fact all four combinations can be used in ALA. 

As we said, the term 'Event Driven' usually refers to the combination: asynchronous and decoupled, However in C#, events are synchronous and decoupled, which adds to the confusion. In C#, events are a synchronous implementation of the observer pattern - the sender waits until all receivers of the event have completed reacting to the event before continuing its own execution.

==== synchronous/asynchronous 

When something sends out an event or message there are two ways a receiver can get the message from a timing point of view.

* Synchronous - the receiver processes the message immediately when the message is sent. The receiver must be waiting, doing nothing, ready to process the message. The time of processing is therefore said to be synchronised with the sender. 

* Asynchronous - The receiver processes the message in its own time some time later. The receiver may be busy doing other things in the meantime. This implies the message must be stored somewhere until the receiver is ready. The time of processing is not synchronised with the sending of the event. 

So synchronous is made of an event plus the receiver in a do-nothing-wait state. Asynchronous is made up of an event, a storage of the event, and a receiver taking the event when it is ready. 


===== request/response pattern

A common pattern is an orchestration of two messages, a request and a response. Usually both messages are processed synchronously or both messages are processed asynchronously.

When both messages are processed synchronously it creates a very common pattern which we know of as a function call or method call. This pattern is efficient when running on a single thread because it is directly supported in silicon by the  subroutine call instruction. This instruction passes the event and the execution CPU resource to the receiver at the same time, and passes them both back for the response at the same time. It is actually a very nice invention, and a very effective and safe pattern. However, because the synchronous function call or method call is so common in programming languages, and is so efficient, the synchronous request/response pattern appears to be fundamental to most developers and tends to be over used for messaging in situations where asynchronous messaging would be better. 

Let's unravelling when to use synchronous and when to use asynchronous.

===== real world messaging

In the real world we don't normally think about synchronous or asynchronous. If we are in a conversation, it is inherently synchronous. We naturally wait for the other person to stop talking, and then we talk. Synchronous can operate on slightly longer time scales as when go to the coffee machine and wait for the coffee. In synchronous, we may have to wait doing nothing at all for the receiver to be ready, as we do when we arrive for a doctors appointment. We basically do nothing until we are synchronised with the doctor. 


On longer time scales everything is naturally asynchronous. We send an event out. It could be a letter, an e-mail, or dropping off our car. We don't wait, doing nothing, until the receiver is ready. We don't wait, doing nothing, for the response. The receivers react to our events in their own time. In the meantime we can do other things.

If the response is not that important, like a request for a quote, the sender can simply never notice that there was no response. If it is important to get the response, like a payment of an invoice, the sender will generally time out if there is no response and then talk an alternative action. So timeouts frequently come into play with asynchronous messaging.

Now notice that asynchronous events or messages are the fundamental form. An asynchronous message can be processed synchronously, but not the other way around. When you are waiting for the coffee machine, you are actually able to do asynchronous, just currently operating synchronously. If someone comes and talks to you, you can switch to asynchronous, and pick up the waiting coffee when you are ready rather when it is ready. In ALA we will be making use of this fundamental property of messaging so that we can build abstractions without having to know whether the abstraction we are talking to wants to handle it asynchronously or synchronously. 


===== Event driven as a paradigm

We have discussed two properties of event driven: asynchronous and decoupled. 

The Event Driven programming paradigm also has third meaning attached to it that is at higher level. In this context, the opposite of 'event driven' might be called 'Orchestration'.

The orchestration paradigm will be covered in the Activity programming paradigm in the next section. For now it just means that our application will prescribe what will happen in what order.

The event driven paradigm is the opposite. In the application we don't know what will happen next (in either the outside world or what code will execute next). We will just wait until some event happens, and then react to it. Reacting to it usually changes some stored state. This state may change the way we will react to subsequent events. In other words, event driven and state machines work well together. 

The Event driven paradigm allows events external to the system to happen at any time. We may be bust processing a previous event, so these events must be asynchronous. Events sent between modules in the system may be either asynchronous (treated like external events) or synchronous (let's do everything related to an external event now - called GALS - Globally Asynchronous locally synchronous) or a combination of both.  

===== Why use synchronous?

So if asynchronous is the more general and more flexible execution model, why use synchronous at all? As mentioned synchronous is efficient on a single thread, and is supported by the very common function or method statement of our common programming languages. These are sometimes good reasons to use synchronous. But there are other reasons to use synchronous locally. 

* Synchronous allows orchestration to be coded more conveniently. After a function call, the next thing to happen is coded in the next line of code, which is very nice. If using asynchronous messages for orchestration logic, the code for what happens next ends up in a different place (where the response event arrives) (although languages that have async/await can do code orchestration using asynchronous messaging just as nicely). 

* Single threaded synchronous messaging avoids certain potential problems because it is internally more deterministic - it orders the execution of everything that reacts to events. Asynchronous leaves the ordering of execution to be determined separately, which will generally appear less deterministic.

===== Why use asynchronous?

* Asynchronous avoids temporal coupling between sender and receiver. This can be hugely important, just as it's important not to have to wait for the receiver to be ready read your email before you send it, or to have to wait all day doing nothing while your car is being fixed.

* Asynchronous allows separate explicit (rather than implicit) scheduling of all work for temporal or performance issues. This explicit scheduling is both a greater freedom and a greater responsibility.

* A synchronous thread can't do anything else until it gets the response. This causes performance issues for long running routines. The connonical example is the UI that freezes while the single thread application executes a long synchronous algorithm. Synchronous generally involves temporal coupling. 

* Synchronous theoretically can work across threads, processors or networks (by remote procedure calls), but becomes even more problematic in temporal coupling. A synchronous call may block execution of the sender for an arbitrary length of time. The more general asynchronous approach becomes very much preferred.

==== ALA temporal decoupling between synchronous and asynchronous

ALA can use both asynchronous and synchronous. It does not have rules for when to use one or the other. The rules remain more or less the same as in non-ALA applications. However, ALA is all about abstractions that are completely uncoupled. They know absolutely nothing about each other, and this applies equally to whether they use asynchronous or synchronous events or messaging. It is therefore desirable that abstractions that generate events and abstractions that listen to events can be connected regardless of their synchronous or asynchronous nature. The only way to do this is for interfaces to be all asynchronous, and then be used synchronously when required at runtime. Let's explore the consequences of this.

Abstractions that receive events can implement the asynchronous interface either asynchronously or synchronously as they choose. If implementing synchronously, if the interface uses a callback, this means that they will call the callback function in the interface synchronously. If Tasks or Promises are used in the interface, it means they will return a Task or Promise already in the complete state. 

Abstractions that send events can also use the asynchronous interface synchronously if they choose. To do they simply don't do anything else until the response comes. If callbacks are used, it needn't care if the callback is called back synchronously. If Tasks or Promises are used, it needn't care if the Task or Promise it gets back after it sends the event is already in the complete state. But for when the receiver behaves asynchronously, the sender must still implement either a callback or a promise.

In this way senders and receivers do not need to be coupled with respect to synchronous/asynchronous. If two abstractions that don't know each other are connected in the same processor, they can execute synchronously. If they are connected in over a network, they can communicate asynchronously. 

This all sounds good, but unfortunately, if you make an interface asynchronous in order for it to handle either asynchronous or synchronous, both ends must be written in the 'coding style' of asynchronous. If the sender wants to execute synchronously, the coding style looks awkward unless your language has async/await or a similar mechanism such as protothreads. This is especially true when there is a known sequence of activities to be done that is naturally expressed as sequential function calls. The other problem is that if you are in the happy position of having async/await available, the async functions can start spreading to everywhere.

On the receiver side, when it wants to implement an asynchronous interface in a  synchronous manner, it can't simply return the value - it must call the callback or set the result in the promise object first.

All this only affects code that is written inside domain abstractions. It doesn't affect things so much at the application layer. This is because in the application layer we have lifted ourself into the declarative realm of composition of instances of abstractions. We have abstracted away the execution model in the interfaces in the Programming Paradigms layer. If you are wanting to do something sequential (but not Imperative) in the application layer module, you do it using the 'Activity' execution model which we will describe in a later section of this chapter.   

TBD
==== Preemptive/non-premptive

Before leaving the 'Event Driven' execution model, we just need to clarify two variants of asynchronous - preemptive or non-preemptive. An Event or Message can be sent and end up being executed on another thread or the same thread.  

In ALA, when using asynchronous, it must be non-pre-emptive by default. This is to prevent thread safety causing coupling between abstractions. Preemtive asynchronous (using multiple threads) would only be used when it is the only way to solve the temporal constraints of the problem, which would be understood to be compromising the decoupling between abstractions. This is the same criteria you should use in any type of programming style. 

////
==== Is a call to a blocking function synchronous or asynchronous? 

At this point there may be confusion in the situation where you have a multi-threaded program and a thread has a function call to a function that blocks. Is this synchronous or asynchronous? The code uses a synchronous programming style but is actually asynchronous because the execution model is that the caller does not get to continue execute return to the thread immediately. TBD
////

==== Examples of Event Driven

There are many examples of usage of asynchronous event driven systems. Examples are Node.js, the reactor pattern, IEC 61499 function blocks and there is usually an Asynchronous Event Framework behind the scenes of state machines.

=== Activity-flow

The name Activity-flow comes from the UML activity diagram. Activities that are wired together execute in order. One starts when the previous one finishes. The activity itself may take a long time to complete (without holding the CPU). Activity flows can split, run in parallel or pseudo-parallel and recombine. 

There are languages or libraries that support the Activity paradigm in text form so that the code looks like the Imperative paradigm but is actually more of the Activity paradigm. These are mechanisms such as async/await, yield, or coroutines such as Protothreads implemented using Duff's device in C.

==== Work-flow

Persisted Activity-flow. This includes long running activities within a business process such as an insurance claim.

=== Data-flow

A data-flow model is a model in which wired instances in the program (or connected boxes on a diagram) are a path of data without being a path of execution-flow. The execution flow is like in another dimension relative to the data flow - it may go all over the place.

A stream of data flows between the connected components. Each component processes data at its inputs and sends it out of its outputs.

Each input and output can be operated in either push or pull mode. Usually the system prescribes all pull (LINQ), all push (RX), all inputs pull and outputs push (active objects with queues) or all outputs pull and inputs push (active connectors). In ALA we can use a mix of these different mechanism when we define the programming paradigm interfaces.

The network can be circular provided some kind of execution semantic finishes the underlying CPU execution at some point (see synchronous programming below).

The data-flow paradigm raises the question of type compatibility and type safety. Ideally the types used by the components are either parameterised and specified by the application at each connection or determined through type inference.  


==== IDataFlow<T>

I frequently use data-flow execution models.

Here is one variation which works well:

TBD


This variation has these properties:

* On a diagram, the line (wire) represents a variable that holds the value.
* Fan-out - one output can connect to multiple inputs. All inputs read the same output variable.
* Fan-in - multiple outputs cannot connect to one input.
* Each output is implemented by a single memory variable whose scope is effectively all the places connected by the line (wire).
* Receivers can get an event when the value changes
* Receivers can read and re-read their inputs at any time.
* Operator don't need to have an output variable, they can pass the get through and recalculate every time instead. 

Here is the version I use most often.

TBD


It has a number of useful properties.

 

==== ITable

This interface moves a whole table of data at once. The table has rows and columns. The columns are determined at runtime by the source. 

TBD implemantation examples

==== IIterator

This data-flow interface allows moving a finite number of data values at once. It does so without having to save all the values anywhere in the stream, so has an efficient execution model that moves one data value at a time through the whole network.

This is the ALA equivalent of both IEnumerator and IObserver as used by monads. ALA uses the WireTo extension method that it already has to do the Bind operation. So the IIterator interface is wired in the same consistent way as all the other paradigm interfaces. There is no need for IEnumerable and IObservable type interfaces to support Also unlike monads, multiple arbirary interfaces can be wired between two objects with a single wiring operation.

IIterator has two variants that handle push and pull execution models. Either the A object can push data to the B object, or the A object can pull data from the B object. 

TBD implementation examles

==== Glitches

All systems can have glitches when data flows are pushed in a diamond pattern. The diamond pattern occurs when an output is wired to two or more places, and then the outputs of those places eventually come back together. If they never come together, even both seen by a human, then we generally don't care what order everything is executed in. But when they come together, the first input that arrives with new data will cause processing, and use old data on the other inputs. This unplanned combination of potentially inconsistent data processed together is a glitch. It even happens in electronic circuits.

The following composition of data-flow operators is meant to calculate (X+1)*(X+2)

[plantuml,file="diagram-25.png"]
----
@startdot
digraph foo {
# edge [color=green]
size="2!"
graph [rankdir=LR]
node [shape=Mrecord]
Add1 [label="<f0> Add|<f1> 1"]
Add2 [label="<f0> Add|<f1> 2"]
D [style=invis]
E [style=invis]
F [style=invis]
D -> X [style="invis"]
X -> Add1
X -> Add2
Add1 -> Mul
Add2 -> Mul
Mul -> E [style="invis"]
E -> F [style="invis"]
}
@enddot
----

When X changes, there can be a glitch, a short period of time, in which the output is (C~new~+1)*(C~old~+2).

In imperative programming, this problem is up to the developer to manage. He will usually arrange the order of execution and arrange for a single function or method to be called at the place where the data-paths come back together. As he does this, he is introducing a lot of non-obvious coupling indisde the modules of the system, which is one of the big problems with imperative programming.

When we have composability, we don't know inside the abstractions how data will propagate outside, and how it will arrive at its inputs. We want to execute whenever any of our inputs change, because as far as we know it may be the only change that might happen. So we really want the execution model to take care of eliminating glitches automatically for us.

This is a work in progress for the IDataFlow execution model described above.
In the meantime, as a work-around I take care of it at the application level using a pattern. When I know data-flows will re-merge in a potentially inconsistent manner, I wire in an instance of an abstraction called 'Order' between the output and all its destination inputs. This instance of order is configured to explicitly control the order that the output date stream events are executed in. Then I will use a second abstraction called 'EventBlock' at the end of all data paths except one, the one that executes last.    

[plantuml,file="diagram-26.png"]
----
@startdot
digraph foo {
# edge [color=green]
size="2!"
graph [rankdir=LR]
node [shape=Mrecord]
Add1 [label="<f0> Plus|<f1> 1"]
Add2 [label="<f0> Plus|<f1> 2"]
X -> Order
Order -> Add1 [label="1"]
Order -> Add2 [label="2"]
Add2 -> Mult
Add1 -> EventBlock
EventBlock -> Mult
{rank=same Add1 Add2}
}
@enddot
----
By default multiple IDataFlows wired to a single output are executed in the order that they are wired anyway. On the diagram, they are drawn top to bottom in that order.  This improves the determinism but is a little too implicit for my liking, so that is why I use the order abstraction.


=== Live-data-flow

As used in the coffee-maker example earlier, this paradigm simulates electronic circuits instead of using the concept of discrete messages. Semantically the inputs have the values of the outputs they are wired to at all times. This type of flow is readily implemented with shared memory variables.

FRP (Functional Reactive Programming) also is effectively a live data-flow execution model.


=== Synchronous data-flow

The use of the word synchronous here is different from its use in the discussion of synchronous/asynchronous events above. Here it means a master system clock clocks the data around the system on regular ticks. At each tick, every instance latches its own inputs and then processes them and places the results on their outputs. Data progresses through one operator per tick, so takes more time to get through the system from inputs to outputs. The result is a more deterministic and mathematically analysable system. 

The execution timing and the timing of outputs occurs at a predictable tick time, albeit on a slower time scale than an asynchronous system. All timings are lifted into the normal design space.

Glitches that could occur in an asynchronous system (discussed earlier) are eliminated at the level of single clock ticks. A fast glitch could not occur. A glitch would occur when different data paths had different lengths, and would last for at least one tick duration. Controlling glitches is therefore lifted into the normal design space.



=== UI layout

TBD

=== UI navigation flow

TBD

=== Data schema

TBD


=== Example project - Ten-pin bowling

The full source code for the bowling application can be viewed or downloaded from here: https://github.com/johnspray74/GameScoring[GameScoring code]



The ten-pin bowling problem is a common coding kata. Usually the problem presented is just to return the total score, but in this example we will tackle the more complicated problem of keeping the score required for a real scorecard, which means we need to keep all the individual frame ball scores. We can afford to do this even for a pedagogical sized example because ALA can provide a simple enough solution.





[plantuml,file="bowling_scorecard2.png"]
----
@startditaa --no-separation --no-shadows
/-----+-----+-----+-----+-----+-----+-----+-----+-----+--------\
|   1 |   2 |   3 |   4 |   5 |   6 |   7 |   8 |   9 |    10  |
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
| 1| 4| 4| 5| 6| /| 5| /|  | X| -| 1| 7| /| 6| /|  | X| 2| /| 6|
+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+--+
|   5 |  14 |  29 |  49 |  60 |  61 |  77 |  97 | 117 |   133  |
\-----+-----+-----+-----+-----+-----+-----+-----+-----+--------/

                    A ten-pin bowling scorecard
@endditaa
----


The ALA method starts by "describing the requirements in terms of abstractions that you invent". When we start describing the requirements of ten-pin bowling, we immediately find that "a game consists of multiple frames", and a "frame consists of multiple balls". Let's invent an abstraction to express that. Let's call it a "Frame". Instances of Frame can be wired together by a "ConsistsOf" relationship. So let's invent an abstract interface to represent that, and call it 'IConsistsOf'.

Here is the diagram of what we have so far.

////
[plantuml,file="bowling.png"]
----
@startditaa --no-separation --no-shadows utf-8

 nFrames==10     score==10 || nBalls==2
   |              |
   v              v
+-----+        +-----+
|     |        |     |
|Frame|------->|Frame|
|     |        |     |    
+-----+        +-----+
@endditaa
----
////

[plantuml,file="diagram-bowling-1.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
subgraph cluster_C {
label="Ten-Pin Bowling"
style=rounded
#node [style=rounded]
node [shape=Mrecord]
game [label="Frame|\"game\"|nFrames==10"]
frame [label="Frame|\"frame\"|balls==2 \|\| pins==10"]
ball [label="SinglePlay|\"throw\""]
game -> frame -> ball [label = "IConsistsOf"]
}
}
@enddot
----

This is the first time we are using a diagram for an ALA application, so le's go through the conventions used.

The name in the top of the boxes is the abstraction name. The name just beneath that is the name of an instance of the abstraction. For the bowling application above, we are using two instances of the Frame abstraction, one called "game" and one called "frame". Below the abstraction name and instance name go any configuration information of the instance.

The Frame abstraction is configured with a lambda function to tell it when it is finished. The Frame abstraction works like this - when its last child is complete it will create a new one. It will stop doing that when the lambda expression is true. It will tell its parent it is complete when both the lambda expression is true and its last child Frame is complete. 

The end of the chain is terminated with a leaf abstraction that also implements the 'IConsistsof' interface called 'SinglePlay'. It represents the most indivisible play of a game, which in bowling is one throw. Its job is to record the number of pins downed. 

The concept in the Frame abstraction is that at run-time it will form a composite pattern. As each down-stream child frame completes, a Frame will copy it to start a new one. This will form a tree structure. The "game" instance will end up with 10 "frames", and each frame instance will end up with 1, 2 or 3 SinglePlays.

Note, in reference to the ALA layers, this diagram sits entirely in the top layer, the Application layer. The boxes are instances of abstractions that come from the second layer, the Domain Abstractions layer. The arrows are instances of the programming paradigm, 'InConsistsOf', which comes from the third layer, the ProgrammingParadigms layer.  

This diagram will score 10 frames of ten-pin bowling but does not yet handle strikes and spares. So let's do some 'maintenance' of our application. Because the application so far consists of simple abstractions, which are inherently stable, maintenance should be possible without changing these abstractions.

The way a ten-pin bowling scorecard works, bonuses are scored in a different way for the first 9 frames than for the last frame. In the first nine frames, the bonus ball scores come from following frames, and just appear added to the frame's total. They do no appear as explicit throws. In the last frame, they are shown as explicit throws on the scorecard. That is why there are up to 3 throws in that last frame. 

To handle the different last frame, we just need to modify the completion lambda expression to this. 

 frameNum<9 && (balls==2 || pins==10) // completion condition for frames 1..9
 || (balls==2 && pins<10 || balls==3) // completion condition for frame 10

To handle bonuses for the first 9 frames, we introduce a new abstraction. Let's call it Bonuses. Although we are inventing it first for the game of ten-pin bowling, it is important to think of it as a general purpose, potentially reusable abstraction.

What the Bonus abstraction does is, after its child frame completes, it continues adding plays to the score until its own lambda function returns true.

The completed ten-pin bowling scorer is this:


[plantuml,file="diagram-bowling-2.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
subgraph cluster_C {
label="Ten-Pin Bowling"
style=rounded
#node [style=rounded]
node [shape=Mrecord]
game [label="Frame|\"game\"|nFrames==10"]
bonus [label="Bonus||score\<10 \|\| plays==3"]
frame [label="Frame|\"frame\"|frameNum\<9 && (balls==2 \|\| pins==10)\n \|\|\ (balls==2 && pins\<10 \|\| balls==3)"]
ball [label="SinglePlay"]
game -> bonus -> frame -> ball
}
}
@enddot
----

Note that the "game" instance (the left box of the diagram) implements IConsistsOf. This is where the outside world interfaces to this scoring engine. During a game, the number of pins knocked down by each throw is sent to this IConsistsOf interface. To get the score out, we would call a GetScore method in this interface. 
The hard architectural work is done. We have invented abstractions to make it easy to express requirements. We have a diagram that describes the requirements. And the diagram is executable. All we have to do is put some implementation code inside those abstractions and the application will actually execute.  

First let's turn the diagram into equivalent code. At the moment, there are no automated tools for converting such diagrams to code. But it is a simple matter to do it manually. We get the code below:

....
private IConsistsOf game = new Frame("game")
    .setIsFrameCompleteLambda((gameNumber, frames, score) => frames==10)
    .WireTo(new Bonus("bonus")
        .setIsBonusesCompleteLambda((plays, score) => score<10 || plays==3)
        .WireTo(new Frame("frame")
            .setIsFrameCompleteLambda((frameNumber, balls, pins) => frameNumber<9 && (balls==2 || pins[0]==10) || (balls==2 && pins[0]<10 || balls == 3))
            .WireTo(new SinglePlay("SinglePlay")
    )));
....

All we have done is use the 'new' keyword for every box in the diagram. We have made the constructor take the instance name as a string. (This name is not used except to identify instances during debugging.) We use a method called "WireTo" for every line in the diagram. More on that in a minute. And we pass any optional configuration into the instances using setter methods. The WireTo method and the configuration setter methods all return the 'this' pointer, which allows us to write this code in fluent style. If you are not familiar with fluent style it is just making methods return the this reference, or another object, so that you can chain together method calls using dot operators.

Not all ALA applications will be put together using the method in the previous paragraph, but I have found it a fairly good way to do it for most of them, so we will see this same method used for other example projects to come. 

So far, this has been a fairly top-down, waterfall-like approach. We have something that describes all the details of the requirements, but we haven't considered implementation at all. Past experience tells us this may lead us into dangerous territory. Will the devil be in the details? Will the design have to change once we start implementing the abstractions? The first few times I did this, I was unsure. I was not even sure it could actually be made to work. The reason it does work is because of the way we have handled details. Firstly all details from requirements are in the diagram. The diagram is not an overview of the structure. It is the actual application. All other details, implementation details, are inside abstractions, where they are hidden even at design-time. Being inside abstractions isolates them from affecting anything else. So, it should now be a simple matter of writing classes for those three abstractions and the whole thing will come to life. 
Implementing the three abstractions turns out to be straightforward.

First, design some methods for the IConsistOf interface that we think we will need to make the execution model work:

....
    public interface IConsistsOf
    {
        void Ball(int score);
        bool IsComplete();
        int GetScore();
        int GetnPlays();
        IConsistsOf GetCopy(int frameNumber);
        List<IConsistsOf> GetSubFrames();
    }
....

The first four methods are fairly obvious. The Ball method receives the score on a play. The Complete, GetScore and GetnPlays methods return the state of the sub-part of the game. The GetCopy method asks the object to return a copy of itself (prototype pattern). When a child frame completes, we will call this to get another one. The GetSubFrames method is there to allow getting the scores from all the individual parts of the game as required.

The SinglePlay and Bonus abstractions are very straightforward. 

So let's code the Frame abstraction.
Firstly, Frame both implements and accepts IConsistsOf. A field is needed to accept an IConsistsOf. The WireTo method will set this field: 

....
// Frame.cs
private IConsistsOf downstream;
....


Frame has one 'state' variable which is the list of subframes. This is the composite pattern we referred to earlier, and what ends up forming the tree.

....
// Frame.cs

private List<IConsistsOf> subFrames;
private readonly Func<int, int, int, bool> isFrameComplete;
private readonly int frameNumber = 0;
....

The second variable is the lambda expression that is a configuration passed to us by the application. It would be readonly (immutable) except that I wanted to use a setter method to pass it in, not the constructor, to indicate it is optional. 

The third variable is the frameNumber, also immutable. It allows frame objects to know which child they are to their parent - e.g. 1st frame, 2nd frame etc. This value is passed to the lambda expression in case it wants to use it. For example, the lambda expression for a bowling frame needs to know if it is the last frame.  

The methods of the IConsistsOf interface are now straightforward to write. Let's go over a few of them to get the idea. Here is the most complicated of them, the Ball method:

....
public void Ball(int player, int score)
{
    // 1. Check if our frame is complete, and do nothing
    // 2. See if our last subframe is complete, if so, start a new subframe
    // 3. Pass the ball score to all subframes

    if (IsComplete()) return;

    if (subFrames.Count==0 || subFrames.Last().IsComplete())
    {
        subFrames.Add(downstream.GetCopy(subFrames.Count)); 
    }

    foreach (IConsistsOf s in subFrames)
    {
        s.Ball(player, score);
    }
}
....

It looks to see if the last child frame has completed, and if so starts a new child frame. Then it just passes on the ball score to all the child objects. Any that have completed will ignore it.

The IsComplete method checks two things: 1) that the last child object is complete and 2) that the lambda expression says we are complete:

....
private bool IsComplete()
{
    if (subFrames.Count == 0) return false; // no plays yet
    return (subFrames.Last().IsComplete()) && 
        (isLambdaComplete == null ||
         isLambdaComplete(frameNumber, GetnPlays(), GetScore()));
}
....

....

....

GetScore simply gets the sum of the scores of all the child objects:


....
private int GetScore()
{
    return subFrames.Select(sf => sf.GetScore()).Sum();
}
....

The GetCopy method must make a copy of ourself. This is where the prototype pattern is used. This involves making a copy of our child as well. We will be given a new frameNumber by our parent.

....
IConsistsOf GetCopy(int frameNumber)
{
    var gf = new Frame(frameNumber);
    gf.objectName = this.objectName;
    gf.subFrames = new List<IConsistsOf>();
    gf.downstream = downstream.GetCopy(0);
    gf.isLambdaComplete = this.isLambdaComplete;
    return gf as IConsistsOf;
}
....

The few remaining methods of the IConsistOf interface are trivial. The implementation of IConsistsOf for the other two abstractions, SinglePlay and Bonuses, is similarly straightforward. Note that whereas Frame uses the composite pattern, Bonuses uses the decorator pattern. It implements and requires the IConsistsOf interface. The SinglePlay abstraction, being a leaf abstraction, only implements the IConsistsOf interface. 

One method we haven't discussed is the wireTo method that we used extensively in the application code to wire together instances of our domain abstractions. The wireTo method for Frame is shown below:  

....
public Frame WireTo(IConsistsOf c)
{
    downstream = c;
    return this;
}
....

This method does not need to be implemented in every domain abstraction. I use an extension method for WireTo. The WireTo extension method uses reflection to find the local variable to assign to.

The WireTo method will turn out to be useful in many ALA designs. Remember in ALA we "express requirements by composing instances of abstractions". If the 'instances' of 'abstractions' are implemented as 'objects' of 'classes', then we will use the wireTo method. If the 'instances' of 'abstractions' are 'invocations' of 'functions', as we did in the example project in Chapter One, we wont use WireTo obviously. In the coffeemaker example to come, 'instances' of 'abstractions' are 'references' to 'modules' because a given application would only have one of each abstraction.

The wireTo method returns 'this', which is what allows the fluent coding style used in the application code. The configuration setter methods also return the this reference so that they too can be used in the fluent style. 

Here is the full code for the Frame abstraction (with comments removed as we just explained everything above):

....
// Frame.c
using System;
using System.Collections.Generic;
using System.Linq;
using GameScoring.ProgrammingParadigms;
using System.Text;

namespace GameScoring.DomainAbstractions
{

    public class Frame : IConsistsOf
    {
        private Func<int, int, int[], bool> isLambdaComplete;
        private readonly int frameNumber = 0;
        private IConsistsOf downstream;
        private string objectName;
        private List<IConsistsOf> subFrames = new List<IConsistsOf>();


        public Frame(string name)  
        {
            objectName = name;
        }




        public Frame(int frameNumber)
        {
            this.frameNumber = frameNumber;
        }



        // Configuration setters follow. 

        public Frame setIsFrameCompleteLambda(Func<int, int, int[], bool> lambda)
        {
            isLambdaComplete = lambda;
            return this;
        }





        // Methods to implement the IConsistsOf interface follow


        public void Ball(int player, int score)
        {
            if (IsComplete()) return;

            if (subFrames.Count==0 || subFrames.Last().IsComplete())
            {
                subFrames.Add(downstream.GetCopy(subFrames.Count));
            }

            foreach (IConsistsOf s in subFrames)
            {
                s.Ball(player, score);
            }
        }




        public bool IsComplete()
        {
            if (subFrames.Count == 0) return false; 
            return (subFrames.Last().IsComplete()) && 
                (isLambdaComplete == null || 
                 isLambdaComplete(frameNumber, GetnPlays(), GetScore()));
        }




        public int GetnPlays()
        {
            return subFrames.Count();
        }




        public int[] GetScore()
        {
            return subFrames.Select(sf => sf.GetScore()).Sum();
        }



        List<IConsistsOf> IConsistsOf.GetSubFrames()
        {
            return subFrames;
        }




        IConsistsOf IConsistsOf.GetCopy(int frameNumber)
        {
            var gf = new Frame(frameNumber);
            gf.objectName = this.objectName;
            gf.subFrames = new List<IConsistsOf>();
            gf.downstream = downstream.GetCopy(0);
            gf.isLambdaComplete = this.isLambdaComplete;
            return gf as IConsistsOf;
        }

    }
}


....





=== Example project - Tennis

Now let's modify the bowling application to score tennis. If the bowling game hadn't been implemented using ALA, you probably wouldn't contemplate doing this. But ALA excels for maintainability, and I want to show that off by changing Bowling to Tennis. The Frame and IConsistsOf abstractions look like they could be pretty handy for Tennis. A match consists of sets, which consists of games, which consists of SinglePlays.

We will need to make a small generalization to the Frame abstraction first. This will allow it to keep score for two players. We just change the type of the score from int to int[]. The Ball method will be generalised to take a player parameter to indicate which player won a play. A generalization of an abstraction to make it more reusable is a common operation in ALA.

The only other thing we will need to do is invent a new abstraction to convert a score such as 6,4 into a score like 1,0, because, for example, the winner of a game takes one point into the set score. This new abstraction is called WinnerTakesPoint (WTP in the diagram). 

Here is the tennis scoring game:

[plantuml,file="tennis1.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
// subgraph cluster_C {
label="Tennis scoring"
style=rounded
#node [style=rounded]
node [shape=Mrecord]
match [label="Frame|\"match\"|score.Max()==3"]
wtp1 [label="WTP"]
set [label="Frame|\"set\"|score.Max()\>=6 && \nMath.Abs(score[0]-score[1])\>=2"]
wtp2 [label="WTP"]
game [label="Frame|\"game\"|score.Max()\>=4 && \nMath.Abs(score[0]-score[1])\>=2"]
play [label="SinglePlay"]
match -> wtp1 -> set -> wtp2 -> game -> play
// }
}
@enddot
----

The diagram expresses all the details of the requirements of tennis except the tiebreak.

Here is the diagram's corresponding code:

....
private IConsistsOf match = new Frame()
    .setIsFrameCompleteLambda((matchNumber, nSets, score) => score.Max()==3)
    .WireTo(new WinnerTakesPoint()
        .WireTo(new Frame()                     
            .setIsFrameCompleteLambda((setNumber, nGames, score) => score.Max()>=6 && Math.Abs(score[0]-score[1])>=2)
            .WireTo(new WinnerTakesPoint()
                .WireTo(new Frame()          
                    .setIsFrameCompleteLambda((gameNumber, nBalls, score) => score.Max()>=4 && Math.Abs(score[0]-score[1])>=2) 
                    .WireTo(new SinglePlay()))))));
....

The new WinnerTakesPoint abstraction is easy to write. It is a decorator that implements and requires the IConsistsOf interface. Most methods pass through except the GetScore, which returns 0,0 until the down-stream object completes, then it returns either 1,0 or 0,1 depending on which player has the higher score.

And just like that, the tennis application will now execute. The frame abstraction we invented for bowling is already done.

==== Add tiebreak

Now let's switch our attention back to another example of maintenance. Let's add the tiebreak feature. Another instance of Frame will score the tiebreak quite nicely. However we will need an abstraction that can switch us from playing the set to the tie break. Let's call it Switch, and give it a lambda function to configure it with when to switch from one subframe tree to another. Switch simply returns the sum of scores of its two subtrees. Here then is the full description of the rules of tennis:


[plantuml,file="tennis2.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
// subgraph cluster_C {
label="Tennis scoring"
style=rounded
#node [style=rounded]
node [shape=Mrecord]
match [label="Frame|\"match\"|score.Max()==3"]
wtp1 [label="WTP"]
set [label="Frame|\"set\"|score.Max()\>=6 && \nMath.Abs(score[0]-score[1])\>=2"]
wtp2 [label="WTP"]
game [label="Frame|\"game\"|score.Max()\>=4 && \nMath.Abs(score[0]-score[1])\>=2"]
play [label="SinglePlay"]
switch [label="Switch||(setNumber\<4 &&\n score[0]==6 && score[1]==6"]
wtp3 [label="WTP"]
tiebreak [label="Frame|\"tiebreak\"|score.Max()==7"]
play2 [label="SinglePlay"]
match -> wtp1 -> switch -> set -> wtp2 -> game -> play
switch:s -> wtp3:w
wtp3 -> tiebreak -> play2
{rank=same set wtp3}
// }
}
@enddot
----

And here is the code version of that diagram. This application passes an exhaustive set of tests for the scoring of tennis.

....
private IConsistsOf match = new Frame("match")
    .setIsFrameCompleteLambda((matchNumber, nSets, score) => score.Max()==3)
    .WireTo(new WinnerTakesPoint("winnerOfSet")
        .WireTo(new Switch("switch")
            .setSwitchLambda((setNumber, nGames, score) => (setNumber<4 && score[0]==6 && score[1]==6))   
            .WireTo(new Frame("set")                     
                .setIsFrameCompleteLambda((setNumber, nGames, score) => score.Max()>=6 && Math.Abs(score[0]-score[1])>=2)
                .WireTo(new WinnerTakesPoint("winnerOfGame")            
                    .WireTo(new Frame("game")          
                        .setIsFrameCompleteLambda((gameNumber, nBalls, score) => score.Max()>=4 && Math.Abs(score[0]-score[1])>=2) 
                        .WireTo(new SinglePlay("singlePlayGame"))
                    )
                )
            )
            .WireTo(new WinnerTakesPoint("winnerOfTieBreak")
                .WireTo(new Frame("tiebreak")          
                    .setIsFrameCompleteLambda((setNumber, nBalls, score) => score.Max()==7)
                    .WireTo(new SinglePlay("singlePlayTiebreak"))
            )
        )
    )
);
....

And just like that we have a full featured executable tennis scoring engine.

==== Final notes

Notice that I have added string names to the instances of Frame and other objects. This is not required to make the program function, but generally is a good habit to get into in ALA. It is because in ALA we typically use multiple instances of abstractions in different parts of the program. The names give us a way of identifying the different instances during any debugging. Using them I can Console.Writeline debugging information along with the object's name.

Around 8 lines of code express the rules of ten-pin bowling and around 15 lines of code express the rules of tennis. That sounds about right for the inherent complexity of the two games. The two rule descriptions actually execute and pass a large battery of tests. 

The domain abstractions are zero-coupled with one another, and are each straightforward to write by just implementing the methods of the IConsistOf interface according to what the abstraction does. The abstractions are simple and stable. So no part of the program is more complex than its own local part.

The domain abstractions are reusable in the domain of game scoring. And, my experience was that as the details inside the abstractions were implemented, the application design didn't have to change. 

Why two example applications? The reason for doing two applications in this example is two-fold. 

. To show the decreasing maintenance effort. The Tennis game was done easily because it reused domain building blocks we had already created for bowling.

. To emphasis where all the details of the requirements end up. The only difference between the bowling and tennis applications is the two diagrams, which are translated into two code files: bowling.cs and tennis.cs of 8 lines and 15 lines respectively. These two files completely express the detailed requirements of their respective games. No other source files have any knowledge of these specific games. Furthermore, Bowling.cs and Tennis.cs do not do anything other than express requirements. All implementation to actually make it execute is hidden in domain abstractions and programming paradigm abstractions. 



Here is a link to the code on Github: https://github.com/johnspray74/GameScoring[GameScoring code]



== Chapter five - Methodology


=== The first few strokes

As a software engineer contemplating a new project, I have often asked myself "Where do I start?" This also happens with legacy code, when contemplating the direction that refactorings should take. "If this software were structured optimally well, what would it look like?"

Christopher Alexander, the creator of the idea of design patterns in building architecture, said, "As any designer will tell you, it is the first steps in a design process which count for the most. The first few strokes which create the form, carry within them the destiny of the rest". This has been my experience too.

In Agile, where architecture is meant to emerge, this wisdom has been lost. ALA restores that wisdom to software development, and gives the software architect the exact process to follow for that little piece of up-front design. No more than one sprint is required to do this architectural work, regardless of the size of the project.

Furthermore, once this architectural work is done, the Agile process works significantly better thereafter. 

My experience over several projects so far is that the initial architecture does not need to change as the development proceeds if good quality abstraction are invented.




=== Agility

ALA is inherently optimally agile (except for an Iteration zero which we will discuss next). By optimally agile, we mean that the amount of code that changes to change functional requirements is the minimum it can be. The amount of code that actuall depends on requirements is a small percentage of the total. This differs from the average application where most code depends on the requirements.

ALA achieves this at its first level of separation of concerns. This first  separation is to separate code that will just describe requirements from code that will implementation the abstractions needed to describe the requirements. This implementation code never has knowledge of any requirements, so it generally doesn't change when requirements change. Only the code that describes requirements needs to change, and that code is optimally minimal.



==== Iteration zero

When a new project begins, the only new information we have is the requirements. Any design decisions that don‚Äôt depend on the specific requirements could already have been made beforehand. It is those decisions that form the ALA reference architecture. Therefore, when we get the requirements, that is our immediate and total focus. We may not know all of them, but we will only need a sample to build start inventing our domain abstractions. 

Looking at the available new information as a whole first instead of taking it a bit at a time during the project's sprints will make a huge difference to the quality of the abstractions we invent, and eventually the quality of the application's architecture.

The process in the first iteration takes requirements one by one, and represents them, in all their detail. Domain abstractions will be invented as you go, and they will have parameters or properties that will handle those details from requirements. 

For the first green field application, you spend a maximum of one sprint. After that you do need to find out if your design works. So you may not get through all the known requirements. That does not matter. 

To know whether knowledge from your design goes in the application layer or the domain abstractions layers, you consider what the scope of that knowledge is. Is the knowledge specific to this one requirement in the one application, or is it potentially reusable in the same or other applications? A softkey label is clearly specific and goes in the application. The concept of softkeys is clearly a domain abstraction. 

The output of the first sprint does not implement any of the invented abstractions, but it does include all details of the requirements that are looked at. In so doing, you design the first approximation of a DSL. The DSL may be refined later as more requirements are looked at.

Each abstraction will eventually be implemented as a class, but initially we just record the names of the abstractions, and a short explanation that provides the insight into what the abstraction does. 

By the end of the first sprint the requirements will have become easier and easier to represent, as the set of abstractions will have taken shape. Sometimes you will generalise an abstraction further to enable it to be useful in more parts of the application.

By keeping moving through the requirements at a much faster pace than in normal development (say one feature per hour instead of one per week), we can keep representing them in a coherent way, revising abstraction ideas we have already invented. Ideally, we will end up with a set of domain abstractions that can be wired together in different ways to represent the requirement space - the space of all possible requirements. That space, which we call the domain, will grow slightly as time goes on and it accommodates a growing family of products, but we don‚Äôt want it to grow beyond that. We don‚Äôt want to invent ways of implementing things we will never do.

On the other hand, we do want to invent quite a few abstractions during this first iterations so that we end up with a coherent set of them that will compose together in an infinite variety of ways.

The output of sprint zero is usually a diagram showing the wiring of instances of abstractions, together with configuration information for those instances.

It doesn‚Äôt matter if some of the requirements are wrong. Chances are they are still useful for scoping out the domain space. What we are actually producing in this phase are the necessary abstractions for the Domain Abstractions layer. If the requirements change later, it will be trivially simple to change them as only the Application layer wiring should change.

Once this process has started to become easy, which should happen within the first sprint, the burning question in our minds will become ‚ÄúWill all this actually work?‚Äù We have to trust that there will be a way to write those abstractions to make the whole system execute.

==== How to invent Domain Abstractions

The most difficult part for people new to ALA is the skill of inventing the domain abstractions. You can fully understand the theory of ALA and why we need to invent abstractions, and still find it tricky to actually invent them. That's because in this step in the process, we have to literally become inventors who are adding to the state of the art within your domain.

So the biggest insight I can offer here is don't expect it to come without effort. Put your inventors hat on. Deliberate about the problem over a long period of time. Leave it overnight. Come back to it afresh in a week. Be patient. 

I sometimes find that a solution will pop out of nowhere while reading about something completely unrelated. Once the human mind has been deliberating for some time, it remembers the whole context of the problem, and seems to carry on pattern matching for potential solutions in the background. I am reminded of the story of the Dam Busters. The British wanted to bomb the German dams to flood the industrial valleys below them. They worked out that they could deliver the bombs to the face of dam by skipping them across the surface of the lake. But they couldn't get their bomber low enough to the water at night to get them to skip, because they had no way of knowing their height above the water.

Then one of the pilots was attending a play. He saw the spotlights pointing at the actor from different angles. And suddenly he had the solution. By mounting spotlights at the nose and the tail of the aircraft at a certain angle, they would know when they were at the correct height when the two spots came together at the surface of the water.  

In my experience, there is always a solution, and it is always worth the effort. Just as good inventions are like gold, good abstractions are like gold in your application.

This section offers some practical tips on where to start.

* You start by simply expressing requirements. You are inventing domain abstractions to allow you to express the requirements succinctly, but including all their details. 

* Draw a diagram that describes the requirements. You will draw boxes with lines. The boxes are your invented domain abstractions. The lines are your invented programming paradigms.

* Look at the English version of the requirements for words that recur. These are candidates for abstractions. 

* Your diagram should have about the same amount of information as the English requirements. It will be succinct, even though it will include lots of detail such as text strings that come from requirements. Anything else that even begins to look like implementation or how it will work or execute is the beginning of an idea for an abstraction. Don't worry about them. Just concentrate on making a description of requirements. 

* Always keep in mind that reusability and abstraction are two sides of the same coin. Your invented abstractions are anything that is potentially reusable.

* Start with the user interface. Sketch multiple parts of the UI to make it more concrete. Then it is relatively easy to invent abstractions for your UI. They are things that will recur in different parts of the UI that you will always want to be done the same way. We can draw inspiration from the many widgets we already find in UI frameworks. ALA will often have equivalent ones that are just a little more specialised to your domain. Buttons may have a consistent size and style in your domain. Or your domain may need Softkeys, which are not usually part of a UI framework.
+
ALA UI abstractions will usually be composed together in a tree structure representing the containment structure. This is similar to the tree structure of XAML, but in ALA we will usually do it as a diagram that is just one part of the entire application diagram.

* Once you have designed some UI, you will then want to connect the UI elements that display data to some data sources. These data source are candidates for abstractions. For example, a data source that represents a disk file can be an abstraction that handles a disk file format. You will start to have dataflows between instances of data sources, be they UI elements or other source/destinations.

* Between your data end points, data may need to be transformed, aggregated, filtered, sorted, validated or transacted (transacted means either all of it or none of it). All of these are great candidates for domain abstractions.

* Sometimes a data source or destination will involve a protocol. A protocol is a domain abstraction. One abstraction should be invented to know about the protocol so that no other abstraction needs to know anything about the protocol. Sometimes there are protocols on top of protocols. For example, on top of a serial data stream protocol such as line terminated text, you may have another protocol that specifies the expected content of the first line.
+
This same idea applies to file formats. A file format, such as a CSV file becomes an abstraction. If there is further formatting expected on top of the basic CSV format, such as a header row, that becomes a second abstraction.
+
As with all abstractions, these abstractions know all about the details of something, e.g. a protocol or a format, and become the only thing in the entire application that does know about it.
+
As a result these types of abstractions will usually handle the data going in both directions - sending and receiving, reading and writing.   

* If you have hardware devices, each will become an abstraction. For example, an ADC device will become a domain abstraction. The abstraction will know all the detail about the device (everything that is in the datasheet for the device). No other part of the program will know these details.
+
If you have an ADC device that has an SPI interface, that will become two abstractions, one that knows all the details of the device, and one that knows all the details of the basic SPI interface. 

* Sometimes a section of requirements will seem like it should become a 'module' or 'function' - for example to parse a string. Try to turn the module or function into something more generally useful. Even if you still end up having only one instance of it for now, by separating that module or function into a general part and a configuration part (that has the information for it's specific use in the one part of your application), you will make the general part easier to know what it does - simply because it is more abstract. In time you will often generalise it further and start to have instances of it elsewhere.   

* If all else fails, just start writing code that implements the requirements in the old fashioned way, not worrying about how messy it gets. When it is functioning as you want, then refactor it to ALA as follows. This is actually quite a straightforward process.
+
Any code that has details that come from requirements, move that to the application layer, leaving behind generalised functions or classes that have parameters or configuration properties that the application will pass in.
+
At first the generalised classes may have only one instance each. Look for ones that have similar functionality and combine them. The difference between them become further configuration properties, sometimes in the form of lambda expressions. 
+
Now refactor the generalised classes or functions so that they do not call each other directly.
+
** In the case of functions, this step will involve adding new 'wiring' parameters that themselves take functions. The application will pass in the function that it needs to be wired to. These wiring parameters will usually either be to pull the input or push the output. The wiring function signatures should be even more generalised to allow Lego-like composition of functions by the application. They become interfaces in the programming paradigms layer. Section 1.11 has a worked example of refactoring of functions to ALA. 
+
** In the case of classes, this step will involve adding dependency injection setters. These will be used by the application to specify what class and instance it will talk to. This step removes all uses of the "new" keyword from the class (except ones that are instantiating classes in a lower abstraction layer such as your framework). 
+
If you have any uses of the observer pattern (publish/subscribe pattern), move the code that does the actual registering or subscribing up to the application. Provide a dependency injection setter for it to use.
+
The dependency injection setters should all take generalised interfaces as thier parameter to allow Lego-like composition of class instances by the application.

Your classes and functions are now proper abstractions because they don't know anything about the outside world, including who they are wired to, making them reusable.



==== 2nd Sprint

In the second sprint we start converging on normal Agile. You pick one feature to implement first. Agile would say it should be the most essential feature to the MVP (minimum viable product), but this can be tempered by the need to choose one that requires a fewer number of abstractions to be implemented. Next, you design the interfaces that will allow those abstractions to plug together according to the wiring you already have from the first sprint. What messages will these paradigm interfaces need to pass at runtime between the unknown clients to make them work?

It may take several sprints to produce the first working feature, depending on the number of abstractions it uses. 

At first this sounds as if it might be just the waterfall method reincarnated. Do an overall design, document it or model it, and then write lots of code before everything suddenly starts working. But the design we created in iteration zero is very different from what a normal waterfall would produce, and is resilient to the sorts of problems waterfall creates. Instead of a ‚Äòhigh level‚Äô design of how the implementation will work which is lacking in detail, the design is a representation of requirements, in full detail. The design is not a model. It is executable.

There is one more important thing that the design phase in Iteration Zero does. While it deliberately doesn‚Äôt address any implementation, it does turn the remainder of the implementation into abstractions, and those abstractions are zero coupled. To convert from executable to actually executing, it only remains to implement these now completely separate parts. You can give these abstractions to any developer to write.  Together the developers will also easily be able to figure out the paradigm interface methods needed to make them work, and the execution models to take care of the execution flow through them with adequate performance.

Often when a project is split into two phases, the first phase turns out to be waste. The devil is in the details so to speak. This happens because the implementation details in phase two are coupled back to and affect the design in phase one. As learnings take place during implementation, the design must change. In ALA the output from phase one is primarily abstractions, which are inherently stable and therefore hide details that can't affect the overall design. If the abstractions are good, phase two will typically have little effect on the work done in phase one.

Once the first feature is working, several abstractions will have been implemented. The second feature will take less time because some of the abstractions are already done. In ALA velocity increases as time goes on and keeps increasing until new features only involve instantiating, configuring and wiring domain abstractions in new ways. This velocity acceleration is the complete opposite of what happens in monolithic code.

==== Later sprints

Imagine going into a sprint planning meeting with a Product Owner, a small team of developers, and a mature ALA domain that already has all the common domain abstractions done. As the Product Owner explains the requirements, one of the team members writes them down directly as they would be represented in terms of the domain abstractions. Another team member watches and remembers any lost details without slowing the product owner down. A third member implements the acceptance tests in similar fashion, and a fourth provides him with test data. It would be nice to have a tool that compiles the diagram into the equivalent wiring code. With such a tool, the team could have it executing by the end of the meeting. At the end of the planning meeting the development team say to the product owner "Is this what you had in mind?". The team can get immediate feedback from the Product Owner that the requirements have been interpreted correctly. 

Of course, the planning meeting itself would only produce 'normal' functionality. Usually it is up to the development team, not the Product Owner, to uncover all the abnormal scenarios that can happen, and that is usually where most of the work in a software system goes. Having said that, in a mature domain, the validation of data already has decorator abstractions ready to go.


[chart,line,file="effort_curve.png", opt="title=Effort per user-story,x-label=months"]
--
//Big ball of mud
1,	5
2,	5
3,	6
4,	6
5,	7
6,	8
7,	9
8,	10
9,	12
10,	13
11,	15
12,	17
13,	19
14,	21
15,	24
16,	28
17,	32
18,	37
19,	43

//Cocomo
1,	16
2,	17
3,	17
4,	18
5,	18
6,	19
7,	19
8,	19
9,	19
10,	20
11,	20
12,	20
13,	20
14,	20
15,	20
16,	20
17,	21
18,	21
19,	21
20,	21
21,	21
22,	21
23,	21
24,	21

//ALA
1,	30
2,	21
3,	17
4,	15
5,	13
6,	11
7,	10
8,	9
9,	8
10,	8
11,	7
12,	7
13,	6
14,	6
15,	5
16,	5
17,	4
18,	4
19,	3
20,	3
21,	3
22,	2
23,	2
24,	2
--

The graph shows the effort per user story against months into a green-field project. The left axis is arbitrary - the shape of the curves is what is important. For a big ball of mud, experience tells us that the effort increases dramatically and can asymptote at around 2 years as our brains can no longer handle the complexity, and the project must be abandoned.

The COCOMO model, which is an average of industry experience, has a power relationship with program size, with an exponent of around 1.05 to 1.2. I have used the mid point, 1.1, for this graph. The model appears to imply that getting lower than 1.0 is a barrier, but there is no reason to believe this is the case. Reuse can make the power become less than 1. The range of 1.05 and 1.2 probably results from some reuse mitigating some ever increasing complexity.

ALA takes advantage of the fact that zero-coupled abstractions can keep complexity relatively constant and drastically increase reuse. A spectacular fall in effort per user story is thus possible.  

=== Technical debt

Technical debt is real. Convincing your non-technical manager that it is real is not realistic, especially when you tell him that this is based on estimates. He already knows about your 'estimates'. Even if you could measure it, and offer your manager a payback period for a one-day investment in refactoring, there is a problem. He is measured on this sprints performance. Or he is measured on some other criteria such as this years budgeted sales. Technical debt is tomorrow's problem, and that is not his problem, not ever.

A better answer would be to not generate technical debt in the first place. In Agile we are taught that the architecture depends on the what we learn as we write the code. The Definition of Done is supposed to tell us to clean it up as we learn. But it is also possible that we will learn something that requires previous sprint's of work to be cleaned up. A refactoring could need changes to the structure at the largest granularity level. 

So here is a better solution. What if, as far as possible, we know a meta architecture that all software programs should follow. It is a big scale meta-architecture, so it gets things into the right places in the big scale. 

So now you just get it right in the first place. Isn't that better?

Now some will argue that they do that already. Their large scale structure is layering, or it is MVC or it something else. I have been told that this doesn't work because we fail to actually keep to the prescribed architecture. But think it is because up till now, these architectural patterns have not worked very well.



=== Folder structure

....
[tree,file="folderstructure.png"]
root
|--Application1
|  `--application.cpp
|--Application2
|  `--application.cpp
|--DomainAbstractions
|  |--abstraction1.cpp
|  |--abstraction1.h
|  |--abstraction2.cpp
|  `--abstraction2.h
`--ProgrammingParadigms
   |--Paradigm1.h
   `--Paradigm2.h
....



////
....
[tree,file="folderstructure.png"]
root
|--Domain1
|  |--Application1
|  |  `--application.cpp
|  |--Application2
|  |  `--application.cpp
|  |--DomainAbstractions
|  |  |--abstraction1.cpp
|  |  |--abstraction1.h
|  |  |--abstraction2.cpp
|  |  `--abstraction2.h
|--Domain2
`--ProgrammingParadigms
   |--Paradigm1.h
   `--Paradigm2.h
....
////


////
[tree,file="folderstructure.png"]
#root
##DomainProjects
###Application1
####Application.cpp
###Application2
###DomainAbstractions
####abstraction1.cpp
####abstraction1.h
####abstraction2.cpp
####abstraction2.h
##HardwareDomain
##ConnectivityDomain
##DatabaseDomain
#ProgrammingParadigms
##Paradigm1.h
##Paradigm2.h
////
// (TBD - The folder structure feature of AsciiDocFX causes it to hang)

This is a suggested folder structure for ALA. Because ALA does not use decomposition, you don't end up with components that are contained by the applications, so there are no subfolders under the application. Instead, you end up with Domain Abstractions outside the application, so they go in their own folder in a flat structure.

Similarly, the Programming Paradigms code is not contained by an application, or even by the domain, so would not be contained by the domain's projects folder.

=== Convention over configuration

When the application create an instance of an abstraction, most of the configuration of that abstraction should have defaults. In ALA, setters allow optional configuration, reducing the amount of information that would otherwise be required in the application to fully configure each abstraction. Any configuration that we wish to enforce goes into the constructor.

There is a counter argument that says that all configuration should be explicit so that nothing can be forgotten. ALA prefers optional configuration because we want the application to just express the requirements. Also optional configuration allows abstractions to default to their simplest form, making them easier to learn.


=== Knowledge prerequisites.

When other programmer are doing maintenance on your code, you should make sure they have the knowledge they need. They will need knowledge of ALA. They will need to know about the programming paradigms used. They will need to know about the domain abstractions, and the insight of what each one does. And then they should know that the application diagram is the source code. It is up to you that every develop that follows will know all this.

==== Intellisence

After they have modified the diagram, the maintaining developers will need to manually modify the corresponding code. Here they will see instances of abstractions being used all over the place, either 'new' keywords or function calls. If we have done our job with knowledge prerequisites, they will have been introduced to these abstractions. However, it doesn't hurt to have brief reminders of what they are pop up when the mouse is hovered over them. So put in triple slash comments (or equivalent) describe the abstraction succinctly, with the intention of it being a reminder to someone who has already met the abstraction. Put a full explanation in the remarks and examples sections. 

The class name after a new keyword is actually the constructor name, so you must duplicate the summary section there. Often in ALA, the class name is not referred to at all in the application.

=== Two roles

ALA requires two roles. Both can be done by the same person, but always he should be wearing only one hat at a time. There is the role of the architect, and the role of the developer.

The role of the architect is harder than that of the developer, that's why we have the role. Expect it to be hard.
Perhaps, surprisingly, the architect's main job is to focus on the requirements, and the developers main job is to implement the abstractions (which know nothing of the requirements). In describing the requirements, the architect invents domain abstractions. 

The architect also has a role in helping the developer to design the interface's methods. In other words, how at runtime the system will be made to work. 

This aspect of ALA can also be difficult at times. I have sometimes got stuck for a day or so trying to figure out how the interfaces should work, while still keeping them more abstract than the domain abstractions. The ALA constraints are that these interfaces should work between any two domain abstractions for which it may be meaningful if they are composed together in an application. However, the problem has always been solvable, and once solved, it always seems to have a certain elegance, as if you have created a myriad of possibilities at once. Implementation of the interfaces by the relevant domain abstractions becomes easy. Development then proceeds surprisingly quickly.     



=== Example project - a real device

Unlike our previous example projects, this project is a real device and had previously been implemented without any knowledge of ALA. So this example serves to make comparisons between ALA and conventional software development. The original software was around 200 KLOC and took 3 people 4 years to write. 

The actual device is used by farmers all over the world. It can weigh livestock and keeps a database about them for use in the field. It connects to many other devices and has a large number of features: 

image::Tru%20Test%20XR5000%20Weigh%20Scale%20Indicator.jpg[Tru Test XR5000 Weigh Scale Indicator.jpg, title="Livestock weighing indicator", width=75%]

The architecture in the original software, was somewhat typically organised into modules and patterns by its developers. Also somewhat typically, it had ended up with a high cost of modifiability - a big ball of mud. After the first release, the first incremental requirement was a 'Treatments' feature, which involved several new tables, new columns in existing tables, new data pages, new settings pages and some new business logic. This feature took a further 3 months to complete (actually 6 calendar months), which seemed out of proportion for the size of the feature. Somehow the Product Owner and managers seemed to have a sort of intuition that if similar things had been done before, such as menus or database tables, those things were already done, and the only new work was in the specific details of the new requirements. Those requirements could be communicated in a relatively short time, say of the order of one hour or one day if you include follow up discussions of abnormal scenarios.  So 6 months did not go down well. ALA, of course, works in exactly this intuitive way that managers hope for. All the things already done are sitting there in the domain abstractions, waiting to be reused, configured and composed into new requirements.

==== Iteration zero

During the development, there had a been a high number of changes required to the UI. It occurred to me at the time that the underlying elements of the UI were not changing. It was mainly the details of layout and navigation around the device's many pages that were changing. The same could be said about the data and business logic. Only details were changing. 

I took to representing the new designs using box and line drawings representing both the UI layouts and the navigation flows. I realized these diagrams were potentially executable, and wondered how far I could go representing the data and business logic in the same way. I decided to try to represent all of the functionality of the indicator in just one  diagram.

It took two weeks to complete the diagram. I used Xmind because it laid itself out. I found that any drawing package that needed you to stop and do housekeeping such as rearranging the layout got in the way so much that you would lose your flow. Xmind allowed me to just enter in the nodes and it would automatically wire them in as either peers or chains and lay them out. The one disadvantage was that Xmind only does trees, so any cross tree relations had to be done manually, but this was also very quick in Xmind once you were used to it. I just let the cross wiring form arcs across parts of the tree.

Progress was extremely rapid once you had the abstractions and paradigms you needed. And many of them were obvious: softkeys, pages, grids, menus, actions, navigate-action, tables. etc. The programming paradigms would pop into play as needed. After the obvious UI-layout and navigation-flow ones came data-flow and data-flow of table types, events, and schema. The user of this device could set up custom fields, so the schema itself partially came from another  table. At times I would get stuck not knowing how to proceed. The longest of these blocks was half a day. But every time the required abstractions or programming paradigms would firm up, and in the end anything seemed possible.

The diagram itself took shape on the right hand side of the Xmind tree. On the left side I had the invented domain abstractions and paradigm interfaces, with notes to explain them. The right side was mostly just a set of relatively independent features, but there was the odd coupling between them such as UI-navigation lines that were also present in the requirements.

The diagram contained around 2000 nodes (instances of the abstractions), which is about 1% of the size of the total original code. There were about 50 abstractions, and several paradigm interfaces.

Part of the diagram is shown below (laid out more nicely in Visio)

image::All%20Animals%20Screen%20V3.png[All Animals Screen V3.png, title="Application diagram for the All Animals View feature", link=images/All%20Animals%20Screen%20V3.png]

As I did the diagram, I deliberately left out anything to do with the aforementioned Treatments feature, so that I could see how easy it might have been to implement once the domain abstractions for the rest of the requirements had matured. So after the diagram was completed, I added the Treatments feature. This involved adding tables, columns to existing tables, a settings screen, a data screen, and some behaviours.  No further abstractions needed to be invented. The incremental time for the diagram additions was of the order of one hour. Obviously testing would be needed on top of that, and the 'Table' abstraction would need additional work so it could migrate itself, a function it had not needed up until this point. Although somewhat theoretical, the evidence was that we could get at least an order of magnitude improvement in incremental maintenance effort.

At first the diagram seemed too good to be true. It had an elegance all of its own. It apparently captured all of the requirements, without any implementation at all, and yet seemed potentially executable. And if it worked, application modifications of all the kinds we had been doing were going to be almost trivial.

The burning question on my mind was, is it simply a matter now of writing a class for each of these abstractions and the whole job is done?

==== Translating the diagram to code

We hired a C++ student and proceeded with a 3-month experiment to answer this question.

It was a simple matter to translate the diagram into C++ code that instantiated the abstractions (classes), wired them together using dependency injection setters, configured the instances using some more setters, and used the fluent interface pattern to make all this straightforward and elegant. Part of the code for the diagram sample above is shown below to give you a feel for what it looked like.

....
m_animalListScreen
	->wiredTo((new Softkeys())
		->wiredTo((new Softkey())
			->setTitle("History")
			->wiredTo(new Navigate(m_animalHistoryScreen))
		)
		->wiredTo((skeyOptions = new Softkey())
			->setTitle("Options")
			->wiredTo(new Menu()
				->wiredTo(new Navigate("Session...", m_sessionSummaryScreen))
				->wiredTo(new Navigate("Settings...", m_settingScreen1))
			)
		)
	)
	->wiredTo((searchField = new TextDisplayField())
		->setLabel("Search")
		->setField(VIDField = new Field(COLUMN_VID))
	)
	->wiredTo(new Grid()
		->wiredTo(columnOrder = new ColumnOrder())
		->setRowMenus((new EventHandler())
			->setEvent(EVT_KEY_ENTER)
			->wiredTo(new Menu()
				->wiredTo(new Navigate("View information for this animal", m_animalSummaryScreen))
				->wiredTo((new Action("Delete Record", AnimalsTable::DeleteRow))->wiredTo(AnimalsTable))
			)
		)
	);
....

==== Writing the classes

We knew we wouldn't have time to write all 50 classes, so we chose to implement the single feature shown below as a screen shot. 

image::XR5000ScreenShot.jpg[XR5000ScreenShot.jpg, title="All Animals view in the weighing indicator", width=75%]

The student's job was to write 12 abstractions out of the 50. These 12 were the ones used by that feature. The initial brief was to make the new code work alongside the old code (as would be needed for an incremental legacy rewrite), but the old code was consuming too much time to integrate with, so this part was abandoned. 

The learning curve for the student was done as daily code inspections, explaining to him where it violated the ALA constraints, and asking him to rework that code for the next day. It was his job to invent the methods he needed in the paradigm interfaces to make the system work, but at the same time keep them abstract by not writing methods or protocols for particular class pairs to communicate. It took about one month for him to fully 'get' ALA and no longer need the inspections.  

// image:All%20Animals%20Screen%20V3.svg[]

The student completed the 12 classes and got the feature working in the device. The feature included showing data from one database table in a grid, sorting, searching, softkeys, and a menu.

Interestingly, as the student completed certain abstractions that allowed parts of other features to be done, he would quickly go and write the wiring code and have the other features working as well. For example, after the softkeys, actions, navigate, and page abstractions were done, he went through and added all the softkey navigations in the entire product as this only took minutes to do. 

We wanted more funding to retain the student until we had enough to do the treatments feature, and indeed all 50 abstractions with the hope of making this implementation the production code and improving our ongoing maintenance effort. But that was not to be, despite the promising result.

We have about a quarter of a data point. Some of the abstractions done were among the most difficult, for example the Table abstraction, which had to use SQL and a real database to actually work. So it is not unreasonable to use extrapolation to estimate that the total time to do all 50 abstractions would be about one person-year. That compares with the original 12 person-years. 

It seems that classes that are abstractions are faster to write. This seems intuitive because you don't have any coupling to worry about. More importantly, the two phase design-then-code methodology of ALA allows the developer not to have to deal with large scale structure at the same time as writing code. This frees the developer to go ahead and write the code for the local problem.

I believe it is beneficial for each developer to be trained to be both an architect and a developer, but just don't ask them to do both at the same time.

This practical result combined with the theory outlined earlier in this article suggests there ought to be a large improvement in incremental maintenance effort over a big-ball-of-mud architecture.











== Chapter six - The philosophy behind ALA


=== The human brain

In this perspective of ALA, we look at the problem of complexity in software in the context of how the human brain works.

Software design involves our intelligence or brain power. Understandability, readability, complexity are all things very closely related to the brain. Yet in the field of software engineering we pay little attention to how the brain understands our complicated world in order to understand how we should do our software.

Our brains do it primarily through one mechanism which we have come to call 'abstraction'. We learn abstractions from the commonality of multiple examples, and we then use abstractions without those examples cluttering up the common notion that was learned.

image::Paintings_from_the_Chauvet_cave.jpg[Paintings_from_the_Chauvet_cave.jpg,400, title="Paintings in the Chauvet cave", float="right"]

Our ancestors could use a word like 'bring your spear' and it had a simple meaning to them only because all the detail and knowledge that went into building a spear was replaced with the abstraction 'spear'. Without the abstraction, the sentence would have had to be more like "bring the object that we made by joining the object we made by applying blows to the hard material we found at the place..., with the long material we cut in the place with the tall..., by tying it with the long grass material using the gooey stuff we found at the...". Even this sentence was only made possible by other abstractions: joining, material, blows, hard, long (twice), cut, tall, tying, gooey, and found. If we expanded all of them until we were only using a few basic concepts like 'object' and 'place', we would have a sentence so long that we could never communicate at all. That's what abstractions do, and how our brains make use of them. The word spear, in turn can be used to create a new abstraction, a hunting plan, while all of that other detail remains hidden from that new context.

The problem with software engineering is we are not making use of this way that the brain works. Simply put, we are not creating good abstractions. This lets the complexity inside one 'module' spill out into other modules. Abstractions, not modules, are the only mechanism that allows us to hide details at design-time. 

image::neuron.svg[neuron.svg, 300, title="", float="left"]

As software engineers we do learn and use many abstractions. For example if we want to protect simultaneous access to the resource, our brain should conjure up 'mutex'. 

If the brain already 'knows about' an abstraction, the abstraction is like any other single line of code, such as a mutex. We can make use of a mutex without having to deal with the details and complexities of how it works. We don't have to think about the fact that we may have to wait for the resource. Nor that another thread may start running if we have to wait. Nor that if a higher priority thread preempts us while we have the resource, we may have it for a long time. Nor that if a still higher priority thread needs it during that long time, we will be given temporary priority to finish our use of it. We can just simply use the abstraction for protecting a resource.

Abstractions like mutex, regex, SQL are already invented by the 'culture' of software engineering, much like memes in the real world have been passed down to us. Where we fall down is when we get into a particular domain where the abstractions have not yet been invented, and we need to invent them. It is not easy to invent new abstractions, but invent them we must, at a rate far higher than is normal for cultural evolution.

Good domain abstractions, introduced and learned by new developers in the domain, then appear to them as normal program elements - things they can use with extraordinary convenience like any other line of code.



=== Abstraction

Of the overwhelming list of engineering topics that we listed in Chapter One, this topic that is the most fundamental to ALA, and the one most needed for explaining it. It's also probably the vaguest and most misunderstood topic in software engineering, so we will spend some time understanding it.

Abstraction will be the king. The short reason why we start with abstraction is that our quality attributes, complexity and understandability are very much to do with how our brains work, and for 100,000 years at least, our brains have worked with abstractions to understand our world. Abstractions are the only mechanism our brains use for dealing with otherwise complex things. 

As in a chess game, winning is only about protecting the king. But this Abstraction king is benevolent. If he is destroyed, you do not lose the game immediately. It will take time, but you will lose.

There are other contenders to be king in the engineering topics list. For example, it is said that the best thing about TDD is not the testing but the emergence of better abstractions. TDD is like a lord that serves the king. It usually serves the king, causing you to make better abstractions. But sometimes it just serves its own purpose and makes the abstraction worse. It just produces code that works where it passes and no more.

Another contender is microservices. It is popular because it improves your abstractions by making them harder to destroy with cross coupling. But it too is just a lord. Because it provides physical boundaries that in normal software would be crossed, it serves the king. But by serving the abstraction king directly we can have logical boundaries, and all their benefits, even in 'monolithic' code.

Another contender to be king is 'no side effects' used by the functional mathematical purity guys. There are those who talk as if disobeying this king is absolute treason. But again, this lord is only effective because he usually serves the abstraction king. But, again, there are times when he doesn't, and 'no side effects' is not enough to make a good abstraction.

ALA always follows the one true king.

==== Classes, Modules, functions and encapsulation. 

Classes, Modules, functions and encapsulation are artefacts of the language and do their thing at compile-time. They are not necessarily abstractions. They have been around for about 60 years, not enough time for our brains to see them in the same way as the compiler does. Although abstractions are implemented using these artefacts, ALA needs them to also be abstractions. In ALA "abstraction" is the term we use for the artefacts of our design instead of classes, modules, functions, or components, all of which are extremely fragile as abstractions.  

==== Wikipedia on abstraction

"Thinking in abstractions is considered by anthropologists, archaeologists, and sociologists to be one of the key traits in modern human behaviour, which is believed to have developed between 50 000 and 100 000 years ago. Its development is likely to have been closely connected with the development of human language, which (whether spoken or written) appears to both involve and facilitate abstract thinking."

In the real world, new abstractions come along infrequently, and are conceived of by few. People quickly begin using them to understand new insights or compose new things. They become so natural to us that we forget that they are abstractions. In no other field do we need to create them as fast as in software engineering. It is the most important skill a developer needs to have.

==== Defining abstraction

The term abstraction is arguably one of software engineering's vaguest or most overloaded terms. Because it is the most fundamental concept in ALA, we try to provide a definition. I find the easiest way to define it is to provide a set of 'statements about', 'properties of', or 'what it is nots':

* Etymology: 'to draw out commonality'

* The concept or notion drawn out of what is common in multiple instances

* Because it is a 'commonality', it is inherently reusable. Kruger says that  abstraction and reuse are two sides of the same coin.

* Has inherent stability - as stable as the concept itself

* The only mechanism that separates and hides _design-time_ knowledge

* Its concept or notion is easier to remember than its implementation. For a good abstraction, it is much, much simpler. 

* Abstractness increases with scope of reuse

* Knows nothing about peer abstractions

* use ports (instances or interfaces) for IO instead of directly calling other abstractions.  

* Abstractness decreases with more ports

* Abstractness decreases as you get closer to your specific application

* Abstractness is not how far you are above physical hardware

* An ability our brains evolved understand the world

* The only way we have of dealing with complexity 


==== The three stages of creativity

image::creativity.jpg[creativity.jpg, title="The creativity cycle", width=80%, align="center"]

A good abstraction separates the knowledge of different worlds. A clock is a good abstraction. On one side is the world of cog wheels. On the other side is someone trying to be on time in their busy daily schedule. Neither knows anything about the details of the other. SQL is another good abstraction. On one side is the world of fast indexing algorithms. On the other is finding all the orders for a particular customer. Let us consider a domain abstraction - the calculation of loan repayments. On one side is the world of mathematics with the derivation and implementation of a formula. On the other, the code is about a person wanting to know if they can afford to buy a house. If your abstractions don't separate knowledge of different worlds like this, then you are probably just factoring common code. Find the abstraction in that common code. Make it hide something complicated that's really easy to use and really useful, like a clock.

The creativity cycle starts with abstractions, such as cogs and hands, instantiates them, configures them for a particular use, then composes them into a new abstraction. In ALA we usually go around the creativity cycle three times, creating three layers on top of our base programming language.


==== Abstractions need ports

In traditional programs, inputs (or at least incoming function calls) are typically part of the module or class's interface but outputs (or at least outgoing function calls) are typically just buried in the code.

This is fine if calling functions or methods in a lower abstraction layer. However, it is absolutely not fine if calling functions or methods of a peer in the same abstraction layer. 

In ALA all inputs and outputs to or from peers in the same layer must be 'ports'. 
There should be one port for each peer that can be wired. This is the Interface Segregation Principle. A port is a logical wirable connection point. A port either implements or accepts an interface. Outgoing function calls buried in the code that at run-time will go to a peer must only go to the port, which has an indirection mechanism of some kind.

Programming languages encourage all outgoing function or method calls to refer directly to the destination, or the destination's interface, so you have to make an effort to avoid doing this.

A port is not an artefact of programming languages (yet) so they must be implemented logically somehow as normal code. To code a logical port, you need to do two things. 

. The interface type of the port must not be owned by another peer abstraction. The interface type must be from a lower abstraction layer.

. The name of the port is the name of the field that accepts the interface.

A port can have multiple interfaces. In this case I make the names of the multiple fields contain the port name.


If you are using an asynchronous event driven design, the equivalent of a conventional outgoing function call is typically written something like this:

 Send(Event, Receiver, Priority);

where the Event is something the receiver defines. 

Again, we are sending the event directly to a peer abstraction using the peer abstraction's interface (its event).

In ALA, sending an event should be self-oriented, so written something like this:

 Send(Sender, SenderPort)

The sender just sends the event out, not knowing where it goes, and the port identifies the event (or you could have both port and event). This just tells the event framework who the sender and sender's port was. The event framework gets information from the application in the top layer to know what to do with the event. The application has the specific knowledge to know what an event from a given sender on a given port means, and therefore where it should go, and what the priority should be.

In general, classes, modules, components, functions should all have ports for both input and output. They should not own the interface types for these ports, whether they are incoming or outgoing. 

An output port from an abstraction may say 'This has happened' or 'Here is my result', not 'do this next', or 'here is your input'.

There are multiple ways to implement the indirection inherent in ports for outgoing calls. They can be callbacks, signals & slots, dependency injection, or calls to a framework send function.

Note that inputs and outputs are not necessarily on different ports. We may want to wire both inputs and outputs between two instances or two abstractions with a single wiring operation. The general case is that a single wiring operation wires multiple interfaces that are logically one port. One contains methods going in one direction and the other contains methods going in the other.   



=== Complexity

==== Philosophy of complexity



==== Dijkstra on complexity

anchor:Dijkstra1[]

"It has been suggested that there is some kind of law of nature telling us that the amount of intellectual effort needed grows with the square of program length. But, thank goodness, no one has been able to prove this law. And this is because it need not be true. We all know that the only mental tool by means of which a very finite piece of reasoning can cover a myriad cases is called ‚Äúabstraction‚Äù; as a result the effective exploitation of his powers of abstraction must be regarded as one of the most vital activities of a competent programmer. In this connection it might be worth-while to point out that the purpose of abstracting is not to be vague, but to create a new semantic level in which one can be absolutely precise. Of course I have tried to find a fundamental cause that would prevent our abstraction mechanisms from being sufficiently effective. But no matter how hard I tried, I did not find such a cause. As a result I tend to the assumption ‚Äîup till now not disproved by experience‚Äî that by suitable application of our powers of abstraction, the intellectual effort needed to conceive or to understand a program need not grow more than proportional to program length."

The "conceive" part I agree with, if by that we mean the development. However, the "intellectual effort to understand" part needs further insight. We shouldn't have to read an entire program to understand a part of it. We ought to be able to understand any one part of it in isolation. The effort to read any one part should be approximately constant. In Chapter One of this article there was a quality graph of complexity <<ComplexityGraph1, here>>.

anchor:ComplexityGraph2[]

[chart,line,file="complexity_curve.png", opt="title=Complexity,x-label=KLOC,legend=right"]
--
//Big ball of mud
1,	10
2,	20
5,	50
10,	100
20,	200
50,	500

//Loosely coupled
1,	10
2,	14
5,	22
10,	32
20,	45
50,	71
100,100
200,141
500,224
1000,316

//ALA
1,	10
2,	11
5,	12
10,	13
20,	13
50,	15
100,16
200,17
500,19
1000,20

//Code writer's brain limit
1,	100
2,	100
5,	100
10,	100
20,	100
50,	100
100,100
200,100
500,100
1000,100

//Code reader's brain limit
1,	50
2,	50
5,	50
10,	50
20,	50
50,	50
100,50
200,50
500,50
1000,50
--

These graphs are qualitative in nature, based on experience. But now that we have a better understanding of ALA structure, we can explain how it manages to keep complexity from increasing.

In ALA, the design-time view of the system is nothing more than a static view of instances of abstractions composed together. In a typical application, there will be of the order of fifty different domain abstractions - not a difficult number to familiarize yourself with in a new domain. 

Abstractions have no relationship with one another. Each is a standalone entity like a standalone program. If every abstraction contains say 500 lines of code, and the system itself contains 500 lines (instances of abstractions wired together) then the most complex the software gets is that of 500 lines of code.

Even if one abstraction is overly complex internally, say it conceals a piece of legacy code using a facade pattern, that doesn't affect the complexity of any other part of the system.

ALA is based on the realization that abstraction is fundamentally the only mechanism available to us to achieve this constant complexity. 

When doing this for the first time in a domain, it's not easy to invent the abstractions. but the alternative is always runaway complexity.

[TIP]
====
The goal of software architecture should be to keep complexity constant. 
====




=== No Loose Coupling

Here we meet the first meme from our list of software engineering topics that we must throw out. To many, this will seem a surprising one. Yes, I am saying 'loose coupling' is undesirable.

==== A common argument

An argument is sometimes stated along these lines: "There must be at least some coupling, otherwise the system wouldn't do anything." Hence we have the common meme about "loose coupling and high cohesion". In this section we show how this argument is false and resolve the apparent dilemma. We will eliminate all forms of design-time coupling except one. That one remaining one is anything but loose and very desirable.



==== Classifying coupling

Think of some instances of dependencies you know of in a system and try to classify them into these three types by asking when the system would fail without it. 

For example, let's say that data flows from an ADC (analog to digital converter) to a display as part of a digital thermometer. At run-time, both must exist. At compile-time both must have the same method signature:

[plantuml,file="diagram-01.png"]
----
@startdot
digraph foo {
// size="4!"
graph [rankdir=LR]
ADC -> display [dir=forward, arrowhead=open, color=red]
}
@enddot
----

Or the display may tell the ADC when to do the conversion. At run-time there is temporal coupling. 

[plantuml,file="diagram-02.png"]
----
@startdot
digraph foo {
// size="4!"
graph [rankdir=LR]
ADC -> display [dir=both, arrowhead=none, arrowtail=open, color=red]
}
@enddot
----

In this one there is an association from a Customer class to an Account class to facilitate communication between them. At run-time there is coupling. At compile-time there is coupling too - the type of the Account class must be exactly the same as expected by the Customer class:

////
[plantuml,file="diagram-03.png"]
----
@startdot
digraph foo {
// size="4!"
graph [rankdir=LR]
Customer [shape=box]
Account [shape=box]
Customer -> Account [dir=forward, arrowhead=open, color=red]
}
@enddot
----
////

[plantuml,file="diagram-04.png"]
----
scale 2
class Customer
class Account
Customer->Account
----


In all the above diagrams, relationships shown in red indicate they are disallowed by the ALA constraints. Green is for desirable relationships, of which there is only one. When we disallow all these types of coupling, the modules, components, functions and classes can now be abstractions.


==== Run-time, Compile-time and Design-time

A few times already in the article, I have sneaked in a magic qualifier, 'design-time'. You know how we sometimes talk about run-time and compile-time with reference to binding. In ALA we recognise that understandability, complexity, etc, are all happening at design-time. By design-time I mean any time you are reading code, writing code, or changing code.

At run-time, the CPU processes data. At compile-time, the compiler processes code. At design-time the brain is processing abstractions. 

In conventional code, it is common for all forms of coupling, run-time, compile-time, and design-time, to appear as coupling between modules or classes.

You can work out what type of dependency you have by when it first breaks. A run-time dependency doesn't break until the program runs. The program can still be compiled and it can still be understood. 

A compile-time dependency first breaks at compile-time. At design-time the code can still be understandable. 

A design-time dependency prevents code from even being understood. The code loses its meaning. 


==== Layers

In everyday design, knowledge dependencies are not normally shown as lines. You simply use the abstraction by its name. But in this article, just so we can explain the meta-architecture, we will sometimes draw knowledge dependencies like this (always downward).

[plantuml,file="diagram-05.png"]
----
@startdot
digraph foo {
// size="3!"
C -> A [dir="both", arrowhead="open", arrowtail="diamond", color=green]
}
@enddot
----

This represents that the implementation of abstraction C knows about abstraction A. A is more abstract than C. C and A cannot therefore be peers, as was the case with the components above. Peer abstractions cannot have any coupling with one another.

==== Whole-Part pattern

If you are familiar with the Whole-Part pattern, ALA uses it extensively. But there is a constraint. The Whole-Part pattern is only used with knowledge dependencies (since that is the only relationship you are allowed). It may of course be used in other forms inside an abstraction, provided it is completely contained in a single abstraction.

A real world example of the Whole-Part Pattern with knowledge dependencies is Molecules and Atoms. A water molecule, for example, is the whole. 

[plantuml,file="diagram-06.png"]
----
@startdot
digraph foo {
// size="5!"
edge [color=green]
H2 [label=H]
Water -> O [dir="both", arrowhead="open", arrowtail="diamond"]
Water -> H [dir="both", arrowhead="open", arrowtail="diamond"]
Water -> H2 [dir="both", arrowhead="open", arrowtail="diamond"]
}
@enddot
----

Oxygen and hydrogen are the parts. Note that oxygen and hydrogen are abstractions, and they are more abstract than water because they are more ubiquitous, more reusable and more stable (as a concept) than any specific molecule. We could make a different molecule but still use exactly the same oxygen and hydrogen as parts to compose the new molecule.

NOTE: When we use the word 'ubiquitous', it refers to the number of times the abstraction is used in a Whole-Part pattern to make other abstractions. It doesn't refer to the number of abstractions that are instantiated. So just because there is a lot of water, that doesn't make the abstraction ubiquitous. In comparing the abstraction levels of Oxygen and Hydrogen with water, Oxygen and Hydrogen are more ubiquitous because they are used to make more abstractions than water is.  

The molecules and atoms analogy with ALA is very close, and we will return to it when we come to explain in more detail how run-time and compiler-time dependencies are moved inside a single abstraction.

For now we just need to remember that we are using the whole-part pattern with knowledge dependencies only. At design-time, the whole is explained and reasoned about in terms of the parts, just as the water molecule is in terms of the oxygen and hydrogen.

==== Run-time/design-time congruence

A software program can be temporally confusing. Everything that happens at design-time is in preparation for what will happen at run-time. Our low-level imperative languages tend to keep the two congruent. The statements in the program at design-time follow in the same order as they will execute at run-time. The only difference between the two is a time shift and the speeding up of the clock.

When we want the knowledge of run-time dependencies to be moved inside another abstraction, this congruence between design-time and run-time must be broken. Unfortunately, developers start out by learning a low-level imperative language, so it becomes unnatural to them to architect their programs without this congruence. Indeed, breaking this congruence needs a pattern to be learned, and then carefully protected from the temptations of our imperative languages. I call it the ·∫Çiring pattern'.

Before going into the pattern, we need to round out the most important aspects of ALA.


=== Wiring pattern - Part one

We now introduce the pattern that both solves the congruence problem just discussed in the previous section, and provides the alternative to all those disallowed coupling types discussed earlier. This pattern is usually an important part of ALA. 

Note: The wiring pattern is not necessarily a part of an ALA architecture. For example, if your whole problem is just an algorithm, and therefore suits a functional programming style, then you can still compose abstractions with function abstractions, provided all function calls are knowledge dependencies, and not say, just passing data or events. 

If you are using monads, especially I/O monads, or RX (reactive extensions), especially with hot observables, you are already using the wiring pattern. The pipes and filter pattern is also an example of the wiring pattern. Labview or Node-Red can use the wiring pattern. There are many other examples of the wiring pattern. Most support a data-flow programming paradigm. Here we generalise the pattern to support any programming paradigm. 

The wiring pattern may be the same as the "Component Pattern" in some literature if used with what is referred to as 'configurable modularity' or 'abstracted interactions'. 

The wiring pattern allows lines on your application diagram to mean any programming paradigm you want that express your requirements. It also allows you to implement multiple programming paradigms together in the same diagram.

If you are using dependency injection with explicit code for the wiring (not auto-wiring), then you are half way there. 

The wiring pattern separates design-time/run-time congruence. It works by having a 'wiring-time' that is separated from run-time. 'Wiring-time' can happen any time before run-time. It can happen immediately before it, as for instance in LINQ statements or RX with a cold observable. It becomes powerful when we make wiring-time congruent with design-time. Usually the wiring code will actually run at initialization time, when the program first starts running. That initialization code becomes the architectural design.   

Let's suppose you have designed your system with two modules, A and B. There will be one of each in your system.

[plantuml,file="diagram-07.png"]
----
@startdot
digraph foo {
// size="4!"
graph [rankdir=LR]
A -> B [color=red]
}
@enddot
----

At run-time we know that A will talk to B. So we design A to have an association with B. The association may first appear on a UML model, or it may go straight into the code something like this:


 static component A
 {
    B_method();
 }

 static component B
 {
    public B_method() { }
 }

A and B may be implemented as non-static, with only one instance of each. The association is still there.

 component A
 {
    private var b = new B();
    b.method();
 }

 component B
 {
    public method() { }
 }

A may create B itself, which is a composition relationship, as above. Or A may have a local variable of type B passed in by some kind of dependency injection, which is still an association relationship.

 component A
 {
    B b;
    public setter(B _b) {b = _b}
    b.method();
 }

Note that although dependency injection was used, it only eliminated part of the dependency, that of which particular subtype of B it is going to talk to, but A still knows the general type B, which is not allowed in ALA. (Part of the problem here is that A and B were probably arrived at by decomposition, and so they have subtle knowledge of each other, for example of how they collaborate.)

If A and B are collaborating, they are not abstractions. Their knowledge of each other at design-time (to enable their relationship at run-time) binds them to each other so that neither can be reused in any other way. And if they can't be reused, they can't be abstract. 

Let's revisit the water molecule analogy we discussed earlier for the Whole-Part pattern, and develop it further to be clearer how these dependencies affect abstractions. Let's say we have decomposed water into two components, Oxygen and Hydrogen. Oxygen will talk to Hydrogen to get an electron, so we write:

 component Oxygen 
 {
    var h1 = new Hydrogen();
    var h2 = new Hydrogen();
    h1.getElectron();
    h2.getElectron();
 }

The diagram for that looks like this:

[plantuml,file="diagram-08.png"]
----
@startdot
digraph foo {
// size="4!"
edge [color=red]
H2 [label=Hydrogen]
Oxygen -> Hydrogen [dir="both", arrowhead="open", arrowtail="diamond"]
Oxygen -> H2 [dir="both", arrowhead="open", arrowtail="diamond"]
}
@enddot
----

In the real world, oxygen is a very useful abstraction for making other molecules. In writing code this way to make water, we have tied it to hydrogen. Oxygen can't be used anywhere else, at least not without bringing with it two hydrogens, rendering it useless. By implementing the Oxygen-Hydrogen relationship needed to make water in oxygen, we have destroyed the oxygen abstraction. We never even made the water abstraction. To understand water, we would have to read the code inside oxygen, where the parts about water have become entangled with the inner workings of oxygen, protons and neutrons and all that stuff. Oxygen is also used to make caffeine. We could never make coffee!

image::caffeine%20molecule.png[Caffeine molecule.png, 300,title="caffeine - oxygen atoms are red"]

Abstractions are fragile and get destroyed easily, so we have to take care to protect them. What we needed to do was to put the knowledge about the relationship between oxygen and hydrogen to make water in a new abstraction called Water.

[plantuml,file="diagram-09.png"]
----
@startdot
digraph foo {
size="2!"
edge [color=green]
Water -> Oxygen
Water -> Hydrogen
}
@enddot
----


In general, to break coupling between peer modules A and B, we move the knowledge of the coupling to a higher level abstraction (less abstract level) where it belongs. Let's call it C. C is a more specific abstraction. The knowledge is encapsulated there - it never appears as a dependency of any kind. And it is cohesive with other knowledge that may be contained inside abstraction C.

[plantuml,file="diagram-10.png"]
----
@startdot
digraph foo {
// size="4!"
graph [rankdir=LR]
A -> B [color=red]
}
@enddot
----

becomes


[plantuml,file="diagram-11.png"]
----
@startdot
digraph foo {
// size="4!"
edge [color=green]
C -> A
C -> B
}
@enddot
----

The diagram above is only to show the ALA knowledge dependency relationships between the three abstractions. It doesn't yet show explicitly that an instance of Abstraction A will be wired to an instance of Abstraction B. In practice we never actually draw knowledge dependencies. We are just doing so here to show how ALA works. We would draw it in this way instead:

[plantuml,file="diagram-12.png"]
----
@startdot
digraph foo {
size="2!"
graph [rankdir=LR]
subgraph cluster_C {
label=C
style=rounded
A -> B [color=green]
}
}
@enddot
----

[plantuml,file="diagram-13.png"]
----
@startdot
digraph foo {
size="2!"
graph [rankdir=LR]
A -> B [style=invis]
#a -> b [color=red]
}
@enddot
----

Now we have the explicit wiring. It looks a lot like the original diagram where we had no C. But where the knowledge is coded is very different. Because it is C and not A that has the knowledge of the relationship between A and B, Abstractions A and B do not change. They continue to know nothing of the connection. They remain abstractions. They remain re-usable.

It may seem at first that adding the extra entity C is a cost, but in fact C is an asset. It shows the structure of the system. It shows it explicitly. It shows it in one small understandable place. And it is executable - it is not a model.

The original abstractions were left below C to show that they still exist as free abstractions to be used elsewhere. They are not contained by C in any way as modules from a decomposition process would be. The A and B inside C are only instances. We wouldn't normally bother to draw the abstractions below. So we just draw this:

[plantuml,file="diagram-14.png"]
----
@startdot
digraph foo {
size="2!"
graph [rankdir=LR]
subgraph cluster_C {
label=C
style=rounded
A -> B [color=green]
}
}
@enddot
----

C must achieve the connection between A and B either at compile-time or run-time. With current languages, the easiest time to do this is at initialization time, when the program first starts running. This is similar to dependency injection, except that we are not going to inject the instance of B into A.  

This is what the code inside C might look like:

 Abstraction C
 {
    var a = new A();
    var b = new B();
    a.wireTo(b);
 }

Typically we will write the code using the fluent pattern, with the wireTo method always returning the object on which it is called, or the wireIn method always returning the object wired to. The constructor already returns the created object by default. 

 Abstraction C
 {
    new A().wireTo(new B());
 }

If A and B are static modules, this produces something like:

 Abstraction C
 {
    A_setcallback(B_method);
 }


=== Wiring pattern - part two 

We are half-way through explaining the wiring pattern. Now we turn our attention to how A and B can communicate without knowing anything about each other. 

This part of the pattern is also called "Abstract Interactions"

Of course, one way is that C acts as the intermediary. This way is less preferred because it adds to C's responsibilities. But it is sometimes necessary if there are some abstractions brought in from outside. Such abstractions will 'own' their own interfaces or may come with a contract which C will have to know about. C will usually have to wire in an adapter, or handle the communications between the two abstractions itself.

A better way, because it leads to an architectural property of composability, is that A and B know about a 4th abstraction that is more abstract than either of them. This is legal because it is a design-time knowledge dependency.  Let's call it I. 

[plantuml,file="diagram-15.png"]
----
@startdot
digraph foo {
edge [color=green]
size="2!"
C -> A
C -> B
A -> I
B -> I
}
@enddot
----

I is an interface of some kind. It may or may not be an actual artefact. What it must be is knowledge that is more abstract than A and B and therefore knows nothing of A and B. It is more ubiquitous and more reusable than A and B are. In other words we can't just design I to meet the particular communication needs of A and B. That would cause A and B to have some form of coupling or collaboration with each other, and again destroy them as abstractions. 

I is so abstract, ubiquitous and reusable, that it corresponds to the concept of a programming paradigm. We will cover programming paradigm abstractions in following sections because they are a critically important part of ALA. We will see that ALA is polyglot with respect to programming paradigms.

image::circuit%20diagram.gif[circuit diagram.gif, title="In an electronic schematic, the components are abstractions that are composed using two paradigm interfaces - live analog signals and live digital signals"]

Returning to a software example, let's choose a single simple programming paradigm: activity flow. This programming paradigm is the same as the UML Activity diagram. When we wire A to B and they use this paradigm, it means that B starts after A finishes. If A and B accept and provide this interface respectively, then wiring them together by drawing an arrow will have that meaning, and cause that to happen at run-time.

[plantuml,file="diagram-16.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
size="2!"
subgraph cluster_C {
label=C
style=rounded
A -> B [label="activity flow", color=green]
}
}
@enddot
----
It is easy to create an interface for the activity-flow programming paradigm. It has a single method, let's call it 'start'. Many abstractions at the level of A and B can either provide or accept this paradigm interface. Then instances of them can be wired up in any order and they will follow in sequence just like an Activity diagram. 

Note that the Activity Diagram is not necessarily imperative in that any Activity can take an amount of time to complete that is not congruent with the actual CPU execution of code. In other words activities can be asynchronous with the underlying code execution, and for example, delay themselves during their execution, or wait for something else to finish, etc.  

The code in Abstraction A could look something like this. Don't take too much notice of the exact method used to accomplish the wiring. There are many ways to do this using only knowledge dependencies. The important thing is that A continues to know nothing about its peers, continues to be an abstraction, and yet can be wired with its peers to take part in any specific activity flow sequence:

....
 Abstraction A : IActivity
 {
    private IActivity next = null;
    
    public IActivity wireTo(IActivity _next) 
    {
        next = _next;
        return _next;
    }
    
    IActivty.start()
    {
        // start work
    }
    
    // code that runs when work is finished.
    // may be called from the end of start, or any time later
    private finishedWork()
    {
        if (next!=null) next.start();    
    }
 }
....

Abstraction A both _provides_ and _accepts_ the interface. This allows it to be wired before or after any of its peer abstractions. In ALA we use the word 'accepts' rather than 'requires' because there is often an end to a chain of abstraction instances wired together. If no next interface is wired in, the activity flow ends. 

Abstraction B would be written in the same way, as it also knows about the Activity flow interface:
....
 Abstraction B : IActivity
 {
    private IActivity next = null;
    
    public IActivity wireTo(IActivity _next) 
    {
        next = _next;
        return _next;
    }
       
    IActivty.start()
    {
        // start work
    }
    
    // code that runs when work is finished.
    // may be called from the end of start, or asychronously later
    private finishedWork()
    {
        if (next!=null) next.start();    
    }
 }
....

NOTE: As an aside, in C# projects, we wrote wireTo as an extension method for all objects. It used reflection to look at the private interface variables in the source class and the interfaces provided by the destination class. It would then match up the interface types and do the wiring automatically. It could even use port names to explicitly wire ports of the same types.   

Now let's revisit the molecule analogy. By now we would know to put the knowledge that Oxygen is bonded to two Hydrogens inside the water abstraction where it belongs.

[plantuml,file="diagram-17.png"]
----
@startdot
graph foo {
size="2!"
graph [rankdir=LR]
subgraph cluster_C {
label=Water
style=rounded
edge [color=green]
H2 [label=Hydrogen]
Oxygen--Hydrogen
Oxygen--H2
}
}
@enddot
----

In terms of knowledge dependencies it means this:

[plantuml,file="diagram-18.png"]
----
@startdot
digraph foo {
size="2!"
edge [color=green]
Water -> Oxygen
Water -> Hydrogen
Oxygen -> PolarBond
Hydrogen -> PolarBond
}
@enddot
----

The programming paradigm here is a polar bond. It is more abstract (more ubiquitous and reusable) than any particular atom.  We could have a second programming paradigm, a covalent bond, as well. Again, the important thing here is not what the code does - that is arbitrary (and not actually correct chemistry) but how the atoms can be made to interact while retaining their abstract properties with only design-time knowledge dependencies:


 Abstraction PolarBond
 {
    GiveElectron();
 }

....
 Abstraction Oxygen
 {
    private PolarBond hole1 = null;
    private PolarBond hole2 = null;
    
    public Oxygen wireIn(PolarBond _pb) 
    {
        if (hole1==null) hole1 = _pb; else
        if (hole2==null) hole2 = _pb;
        return this;
    }
       
    public Initialize()
    {
        if (hole1!=null) { hole1.getElectron(); BecomeNegativelyCharged(); }
        if (hole2!=null) { hole2.getElectron(); BecomeNegativelyCharged(); }
    }
 }
....
....
 Abstraction Hydrogen : PolarBond
 {
    PolarBond.getElectron()
    {
        BecomePositivelyCharged();
    }
 }
....
....
 Abstraction Water
 {
    new Oxygen()
        .wireTo(new Hydrogen())
        .wireTo(new Hydrogen())
        .Initialize();
 }
....

Let's do one more example, this time with a Data-flow programming paradigm. I have found that data-flow is the most useful programming paradigm in practice. It is useful in a a large range of problems. 

Let's construct a thermometer. Assume we already have in our domain several useful abstractions: an ADC (Analog Digital Converter) that knows how to read data from the outside world, a Thermistor abstraction that knows how to linearise a thermistor, a Scale abstraction that knows how to offset and scale data, a filter abstraction that knows how to smooth data, and a display abstraction that knows how to display data.

All these domain abstractions will use the Data-flow programming paradigm. Note that none of them know anything about a Thermometer, nor the meaning of the data they process.

So we can go ahead and create a Thermometer application just by doing this:

[plantuml,file="diagram-19.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
subgraph cluster_C {
label=Thermometer
style=rounded
#node [style=rounded]
node [shape=Mrecord]
ADC [label="<f0> ADC|<f1> Port=2|<f2> Pin=3|<f3> Frequency=1kHz"]
Thermister [label="<f0> Thermister|<f1> Type='K'|<f2> InputRange=20-1023"]
Scale [label="<f0> Scale|<f1> Offset=32|<f2> Slope=0.013"]
Display [label="<f0> FloatDisplayField|<f1> Digits=4|<f3> Decimals=1"]
ADC -> Thermister -> Scale -> Display
}
}
@enddot
----

Note that we configure all the abstraction instances for use in the Thermometer by adding configuration information into rows on the instances.

When we manually compile the diagram (assuming we don't have automated code generation), it might look something like this (again using fluent coding style):

 Abstraction Thermometer
 {
    new ADC(Port2, Pin3)
        .setFrequency(1000)
        .wireTo(new Thermister().setType('K').setInputRange(20,1023)
            .wireTo(new Scale(32,0.013)
                .wireTo(newDisplay().setDigits(4).setDecimals(1))
            )
        );
 }

NOTE: The configuration setters and the WireTo extension method return the object on which the call is made to support the fluent coding style.

The diagram is the requirements, the solution and the architecture of the application, and is executable. The diagram has all the cohesive knowledge that is a thermometer, and no other knowledge.

The diagram can be read stand-alone, because all the dependencies in it are knowledge dependencies on abstractions we would already know in the domain.

Let's say when the Thermometer runs, there is a performance issue in that the ADC is producing data at 1kHz, and we don't need the display to be showing Temperatures at that rate. Also the temperature readings are noisy (jumping around). Let's make a modification to the Thermometer by adding a filter to reduce the rate and the noise: 

[plantuml,file="diagram-20.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
subgraph cluster_C {
label=Thermometer
style=rounded
#node [style=rounded]
node [shape=Mrecord]
ADC [label="<f0> ADC|<f1> Port=2|<f2> Pin=3"]
Filter [label="<f0> LowPassFilter|<f1> Cutoff=1000"]
Thermister [label="<f0> Thermister|<f1> Type='K'|<f2> InputRange=20-1023"]
Scale [label="<f0> Scale|<f1> Offset=32|<f2> Slope=0.013"]
Display [label="<f0> FloatDisplayField|<f1> Digits=4|<f3> Decimals=1"]
ADC -> Filter -> Thermister -> Scale -> Display
}
}
@enddot
----

If the domain abstractions are not already implemented, we have got the architecture to the point where we can ask any developer to implement them, provided we first give them knowledge of ALA and of the programming paradigm(s) being used.

But let's look how the data-flow paradigm might work.

NOTE: If you are familiar with RX (Reactive extensions) with a hot observable source (which is an example of the wiring pattern), this is similar in concept although RX tries to have duality with for-loops iterating through the data. The data-flow paradigm we set up here will just be a stream of data. The IDataFlow interface corresponds to IObserver, and the wireTo method corresponds to the Subscribe method.

NOTE: The ideal would be a language where we don't have to decide if the data-flow will be push or pull, synchronous or asynchronous, buffered or unbuffered or other characteristics of communications. The abstractions would not need to know these things - they would just have logical I/O ports, and the type of communications could be binded in at compile-time as part of the performance configuration of the system.

NOTE: Later we will introduce an asynchronous (event driven) execution model. It is preferable to do the data-flow paradigm interface using that because it allows better performance of other parts of the system without resorting to threads.    

For simplicity, we will just implement a synchronous push system. Again, don't worry about the filter itself. The code is just there to see how the LowPassFilter fits in with the Data-flow programming paradigm, and how simple doing that can be. 

 Interface IDataFlow<T>
 {
    push(T data);
 }

....
 /// LowPassFilter is a Data-Flow paradigm decorator to be used in an ALA archtecture.
 /// 1. Decimates the incoming data rate down by the setCutoff configuration
 /// 2. Smooths the data with a single pole filter with cutoff frequency equall to the input frequency divided by the cutoff. T must be a numeric type.
 /// Normal checks and exceptions removed to simplify
 Class LowPassFilter<T> : IDataFlow<T>
 {
    private Dataflow next;
    
    // This is normally done by a general extension method
    public IDataflow wireTo(IDataflow _next) 
    {
        next = _next;
        return _next;
    }
    
    integer cutoff;
    
    setCutoff(integer _cutoff)
    {
        cutoff = _cutoff;
    }
    
    int count = 0;
    T filterState = NAN;
       
    IDataFlow.push(T newData)
    {
        if (filterState==NAN) filterState = newData * cutoff;
        filterState = filterState - filterState/cutoff + newData;
        count++;
        if (count==cutoff)
        {
            count = 0;
            if (next!=null) next.push(filterState/cutoff);
        }
    }
 }
....

You will notice that both the Domain abstraction, Filter, and the Programming Paradigm abstract interface, IDataFlow, use a parameterised type. This makes sense because only the application, the Thermometer, knows the actual types it needs to use.  

////
Suppose we wanted to do something more with the programming paradigm, let's say to support fan-out of the data so that multiple domain abstractions can be wired to the same data stream output. 
////
////
TBD: change the following code to use an intermediary (framework) abstraction to support fan-out using publish/subscribe, and asynchronous calls (event driven programming paradigm), and allow the framework to work without using parameterised types by using a capsule pattern, just to show that can be done. 


 Abstraction LowPassFilter<T> : IDataFlow<T>
 {
    private Dataflow next = new DataFlow();
    
    public IDataflow wireTo(IDataflow _next) 
    {
        if (next==null) next = new DataFlow();
        next = _next;
        return _next;
    }
    
    integer cutoff;
    
    setCutoff(integer _cutoff)
    {
        cutoff = _cutoff;
    }
    
    int count = 0;
    T filterState = NAN;
       
    IDataFlow.push(T newData)
    {
        if (filterState==NAN) filterState = newData * cutoff;
        filterState = filterState - filterState/cutoff + newData;
        count++;
        if (count==cutoff)
        {
            count = 0;
            if (next!=null) next.push(filterState/cutoff);
        }
    }
 }
////


=== Expression of requirements

One of the fundamental aspects of ALA is that the abstraction level of the application is fixed and defined by:

[TIP]
====
The succinct [green]#*description*# of [green]#*requirements*#
====

This is a similar concept to a DSL (but not quite the same). If the abstraction level were more specific, we wouldn't have the versatility to describe changing requirements or new applications in the domain (too expressive). If it were were more general, we would have to write more code to describe the requirements (not expressive enough).

I noticed during 40 years of code bases written at our company, two did not deteriorate under maintenance. They always remained as easy to maintain as they were in the beginning, if not easier. All others deteriorated badly. Some deteriorated so badly that they could no longer be maintained at all. At the time we din't know why and could not predict which way it would go. It seemed as if you just got lucky or unlucky. 

Perhaps it was the type of changes that came along? But the two code bases that were easy to maintain seemed to be easy for any kinds of change. And the ones that were hard were hard for any change. This continued to hold for years on end. Of course, most changes were changes to requirements, but often enough, changes would be for performance or other reasons. These also seemed easy in these two code bases, but hard everywhere else.

I began to look at the structure and style of the easy and hard code. The easy code was not complicated while the hard code had degenerated well into the complex. The two easy code bases were doing very different things in very different ways, so there was apparently not a common structure or style. But they did have one thing in common. The code that represented the knowledge of the requirements was separated out. That code _only_ described requirements, and it was expressed in terms of other things that were relatively independent, reusable and easy to understand (what we call abstractions). 
 
This is what first gave rise to one of the core tenets in ALA. The first separation is not along the lines of functional or physical parts of the system, such as UI, Business logic, and Data model. The first separation is code that just describes requirements.

Of course this has a strong parallel with how DSLs work. Is ALA just DSLs? There are several differences. Firstly in ALA we don't try to create a sandbox language for a domain expert to maintain applications. We don't go as far as an external DSL. It's for the developer and we don't want to cut him off from the power he already has when it is needed. We just give him a way to organise the code and a process to get him there - describe the requirements knowledge in terms of abstractions and then trust that those abstractions, when written, will make it work.


=== No two modules know the meaning of data or a message. 

The two modules will have collaborative knowledge. We reason that the sender must know the meaning to formulate the message, and the receiver must know the meaning to interpret the message. So how can it be avoided? The answer is to make the sender and receiver in same abstraction. They both know the same knowledge, so they are cohesive, so they should be together. In the logical view of the system, they are two instances of the one abstraction. We let the physical view fact that the sender and receiver will be deployed in different places drive them to be different modules. 





=== Expressiveness

Requirements are usually understated initially in terms of abnormal conditions. However, they are usually communicated quite quickly relative to the time to write the code. In ALA, they are separately represented. The precise expression of the requirements using the right programming paradigms should take about the same amount of information as the English explanation of them.

In general, ALA probably requires about the same amount of total code. But once the requirements are represented, the domain abstractions are known and they are independent small programs with dependencies only on the programming paradigm interfaces used. This independence should make them much easier to write. As the system matures, the effort to modify gets less as more domain abstractions come on line as tested, mature and useful building blocks. The final cost of maintenance should be much less than an equivalent ball of mud architecture.





=== No models

[IMPORTANT]
====
Leave out details only inside abstractions
====

It is generally accepted that a software architecture must, by necessity, leave out some details. Somehow we need to find a satisfactory architecture without considering all the details. Often models are used to represent the architecture. Like its metaphor in the real world, a model leaves out details. The problem is they can leave out arbitrary details. We can't be sure that some omitted detail won't turn out to be important to the architectural design.

ALA therefore does not use the model metaphor. Instead, it uses diagrams (if not plain old text). Of course, this distinction comes down to semantics. I define a diagram as different from a model in that it does not leave out details arbitrarily. The only way to leave out details in an ALA diagram is inside the boxes, in other words inside abstractions. Because abstractions already have the required meaning when used in the diagram, the details omitted can't be important to the diagram, and can't affect the architectural design.

==== Executable architecture
[IMPORTANT]
====
Your architecture should be executable
====

The distinction between diagrams and models explained in the previous section gives rise to an interesting property of the ALA architecture. Diagrams are executable. Therefore the architecture itself will be executable. When the implementation of the abstractions is complete, there will be no work left to do to make the architecture execute (apart from practical considerations of bugs, misinterpretations of the requirements, performance issues, improvements to the initially conceived set of domain abstractions, and the like).

There should be two aspects of an architecture, the meta-architecture and the specific architecture. If using ALA, ALA itself is the meta-architecture and the top level application diagram is the specific architecture.  

If your specific architecture is executable, it is also code. There is no separate documentation or model trying to act as a second source of truth.

==== Granularity

The final architecture of your software will consist only of abstractions. These abstractions will need to be independently readable and understandable. To meet this need, all of the abstractions will be small, even the 'system level' ones.   

Conversely, none should be too small. We want them small enough to allow the human brain to understand them, but there is no need for them to be smaller, or we will just end up with an inordinate number of them. This inordinate number will tax the brain in a different way, by causing it to have to learn more abstractions than necessary in a given domain.

The ideal abstraction size is probably in the range of 50 to 500 lines of code.


==== Modules, Components, Layers 

The common terms, modules, components, or layers often result from a decomposition process and therefore are parts of a specific system. The system may have only one of each type. The parts have a lower abstraction level than the system because they are just specific parts of it. In ALA we want to reverse this so that parts are more abstract than the system. 

But say you do end up with some single use abstractions and implement it in a static way, it is important to still see these entities as two aspects in one: an abstraction and an instance.

////
A and B have two aspects, the design-time aspect and the run-time aspect. This is exactly analogous to classes and objects. Even if you intend to have only one of a module or component, we still need to think about it in these two different aspects. In ALA we wont call these aspects classes and objects. We will instead call them Abstractions and Instances (first letter capitalized). The reason √≠s that classes and object carry with them a lot of baggage, such as associations and inheritance, which we are not allowed in ALA. We need a clean start. We want to remember that we have zero coupling by calling them Abstractions. So now we have Abstraction A and Abstraction B and Instance a and Instance b. When we have only one instance, A and a are two aspects of the same entity, as is B and b.

At runtime, Instances a and b will be communicating:

This knowledge that Instances a and b will be communicating at run-time must of course be represented somewhere at design-time. But we must not put that knowledge into either Abstraction A or Abstraction B, or we will destroy them as abstractions, like what happened to oxygen. The knowledge must go inside a 3rd Abstraction, C.
////
////
The A and B inside C are the Instance aspect of A and B. Even if A and B are never actually explicitly instantiated (because they are written as static modules), C still deals with their Instance aspect. If A and B are written in such a way that they need to be explicitly instantiated, C will do that.  
////

=== Abstraction Layers

==== Layers pattern

With only design-time knowledge dependencies to deal with, layers are used for organising these dependencies so that there are no circular dependencies, and that they all go toward more abstract, more stable abstractions. As the name "Abstraction Layered Architecture" suggests, layers are crucially important to ALA.

In the section on the wiring pattern we ended with three layers:

[plantuml,file="diagram-21.png"]
----
@startdot
digraph foo {
edge [color=green]
size="2.5!"
fontsize=6
fontname=Ariel
labeljust=l
subgraph cluster_1
{
label="Features layer"
C
}
subgraph cluster_2
{
label="Domain Abstractions layer"
A
B
}
subgraph cluster_3
{
label="Programming Paradigms layer"
I
}
C -> A
C -> B
A -> I
B -> I
}
@enddot
----


There is a Layers pattern that also controls dependencies, but since most systems have numerous run-time dependencies between elements represented as design-time dependencies, these layers are used for the run-time dependencies. It is usually explained that each layer is built on services provided by the layer below it. 

One example is the UI/Business Logic/Data model. Another example is the OSI communications model, where the layers are Application, Presentation, Session, Transport, Network, Data link, and Physical. In ALA, each of these ends up being turned 90 degrees. Metaphorically they become chains. In ALA each component wouldn't know about the components next to it. That applies symmetrically, to the left and to the right. Data goes in both directions. At run-time, everything must exist for the system to work. It doesn't really make sense to use a asymmetrical layers metaphor.

The design pattern for layers does have one or two examples of layering used by knowledge dependencies. The term ‚Äòlayer‚Äô is therefore an overloaded term in software engineering. When used for knowledge dependencies, the English term 'layer' is a better metaphor. If a lower layer of a wall were to be removed, the layers above would literally collapse, and that's exactly what would happen in knowledge dependency layering. The layers above literally need the knowledge of abstractions in lower layers to make any sense.

ALA's ripple effects are already under control because the only dependencies are on abstractions, which are inherently stable, and furthermore, those abstraction must be more abstract. However, to make these dependencies even less likely to cause an issue during maintenance, we try to make the abstraction layers discrete, and separated by approximately an order of magnitude. In other words each layer is approximately an order of magnitude more abstract than the one above it. More abstract means more ubiquitous, so the layers contain abstractions which have greater scope, and greater potential reuse as you go down the layers. 

We won't need many layers. If you think about abstraction layers in the real world, we can get from atoms to the human brain in four layers. Remember the creativity cycle early in this article. We only need to go around the cycle four times to make a brain: Atoms, Molecules such as proteins, Cells such as neurons, neural nets, and finally the brain itself.   

==== The four layers

We start with four layers. They have increasing scope as you go down. This type of layering was described by Meiler Page-Jones. Meiler Page-Jones‚Äô names for the four layers are: "Application domain", "Business domain", "Architecture domain", and "Foundation domain". 

image::Layers.png[Layers.png, title="Four ALA layers", width=75%]

////
[ditaa,file="diagram-03.png"]
--
Specialized
  
  |       Application layer        |
--+--------------------------------+--
  |   Domain Abstractions layer    |
--+--------------------------------+--
  |  Programming Paradigms layer   |
--+--------------------------------+--
  |         Language layer         |
  V                                v
  
Increasing abstraction            Dependencies
Increasing ubiquity
Increasing reuse
Increasing stability
--
////




ALA uses slightly different names: Application layer, Domain Abstractions layer, Programming Paradigms layer, and Language layer.

===== Application layer

The top layer has knowledge specific to the application, and nothing but knowledge specific to the application, i.e. representing your requirements.

A simple Application might wire a grid directly to a table. When Business logic is needed, any number of decorators (that do validation, constraints, calculations, filtering, sorting, etc.) can be inserted in between the grid and the table by changing the wiring of the application. 

===== Domain abstractions layer

Knowledge specific to the domain goes in this layer. A domain might correspond to a company or a department. As such, teams can collaborate on the set of abstractions to be provided there.

Applications have knowledge dependencies reaching into this layer. 

===== Programming Paradigms layer

All knowledge specific to the types of computing problems you are solving, such as execution models, programming paradigm interfaces and any frameworks to support these, is in this layer.

The Programming Paradigms layer will abstract away how the processor is managed to execute different pieces of code at the right time. Execution models are covered in detail in chapter four.

This layer is also where we arrange for our domain abstractions to have common simple connections instead of having a specific language for each pair of modules that communicate. The Programming Paradigms layer abstracts away ubiquitous communications languages (which we have been referring to as programming paradigms in this article.) 

Let's use the clock as a real world example. (This is the same clock example we used in section 2.9 when introducing the role abstractions play in the creative process.) One of the the domain abstractions for clocks is a cog wheel. Cog wheels communicate with one another. But they don't do it with communications languages specific to each pair, even though each pair must have the correct diameters and tooth sizes to mesh correctly. The cog abstraction just knows about the common paradigm of meshing teeth, a more abstract language in this lower layer. This language is analogous to a programming paradigm. With it, the clock abstraction (which is in the highest layer) can then instantiate two cogs and configure them to mesh. The concept of cog thus remains an abstraction and instances of it are composable. The clock, which already knows that two instances of cogs are needed, also knows where they will be fitted and what their diameters must be. The knowledge in the clock abstraction is cohesive. 

===== Language layer

The language layer is included to show what is below the other three layers. It is not hardware as you would find in many other layering schemes, nor is it a database, because it is not run-time dependencies we are layering. The lowest layer has the remaining knowledge you need to understand your code, that of the languages, libraries and any very generic APIs you may use.

The hardware and database do have a place, but we will cover it later. Being a run-time dependency, it will be well off to one side and slightly higher up.

===== Domain Abstractions API

The boundary between the application layer and the domain abstractions layer is an API that supports the solution space of your requirements (within the constraints of your domain).

The scope of the Domain Abstractions layer defines the expressiveness available to the application. The greater the scope (or bigger the domain), the more applications are able to do. The cost is expressiveness. The applications will have to be longer to specify what is to be done. Conversely, a smaller domain allows less versatility in the applications, but there is greater expressiveness, which means you write less code. 

===== Possible extra layers

The domain is an approximation of all the potential applications and all the modifications you are likely to make. If the domain is large because it is enterprise wide, you could have an additional layer for small domains. The enterprise domain would include enterprise wide abstractions such as a person identity, and the smaller domains would add additional, more specific abstractions, such as a customer (by composition).

If the applications are large and themselves need to be composed of features, an additional layer that supports plug-in style abstractions may work well. Plug-in abstractions may actually be instances of domain abstractions, such as a settings Menu, or a customer Table. A feature can then add settings to the menu, or columns to the table that remain unknown to any other features.

===== Programming Paradigms API

The boundary between all higher layers and the Programming Paradigms layer is another API. It separates the domain knowledge from the programming paradigm implementation knowledge. It almost always takes care of the ‚Äòexecution flow‚Äô, the way the computer CPU itself will be controlled to execute all the various parts of the code and when, often using a framework. On the other hand, the Programming Paradigms layer doesn‚Äôt necessarily have any code at all. Remember that the layers are ‚Äòknowledge dependencies‚Äô, not run-time dependencies, so the paradigm could be a ‚Äòcomputational model‚Äô that just provides the knowledge of patterns of how to constracut the code in higher layers. The decisions about use of the patterns and about the way the code is executed have already been made and exist in the Programming Paradigms layer.

===== Rate of change of knowledge

The knowledge in each of the four layers has different change rates. 

* The Language layer contains knowledge that will likely change only a few times in your career. 

* The Programming Paradigms layer knowledge changes when you move to different computing problems types, or discover different approaches to solving a broad range of problems. For example, if you have not yet used an event driven execution model or state machines in your career, and you move into the embedded systems space, you will very likely need to have those skills.

* The Domain Abstractions layer has knowledge that changes when you change the company you work for. It will change at the rate that the company's domain is changing, or is becoming better understood. If your company uses lean principles, one of the things you want to do is capture knowledge for reuse. This is the whole point of the Domain Abstractions layer, it is a set of artefacts that capture the company's reusable knowledge. 

* The Application layer has the fastest changing knowledge, the knowledge that changes at the rate that an application gets maintained.

=== ALA is a logical view

If the system is deployed on multiple machines (this is the subject of the physical view), the ALA abstractions, layers and diagrams all remain identical. A simple application diagram connecting a temperature sensor to a display field does not change if the sensor happens to be on a Mars Rover and the display field is at JPL. 

Ideally, the performance view also does not affect the ALA logical view. This is a many faceted problem that we will return to later.

ALA usually works very well with aspects of the development view as discussed elsewhere. For example, the fact that domain abstractions have zero coupling greatly helps the allocation of teams. The teams need only cooperate on a common understanding of the programming paradigms used.   

=== No separation of UI

In ALA we don't separate the UI unless there is a reason to do so. The amount of knowledge in the UI that comes from a particular application's requirements is usually quite small and that knowledge is usually quite cohesive and coupled with the business logic of the feature it belongs with. For example, the layout of the UI is a small amount of information, and the bindings of the UI elements to data are a small amount of information. So all that cohesive knowledge is kept together, encapsulated inside a feature. Instead, the UI is composed from Domain UI abstractions. Being domain specific, these abstractions have a little more knowledge to them than generic widgets. For example, their domain knowledge may include style, functionality and suitability to their domain context. For example, a softkey or menu item will have an appearance, functionality and suitability to the way UIs are designed in the domain. Using one in a specific application only requires a label and a binding to an action. They will also provide consistency in the domain.

If there is an actual requirement to have different UIs, say a command based UI and a GUI based UI, then you just abstract the UI abstractions further until they can be used either way. The UI abstractions still remain an integral part of the application.

In the example project for this chapter, we will for the first time use multiple programming paradigms, a usual thing in real ALA projects.


=== Features

You may have noticed throughout this article the word 'features' being used quite often instead of 'Application'. When the application is large, we can think of it as a composition of feature abstractions. This is exactly what happens in natural language in the domain when describing requirements. 'Features' is just the word we give the natural abstractions in the requirements, without even realizing it. Just go with this in the software itself.    

=== Horizontal domain partitions

Say you are implementing a particularly large domain abstraction such as a 'Table', or are implementing a complicated programming paradigm. We would like to break these up into smaller components. Do we introduce a fractal type of structure to deal with this? Should we have hierarchical layers within layers contained completely inside the Table abstraction?

The astute reader will have noticed the non-ALA thinking in the statement "break these up into smaller components". In ALA we don't decompose a large abstraction into components, we compose it from abstractions, which if necessary we invent as we go. These new abstractions will have a scope or level of ubiquity, stability and reuse that corresponds to one of the existing layers. So there should be no hierarchical or fractal structures in ALA.

However, the domain that these new abstractions are in won't be the same domain as the one that provides for the writing of Application requirements. For example, the implementation of the Table abstraction will need to be connected to another abstraction in the domain of databases. One of the abstractions in that domain will know about a particular database, say SQL Lite. A polymorphic interface should exist between the two. That interface, being more abstract than either the Table or the SQL Lite abstractions, will be in the next layer down, where both the Table and the MySQL abstractions can have a knowledge dependency on it. Of course the SQL abstraction will actually be further composed of an adapter and a real database. 

Some application domain abstractions are complicated. Examples of these are abstractions requiring a connection to an actual database, actual hardware, the Internet, etc. Implementing these will typically wire out horizontally into other technical domains. You can visualise them going in multiple directions, which is exactly the idea of Alistair Cockburn's hexagonal architecture.

[plantuml,file="diagram-22.png"]
----
@startdot
digraph foo {
edge [color=green]
size="2!"
fontsize=8
fontname=Ariel
labeljust=l
subgraph cluster_1
{
label="Features layer"
Feature
}
subgraph cluster_2
{
label="Domain Abstractions layer"
Input
Table
}
subgraph cluster_3
{
label="Programming Paradigms layer"
I
IDataModel
HAL
}
subgraph cluster_4
{
label="Database configuration"
Config
}
subgraph cluster_5
{
label="Database domain"
SQLLite
}
subgraph cluster_7
{
label="Hardware domain"
ADCdriver
}
Feature -> Input
Feature -> Table
Input -> I
Table -> I
Input -> HAL
Table -> IDataModel
Config -> SQLLite
ADCdriver -> HAL
SQLLite -> IDataModel
}
@enddot
----



A communications domain using a OSI model may end up with a whole chain of communications domain abstractions going sideways:

[plantuml,file="diagram-23.png"]
----
@startdot
digraph foo {
edge [color=green]
fontsize=10
fontname=Ariel
labeljust=l
subgraph cluster_1
{
label="Application layer"
Application
}
subgraph cluster_2
{
label="Domain Abstractions layer"
A
B
}
subgraph cluster_3
{
label="Programming Paradigms layer"
I
XML
REST
TCP
IP
ICMP
Ethernet
}
subgraph cluster_4
{
label="Network configuration"
ConfigComms
}
subgraph cluster_5
{
label="Network domain"
Presentation
Session
Transport
Network
Datalink
Physical
}
Application -> A
Application -> B
A -> I
B -> I
ConfigComms -> Presentation
ConfigComms -> Session
ConfigComms -> Transport
ConfigComms -> Network
ConfigComms -> Datalink
B -> XML
Presentation -> XML
Presentation -> REST
Session -> REST
Session -> TCP
Transport -> TCP
Transport -> IP
Network -> IP
Network -> ICMP
Datalink -> ICMP
Datalink -> Ethernet
Physical -> Ethernet

}
@enddot
----

The technicalities may be incorrect but the diagram gives the idea of how the OSI 'layers', which are just run-time dependencies, would fit into the ALA layers. 


=== No hierarchical design

ALA does not use any form of hierarchical structure. Instead it uses abstraction layers, together with "Horizontal domain partitions" discussed earlier.


=== Product owner perspective

TBD



=== Reuse

TBD


=== Documentation

TBD


=== Symbolic indirection

TIP: Avoid use of symbolic indirection without abstraction

When we start assembling requirements from abstractions, a topic that we will cover in coming sections, we will be using symbolic indirection, such as function calls or the new keyword with a class name. Unless a symbolic indirection is to an abstraction, they are for the compiler to follow at compile-time, not for the code reader to follow at design-time. Understanding the code relies on allowing the reader to read a small cohesive block of code. The reader should never have to follow the indirection somewhere else. If you don't achieve this, and abstraction is the only way you can, then any decoupled architecture will be _more_ difficult to read. 

Abstraction allows indirection while allowing the reader to continue reading on to the next line. The importance of this property cannot be overstated. As soon as we start thinking in mere programming language terms of modules, components, interfaces, classes, or functions, the abstraction will start to be lost. These other artefacts may have benefits at compile-time (the compiler can understand them), but that is not useful at design-time unless they are also good abstractions.  

It would be nice if your compiler could tell you that you have a missing abstraction, just as it does for a missing semicolon, but alas, they are not capable of understanding abstractions yet. So it is still entirely up to you.

Abstraction is almost a black and white type of property. It's either there or it isn't. If the reader of your code does not have to follow the indirection, you have it. 

Footnote: When the reader of your code meets your abstraction for the first time (usually a domain abstraction in a domain they have recently come into), ideally their IDE will give them the meaning in a little pop-up paragraph as their mouse hovers over any of its uses. Depending on the quality of the abstraction, after a single exposure, their brain will have the insight, like a light coming on, illuminating a meaning. The brain will form a new neuron to represent the concept. Since the reader will hopefully remain in the domain for some time, this overhead to readability shouldn't be large.

=== Everything through interfaces

A class, in contrast to an abstraction, has an interface comprising all the public members. In ALA we only want this interface to be used by the application when it instantiates and configures an instance of an abstraction. All other inputs and outputs that are used at run-time are done through interfaces (abstract interfaces). 


=== What do you know about?

Whenever I have only two minutes to give advice on software architecture, I use this quick tip. The tip is ALA reduced to its most basic driving principle.

Ask your modules, classes and functions:
[TIP]
====
[green]#*What do you _know_ about?*#
====

The answer should always be "I just know about...".

The anthropomorphization helps the brain to see them as abstractions. The word 'knows' is carefully chosen to imply a 'design-time' perspective. 

. It's a restatement of the SRP (Single Responsibility Principle). Every element should know about one thing, one coherent thing. Furthermore, no other elements should know about this one thing.

. An element may know about a single hardware device.

. An element may know about a user story.

. An element may know about a protocol.

. An element may know an algorithm.

. An element may know how to do an operation on some data, or the meaning of some data, but not both.

. An element may know a composition of other elements.

. An element may know where data flows between other elements.

. No element should know the source or destination of its inputs and outputs.









=== Example project - Game scoreboard

For the example project for this chapter, we return to the ten-pin bowling and tennis scoring engines that we used in Chapter two, and add a scoreboard feature (well a simple ASCII scoreboard in a console application rather than real hardware).

As the requirement, say we want a console application that displays ASCII scoreboards that look like these examples:

....
Ten-pin

 -----+-----+-----+-----+-----+-----+-----+-----+-----+--------
|   1 |   2 |   3 |   4 |   5 |   6 |   7 |   8 |   9 |    10  |
+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+--+
| 1| 4| 4| 5| 6| /| 5| /|  | X| -| 1| 7| /| 6| /|  | X| 2| /| 6|
+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+  +--+--+
|   5 |  14 |  29 |  49 |  60 |  61 |  77 |  97 | 117 |   133  |
 -----+-----+-----+-----+-----+-----+-----+-----+-----+--------
....

....
Tennis

 -----++----+----+----+----+----++--------
|   1 ||  4 |  6 |  5 |    |    ||    30  |
|   2 ||  6 |  4 |  7 |    |    ||  love  |
 -----++----+----+----+----+----++--------
....



As usual in ALA, our methodology begins with expressing those requirements directly, and inventing abstractions to do so. So, we invent a 'Scorecard' abstraction. It will take a configuration which is an ASCII template. Here are the ascii templates that would be used for ten-pin and tennis:

....
 -------+-------+-------+-------+-------+-------+-------+-------+-------+-----------
|   1   |   2   |   3   |   4   |   5   |   6   |   7   |   8   |   9   |     10    |
+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+---+
|F00|F01|F10|F11|F20|F21|F30|F31|F40|F41|F50|F51|F60|F61|F70|F71|F80|F81|F90|F91|F92|
+   +---+   +---+   +---+   +---+   +---+   +---+   +---+   +---+   +---+   +---+---+
|  T0-  |  T1-  |  T2-  |  T3-  |  T4-  |  T5-  |  T6-  |  T7-  |  T8-  |    T9-    |
 -------+-------+-------+-------+-------+-------+-------+-------+-------+-------------
....

....
 -----++----+----+----+----+----++--------
| M0  ||S00 |S10 |S20 |S30 |S40 || G0---  |
| M1  ||S01 |S11 |S21 |S31 |S41 || G1---  |
 -----++----+----+----+----+----++--------
....

The scorecard ASCII template has letter place-holders for the scores. (A single letter is used so it doesn't take up much space on the template design.) Different letters are used for different types of scores. Digits are used to specify where multiple scores of the same type are arranged on the scoreboard. They are like indexes. Either 1-dimensional or 2-dimensional indexes can be used in the scoreboard template. For example, the frame scores in ten-pin bowling have scores for each ball for each frame, F00, F01 etc, as shown in the example above.

The scorecard abstraction needs functions it can use to get the actual scores. The functions are configured into little 'binding' objects that we then wire to the scoreboard. The binding objects are configured with the letter that they return the score for. 

==== Ten-pin

Having invented the Scorecard and Binding abstractions, we can now do the ten-pin application diagram:
 

[plantuml,file="diagram-bowling-3.png"]
----
@startdot
digraph foo {
rankdir=LR

#note rankdir does not work inside subgraphs
subgraph cluster_C {
fontsize=20
label="Ten-Pin Bowling                                                            "
style=rounded

node [shape=Mrecord]
console [label="ConsoleGameRunner|\"Enter number of pins\""]

scoreboard [fontsize=14,label=<
<table border='0' cellborder='1' cellspacing='0'>
<tr><td colspan="21" sides="B"><font point-size="14">Scorecard</font></td></tr>
<tr><td colspan="2">1</td><td colspan="2">2</td><td colspan="2">3</td><td colspan="2">4</td><td colspan="2">5</td><td colspan="2">6</td><td colspan="2">7</td><td colspan="2">8</td><td colspan="2">9</td><td colspan="3">10</td></tr>
<tr><td sides="LTR">F00</td><td>F01</td><td sides="LTR">F10</td><td>F11</td><td sides="LTR">F20</td><td>F21</td><td sides="LTR">F30</td><td>F31</td><td sides="LTR">F40</td><td>F41</td><td sides="LTR">F50</td><td>F51</td><td sides="LTR">F60</td><td>F61</td><td sides="LTR">F70</td><td>F71</td><td sides="LTR">F80</td><td>F81</td><td sides="LTR">F90</td><td>F91</td><td>F92</td></tr>
<tr><td colspan="2" sides="LBR">T0</td><td colspan="2" sides="LBR">T1</td><td colspan="2" sides="LBR">T2</td><td colspan="2" sides="LBR">T3</td><td colspan="2" sides="LBR">T4</td><td colspan="2" sides="LBR">T5</td><td colspan="2" sides="LBR">T6</td><td colspan="2" sides="LBR">T7</td><td colspan="2" sides="LBR">T8</td><td colspan="3" sides="LBR">T9</td></tr>
</table>
>]

framebind [label="Binding|F"]
totalbind [label="Binding|T"]
game [label="Frame|\"game\"|nFrames==10"]

node [shape=record]
function1 [label="GetSubFrames()\n.Select(sf =\> sf.GetScore()[0])\n.Accumulate()"]
function2 [label="GetSubFrames()\n.Select(f =\> f.GetSubFrames()\n.Select(b =\> b.GetScore()[0])"]
translate [label="Translate\nX,/,- etc"]

console -> game  [label = "IConsistsOf"]
console -> scoreboard [constraint=false, label = "IPullDataFlow"]
scoreboard -> framebind -> translate -> function2 -> game
scoreboard -> totalbind -> function1 -> game

{rank=same console scoreboard}
{rank=same framebind totalbind}
{rank=same function1 function2}

}
}
@enddot
----

An abstraction we didn't mention yet is the ConsoleGameRunner. Its job is to prompt for a score from each play, display the ASCII scoreboard, and repeat until the game completes. 

The 'game' instance of the Frame abstraction on the right of the diagrams is the scoring engine we developed in Chapter Two. Together with this engine, we now have a complete application. 

The rounded boxes in the diagram are instances of domain abstractions as usual for ALA diagrams. The sharp corner boxes are instances of Application layer abstractions. They are the mentioned functions for the Bindings. That code is application specific so goes in the application layer. They just do a simple query on the scoring engine.

Now tranlate the diagram into code. Here is the entire application layer code for ten-pin:
....
consolerunner = new ConsoleGameRunner("Enter number pins:", (pins, engine) => engine.Ball(0, pins))
.WireTo(game)
.WireTo(new Scorecard(
"-------------------------------------------------------------------------------------\n" +
"|F00|F01|F10|F11|F20|F21|F30|F31|F40|F41|F50|F51|F60|F61|F70|F71|F80|F81|F90|F91|F92|\n" +
"|    ---+    ---+    ---+    ---+    ---+    ---+    ---+    ---+    ---+    ---+----\n" +
"|  T0-  |  T1-  |  T2-  |  T3-  |  T4-  |  T5-  |  T6-  |  T7-  |  T8-  |    T9-    |\n" +
"-------------------------------------------------------------------------------------\n")
.WireTo(new ScoreBinding<List<List<string>>>("F", 
    () => TranslateFrameScores(
        game.GetSubFrames().Select(f => f.GetSubFrames().Select(b => b.GetScore()[0]).ToList()).ToList())))
.WireTo(new ScoreBinding<List<int>>("T", 
    () => game.GetSubFrames().Select(sf => sf.GetScore()[0]).Accumulate().ToList()))
);
....

....
....
If you compare this code with the diagram, you will see a pretty direct correspondence. 
Remember 'game' is the reference to the scoring engine project in the previous chapter.

That's pretty much all the code in the application. Oh there is the 'translate' function, but it is pretty straight forward once you know the way a ten-pin scorecard works. For completeness here it is.

....

/// <summary>
/// Translate a ten-pin frame score such as 0,10 to X, / and - e.g. "-","X".
/// </summary>
/// <example>
/// 7,2 -> "7","2"
/// 7,0 -> "7","-"
/// -,3 -> "-","7"
/// 7,3 -> "7","/" 
/// 10,0 -> "",X
/// 0,10 -> "-","/"
/// additional ninth frame translations:
/// 10,0 -> "X","-"
/// 7,3,2 -> "7","/","2"
/// 10,7,3 -> "X","7","/"
/// 0,10,10 -> "-","/","X"
/// 10,10,10 -> "X","X","X"
/// </example>
/// <param name="frames">
/// The parameter, frames, is a list of frames, each with a list of integers between 0 and 10 for the numbers of pins.
/// </param>
/// <returns>
/// return value will be exactly the same structure as the parameter but with strings instead of ints
/// </returns>
/// <remarks>
/// This function is an abstraction  (does not refer to local variables or have side effects)
/// </remarks>
private List<List<string>> TranslateFrameScores(List<List<int>> frames)
{ 
    // This function looks a bit daunting but actually it just methodically makes the above example tranlations of the frame pin scores 
    List<List<string>> rv = new List<List<string>>(); 
    int frameNumber = 0;
    foreach (List<int> frame in frames)
    {
        var frameScoring = new List<string>();
        if (frame.Count > 0)
        {
            // The first 9 frames position the X in the second box on a real scorecard - handle this case separately
            if (frameNumber<9 && frame[0] == 10)
            {
                frameScoring.Add("");
                frameScoring.Add("X");
            }
            else
            {
                int ballNumber = 0;
                foreach (int pins in frame)
                {
                    if (pins == 0)
                    {
                        frameScoring.Add("-");
                    }
                    else
                    if (ballNumber>0 && frame[ballNumber]+frame[ballNumber-1] == 10)
                    {
                        frameScoring.Add(@"/");
                    }
                    else
                    if (pins == 10)
                    {
                        frameScoring.Add("X");
                    }
                    else
                    {
                        frameScoring.Add(pins.ToString());
                    }
                    ballNumber++;
                }

            }
        }
        rv.Add(frameScoring);
        frameNumber++;
    }
    return rv;
}
....


==== Tennis


So now that we have these domain abstractions for doing console game scoring applications, let's do tennis:


////
[plantuml,file="diagram-bowling-4.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
#subgraph cluster_C {
label="Ten-Pin Bowling"
style=rounded
#node [style=rounded]
node [shape=Mrecord]
game [label="Frame|\"game\"|nFrames==10"]
bonus [label="Bonus||score\<10 \|\| plays==3"]
frame [label="Frame|\"frame\"|frameNum\<9 && (balls==2 \|\| pins==10)\n \|\|\ (balls==2 && pins\<10 \|\| balls==3)"]
ball [label="SinglePlay"]
game -> bonus -> frame -> ball
}
}
@enddot
----
////


[plantuml,file="diagram-tennis-3.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
subgraph cluster_C {
label="Tennis"
style=rounded

node [shape=Mrecord]
console [label="ConsoleGameRunner|\"Enter winner of play\""]

scoreboard [label="Scoreboard| -----++----+----+----+----+----++--------\n\| M0  \|\|S00 \|S10 \|S20 \|S30 \|S40 \|\| G0---  \|\n\| M1  \|\|S01 \|S11 \|S21 \|S31 \|S41 \|\| G1---  \|\n -----++----+----+----+----+----++--------\n"]

gamebind [label="Binding|G"]
setbind [label="Binding|S"]
matchbind [label="Binding|M"]
match [label="Frame|\"match\"|score.Max()==3"]

node [shape=record]
function1 [label="GetScore()"]
function2 [label="GetSubFrames()\n.Select(sf =\> sf.GetSubFrames().First())\n.Select(s =\> s.GetScore()).ToList()"]
function3 [label="GetGameOrTieBreakScore\n(see function)"]

console -> scoreboard [constraint=false, label = "IPullDataFlow"]
console -> match [label = "IConsistsOf"]
scoreboard -> setbind -> function2
scoreboard -> matchbind -> function1
scoreboard -> gamebind -> function3
function1 -> match
function2 -> match
function3 -> match

{rank=same console scoreboard}

}
}
@enddot
----

////
[plantuml,file="tennis4.png"]
----
@startdot
digraph foo {
graph [rankdir=LR]
// subgraph cluster_C {
label="Tennis scoring"
style=rounded
#node [style=rounded]

node [shape=Mrecord]
match [label="Frame|\"match\"|score.Max()==3"]
wtp1 [label="WTP"]
set [label="Frame|\"set\"|score.Max()\>=6 && \nMath.Abs(score[0]-score[1])\>=2"]
wtp2 [label="WTP"]
game [label="Frame|\"game\"|score.Max()\>=4 && \nMath.Abs(score[0]-score[1])\>=2"]
play [label="SinglePlay"]
switch [label="Switch||(setNumber\<4 &&\n score[0]==6 && score[1]==6"]
wtp3 [label="WTP"]
tiebreak [label="Frame|\"tiebreak\"|score.Max()==7"]
play2 [label="SinglePlay"]
match -> wtp1 -> switch -> set -> wtp2 -> game -> play
switch:s -> wtp3:w
wtp3 -> tiebreak -> play2
{rank=same set wtp3}

// }
}
@enddot
----
////

I left the code out of the GetGameOrTieBreakScore box as it is a little big for the diagram here. It is similar to the other queries but it must first determine if a tie break is in progress and get that if so. Also it translates game scores from like 1,0 to "15","love".

And here is the code for the Tennis diagram:
....
consolerunner = new ConsoleGameRunner("Enter winner 0 or 1", (winner, engine) => engine.Ball(winner, 1))
.WireTo(match)
.WireTo(new Scorecard(
        "--------------------------------------------\n" +
        "| M0  |S00|S10|S20|S30|S40|S50|S60|  G0--- |\n" +
        "| M1  |S01|S11|S21|S31|S41|S51|S61|  G1--- |\n" +
        "--------------------------------------------\n")
    .WireTo(new ScoreBinding<int[]>("M", () => match.GetScore()))
    .WireTo(new ScoreBinding<List<int[]>>("S", () => 
        match.GetSubFrames()
            .Select(sf => sf.GetSubFrames().First())
            .Select(s => s.GetScore())
            .ToList())
    .WireTo(new ScoreBinding<string[]>("G", () => GetGameOrTiebreakScore(match)))
);

....

If you compare this code with the diagram, you can see a pretty direct correspondence. match comes from the scoring engine project in Chapter two.

==== Concluding notes

Although the diagrams must be turned into text code to actually execute, it is important in ALA to do these architecture design diagrams first. They not only give you the application, they give you the architectural design by giving you the domain abstractions and programming paradigms as well. If you try to design an ALA structure in your head while you write it directly in code, you will get terribly confused and make a mess. Using UML class diagrams will make it even worse. Code at different abstraction levels will end up everywhere, and run-time dependencies will abound. Our programming languages, and the UML Class diagram, are just not designed to support abstraction layered thinking - it is too easy to add bad dependencies (function calls or 'new' keywords) into code in the wrong places.

Note that at run-time, not all data-flows have to go directly between wired up instances of domain abstractions. The data can come up into the application layer code, and then back down. This was the case when we did the functional composition example in Chapter One. In this application we are doing that with the code in the square boxes that get the score from the engine. The important thing is that all the code in the application is specific to the application requirements.  




////


////


////
Now let's have a look at some of the code in the two of the new domain abstractions. Here is the essence of the Scoreboard domain abstraction (remember we are down a layer now, so it has no knowledge of bowling):

....
public string GetScorecard()
{
    var matches = Regex.Matches(ASCIITemplate, "(([A-Z][0-9][0-9])|([A-Z][0-9])|([A-Z]))-*"); // The regular expression matches e.g. A, B1, C12, D-, E00--
    var rv = ASCIITemplate;
    foreach (Match match in matches)
    {
        char id = match.Value[0];
        foreach (IScoreBinding sg in scoreGetters)
        {
            if (id == sg.Label[0])
            {
                if (match.Length>=2 && char.IsDigit(match.Value[1]))
                {
                    if (match.Length >= 3 && char.IsDigit(match.Value[2])) // e.g. A11
                    {
                        rv = rv.Replace(match.Value, sg.GetScore(Convert.ToInt32(match.Value[1]) - Convert.ToInt32('0'), Convert.ToInt32(match.Value[2]) - Convert.ToInt32('0')).PadLeft(match.Length));
                    }
                    else // e.g. A1
                    {
                        rv = rv.Replace(match.Value, sg.GetScore(Convert.ToInt32(match.Value[1]) - Convert.ToInt32('0')).PadLeft(match.Length));
                    }
                }
                else // e.g just A, no index
                {
                    rv = rv.Replace(match.Value, sg.GetScore().PadLeft(match.Length));
                }
            }
        }
    }
    return rv;
}
....

The ScoreBinding domain abstraction has three overloads of GetScore - one for two indexes, one for one index, and one for zero indexes. Here is the code for the one that has one index. The other two are similar. Because we are given one index, we expect the function that we have been wired to will return a one dimensional something. It could be a List or array, of type int or string. T tells us what type it is. Our job is to index into whatever it is, and return it as a string:

....
public string GetScore(int x)
{
    object temp = function();
    if (typeof(T) == typeof(List<int>))
    {
        List<int> list = (List<int>)temp;
        if (x < list.Count) return list[x].ToString();
    }
    if (typeof(T) == typeof(int[]))
    {
        int[] array = (int[])temp;
        if (x < array.Length) return array[x].ToString();
    }
    if (typeof(T) == typeof(List<string>))
    {
        List<string> list = (List<string>)temp;
        if (x < list.Count) return list[x];
    }
    if (typeof(T) == typeof(string[]))
    {
        string[] array = (string[])temp;
        if (x < array.Length) return array[x];
    }
    return "";
}
....


////

That completes our discussion of the console applications for ten-pin and tennis. The full project code can be viewed or downloaded here:

https://github.com/johnspray74/GameScoring[GameScoring code]




















== Chapter seven - ALA compared with...


=== Physical boundaries

I was listening to a talk by Eric Evans where he said that Microservices works because it provides boundaries that are harder to cross. We have been trying to build logical boundaries for 60 years, he said, and failed. So now we use tools like Docker that force us to use say REST style interfaces in oder to have physical boundaries. I have also heard it suggested that using multiple MCUs in an embedded system is a good thing because it provides physical boundaries for our software components. And I think, really? Is that the only way we can be create a logical boundary? I can tell you that multiple MCUs for this reason is not a good idea if only because all those MCUs will need updating, and the mechanisms and infrastructure needed to do that make it not worth it. Unless there is a good reason, such as to make different parts of your code independently deployable, the extra infrastructure required for physical boundaries that are just logical boundaries is not necessary. Furthermore, physical boundaries, like modules do not necessarily make good abstractions. The only boundary that works at design-time is a good abstraction. So ALA achieves it's design-time boundaries by using abstractions.

=== Test Driven Development

It is said that TDD's main advantage is not so much the testing, but the improvement in the design. In other words, making modules independently testable makes better abstractions. This is probably true, but in my experience, TDD doesn't create good abstractions nearly as well as pursuing that goal directly. The architecture resulting from TDD is better but still not great.


=== Observer pattern and dependency inversion

TBD



anchor:ComparisonHexagonal[]

=== Hexagonal Architecture (ports and adapters)

In the previous section we intimated that the sideways chains of interfaces going out in horizontal directions were the same as hexagonal architecture. While ALA shares this aspect of hexagonal architecture, there is still an important difference.

ALA retains domain abstractions of the UI, Database, communication and so on. For instance, in our XR5000 example, we had a domain abstraction for a persistent Table. We had domain abstractions for UI elements such as Page, Softkey etc. We don't just have a port to the persistence adapter, we have an abstraction of persistence. We don't just have a port for the UI to bind to, we have abstractions of the UI elements. The implementation of these abstractions will then use ports to connect to these external system components. Why is it important that we have domain abstractions of these external components?

. The Database and the UI will have a lot of application specific knowledge given them as configuration. Remember the creativity cycle. After instantiation of an abstraction comes configuration. The database will need a schema, and the knowledge for that schema is in the application. The Softkey UI elements will need labels, and that knowledge is in the application. By making domain abstractions for persistence and UI, the application can configure them like any other domain abstraction as it instantiates and wires up the application. To the application, these particular domain abstractions look like wrappers of the actual database and UI implementations, but they are more like proxies in that they just pass on the work. 
+
The Persistence abstraction then passes this configuration information, via the port interface to the actual database. The Softkey abstraction then passes its label, via the port interface, to the softkeys. Otherwise the Application would have to know about actual databases and actual softkeys.
+
If you need a design where the UI can change, you just make the UI domain abstractions more abstract. A softkey may be a command abstraction. It is still configured with a label. But it may be connected to a softkey, a menu item, a CLI command, a web page button, or a Web API command.

. From the point of view of a DSL, it makes sense to have concepts of UI and persistence and communications in the DSL language. The application is cohesive knowledge of requirements. The UI and the need for persistence are part of the requirements. In fact, for product owners communicating requirements, the UI tends to be their view of requirements. They talk about them in terms of the UI. Many of the product owners I have worked with actually design the UI as part of the requirements (with the backing of their managers, who are easily convinced that software engineers can't design UIs. PO can't either, but that is another story.). The point here is that the UI layout, navigation, and connection to business logic is all highly cohesive. We explicitly do not want to separate that knowledge. 
+
As a restatement of an earlier tenet of ALA, it is much better to compose the application with abstractions of Business logic, UI and persistence than to decompose the application into UI, persistence and business logic.

. We want the application to have the property of composability. We have previously discussed how that means using programming paradigm interfaces for wiring up domain abstractions. By using domain abstractions to represent external components, the abstractions can implement the paradigm interfaces and then be composable with other domain abstractions. For example, the Table domain abstraction which represents persistence may need to be connected directly to a grid, or to other domain abstractions that map or reduce it. Indeed, the Table abstraction itself can be instantiated multiple times for different tables and be composed to form a schema using a schema programming paradigm interface. I have even had a table instance's configuration interface wired to a another Table instance. (So its columns can be configured by the user of the application.)     

. The fourth reason why it is important for the application to not directly have ports for external components of the system is that we don't want the logical view of the architecture to become just one part of the physical view. If there is a communications port that goes to a different physical machine where there is more application logic, the application's logical view should not know about that. It may be presented as an annotation on the application (lines) connecting certain instances, but it shouldn't split the application up. At the application level, the collaboration between parts instantiated on different machines is still cohesive knowledge and belongs inside one place - the application.  


=== Layer patterns

==== MVC

TBD

==== Application, Services, Drivers, Hardware

TBD

=== Factory method pattern

The Factory Method pattern in both the GOF book and in online examples has multiple variations. The only thing they seem to have in common is that the client doesn't use "new ConcreteProduct()". It just wants an object that implements an interface, IProduct. For any reason it doesn't want to be the one who will decides at design-time what that concrete product will be. 

Here are some of the variations. 

* Several ConcreteCreators exists to encapsulate knowledge of how to use the ConcreteProduct constructor which has many parameters, in a consistent way to make a valid ConcreteProduct. The common example is different named pizzas or sandwiches. 

* The Client finds out at run-time what ConcreteProduct is needed (usually a string name). We want to move the switch statement out of the client and into a Creator class.)

* The client knows when the objects are needed, but needs to be more stable. Which product is needed changes more often (although still known at design-time). So it goes into a class that changes. 

In all cases we end up with two objects wired together through the IProduct interface. These two objects we will refer to as the Client and the ConcreteProduct (from the pattern terminology). To get them wired using the Factory Method pattern requires the use of a FactoryMethod. The FactoryMethod typically goes in an abstract class called ICreator, which may do the creating itself, or maybe overridden by one or more ConcreteCreators.

In the context of abstraction layers, ALA gives more insight into the FactoryMethods pattern. Remeber we expect lower layers to more stable. The IProduct and ICreator interfaces are in the ProgrammingParadigms layer (lowest layer). The Client and all the different ConcreteProducts are in the DomainAbstractions layer (middle layer). The ConcreteCreator is in the Application layer and wires one of the ConcreteProducts to the client. So now when we want to change the ConcreteProduct, only the ConcreteCreator in the application layer has to change.

But in ALA we typically accomplish that in a far simpler way. We commonly let the application code instantiate the right concrete class (that implements the interface, IProduct), and wire it to the Client object using the WireTo() method. This is nothing more than static wiring, but can only work when the required ConcreteProduct is known at design-time.


==== case 1

Now to the case in ALA where we have a client that needs a concrete product creating later than design-time, that is at run-time. Such a client is the Multiple Abstraction. It's job is to make many instances of a Domain Abstraction. But it is an abstraction so can be used to make instances of any object. They don't even have to implement a specific interface such as IProduct, because Multiple doesn't interact with these instances itself.

==== case 2

Let's say you have a Table domain abstraction that stores a table of data. In your application, you want to instantiate many Tables. Now lets suppose that we want these Table instances to persist their data. A database must be attached via an IPersistance interface. We don't want the Table class to know about concrete Databases. We want the application layer at the top to do that. But we don't want the application layer to have to wire the database to every instance that requires an IPersistance. We want the Application to be able to just use a Table as if it is a self-contained abstraction. We want the Table instances to take care of themselves for Persistence. So we make a Peristence abstraction in the Programming paradigms layer. The concept of Persistence is at the right abstraction level to go in this layer. The Table class can use this persistence abstraction through a FactoryMethod. A variable in the Persistence abstraction stores the IPeristence object. The application instantiates which database it wants to use and passes it to the Peristence abstraction.


=== Interface segregation principle

TBD

=== Open Closed Principle and decorators

TBD


=== Bridge pattern 

TBD


=== Architecture styles

I am not an expert at these so called 'Architectural styles'. Any feedback about the accuracy of the following comparisons would be appreciated.

==== Presentation, Business, Services, Persistence, Database

TBD

==== Presentation, Application, Domain, Infrastructure

The middle two layers appear to be the same as ALA's. The Presentation (UI) only has run-time dependencies on the Application, and the Domain layer only has run-time dependencies on the Infrastructure (Persistence etc), so these layers are not present in ALA. 

Instead Presentation is done in the same way as the rest of the application, by composing and configuring abstractions in the domain. The meaning of composition for UI elements (typically layout and navigation-flow) is different from the meaning of composition in the use-cases (typically work-flow or data-flow).

In ALA, the foundation layer is also done in the same way as the rest of the application, at least a little. Domain abstractions that represent say a persistent table are in the Domain layer. The composition and configuration of them again goes in the Application layer. This time the meaning of composition is, for example, columns for the tables and schema relations.  

If the implementation of any domain abstraction is not small (as is the case with the persistent Table abstraction mentioned above, which will need to be connected to a real database), it will be using other abstract interfaces (in the Programming Paradigms layer) connected to its runtime support abstractions in a technical domain, the same as in Hexagonal Architecture.

==== Object Oriented Programming

From my reading, it seems that the most characteristic feature of OOP is that when data and operations are cohesive, they are brought together in an object. Others may see it as enabling reuse, inheritance, and still others may see it as polymorphism. New graduates seem to be introduced to polymorphism in inheritance and not be introduced to interfaces at all, which is a shame because the concept of interfaces is much more important. 

I have never been an expert at Object Oriented Design as I found the choice of classes difficult and the resulting designs only mediocre. But I think the most fundamental and important characterising feature of OOP is under-rated. That is the separation of the concepts of classes and objects. This separation is not so clearly marked when we use the terms modules or components. The separation is fundamentally important because it's what allows us to remove all dependencies except knowledge dependencies. In the way described earlier in this article, you can represent the knowledge of most dependencies as a relationship between instances completely inside another abstraction. What OOP should have done is represent relationships between objects completely inside another class. The problem is that OOP doesn't take advantage of this opportunity. Instead, it puts these relationships between objects inside those objects' classes, as associations or inheritance, thereby turning them into design-time dependencies, and destroying the abstract qualities of the classes. Abstractions, unlike classes, retain their zero coupling with one another.

ALA addresses the problem by calling classes abstractions and objects instances. Abstractions differ from classes by giving us a way to have logical zero coupling, as if they were on different physical platforms. Instances differ from objects by having ports because their classes give them no fixed relationships with other objects.

Of course, when you are writing ALA code, abstractions are implemented using classes, but you are not allowed associations or inheritance. Instances are implemented as objects but with ports for their connections. A port is a pair of interfaces that allow methods in both directions. The interfaces are defined in a lower layer.
 
In ALA, the UML class diagram completely loses relevance. Because classes have no relationships with each other, bar knowledge dependencies, a UML diagram in ALA would just be a lot of boxes in free space, like a pallet of things you can use. You could show them in their layers and you could even draw the downward composition relationships that represent the knowledge dependencies, but there would be no point to this except in explaining the concepts of ALA. When you are designing an actual system, the real diagram is the one inside of an abstraction, especially the uppermost one, the application. It shows boxes for instances of the abstractions it uses, with the name of the abstraction in the box, the configuration information for those instances, and of course the lines showing how they are wired together. The names inside the boxes would not even need to be underlined as in UML, because the boxes in such diagrams would always be instances. 

Such a diagram is close to a UML object diagram. However, a UML object diagram is meant to be a snapshot of a dynamic system at one point in time. In ALA, any dynamic behaviour is captured in a static way by inventing a new abstraction to describe that dynamic behaviour. Thus the design-time view is always static. So the object diagram is static. The application class specifies a number of objects that must be instantiated, configured, and wired together to execute at run-time. Since the structure is always static, ideally this would be done by the compiler for best efficiency, but there is no such language yet. So, in the meantime, it is done at initialization time. The object diagram can be fairly elegantly turned into code using the fluent coding style shown in the XR5000 example.

=== DSLs

We briefly discussed ALA as a DSL in the structure chapter <<DSL1, here>> 

ALA includes the main idea of DSLs in that the fundamental method "represent[s] requirements by composition of domain abstractions". It shares the DSL property that you can implement a lot more requirements or user stories in a lot less code. 

But ALA only tries to be a light-weight way of telling ordinary developers how to organise code written in your underlying language. Although the domain abstractions do form a language and the paradigm interfaces give it a grammar, ALA doesn't pursue the idea of a language to the point of textural syntactic elegance. Instead, you end up with explicit wiring methods to combine domain entities, or plain old functional composition, or some other form of composition in the wider sense of the word. Often, the text form is only a result of hand translation of an executable diagram. ALA certainly doesn't overlap with DSLs to the extent of an external DSL, nor does it try to sandbox you from the underlying language. It therefore does not require any parsing and doesn't need a language workbench, things that may scare away 'plain old C' developers.

Like DSLs, ALA can be highly declarative depending on the paradigm interfaces being used to connect domain abstractions. It is better to have the properties of composition and composability in the your domain language even if they may not be in a perfectly elegant syntactic form. ALA may end up composing abstractions with calls to wireTo methods instead of spaces or dots. But often a diagram using lines is even better than spaces and dots.  

In DSLs, it is important that different languages can be combined for different aspects of a problem. For example, a DSL that defines State machines (the state diagram) and a DSL for data organisation (Entity Relationship Diagram) may be needed in the same application. You don't want to be stuck in one paradigm. ALA recognises this importance by having paradigm interfaces that are more abstract than the domain abstractions. 

DSLs probably work by generating a lot of code from templates whereas ALA works by reusing code as instances of abstractions. Both of these methods are fine from the point of view of keeping application specific knowledge in its place, and domain knowledge in its place. Howver, the distinction between ALAs domain layer and programming paradigms layer is probably not so as clearly made in the implementation of the templates.   

It is an advantage of DSLs that they can sandbox when needed. An example from the wiring pattern earlier is that the ports of instances do not need to be wired. Therefore, all abstractions need to check if there is something wired to a port before making a call on it. Enforcing this is a problem I have not yet addressed.

A possible solution, albeit inferior to a real DSL that would tell you at design-time, might be that when there are tools that generate wiring code from diagrams, they automatically put stubs on all unwired ports. These stubs either throw an exception at run-time, or just behave inertly. 

ALA is different from external DSLs. ALA is just about helping programmers organise their code in a better way. It doesn't try to make a syntactically elegant language, as a DSL does. Certainly an external DSL will end up representing requirements in a more elegant syntax. But that is not the most important thing in ALA. The most important thing is the separation of code that has knowledge of the requirements, which will cause the invention of abstractions that have zero coupling (because the coupling was really in each requirement - that is why a requirement is cohesive). ALA also avoids taking the average imperative language programmer out of their comfort zone. It does not require a language workbench and does not sandbox you from the underlying language.

ALA probably does fit into the broadest definition of an internal DSL. However, again, it does not target syntactic convenience in the expression of requirements so much as just separating the code that knows about those requirements from the code that implements them. An internal DSL usually aims to have a mini-language that is a subset of the host language, or it tries to extend the host language through clever meta-programming to look as if it has new features. ALA is about abstraction layering. It is about this design-time view of knowledge dependencies: what abstractions in lower layers are needed to understand a given piece of code.


=== Dependency injection

==== Similarities

In ALA you inject run-time required objects via setters.

==== Differences

ALA uses explicit wiring, never automatic wiring. For one thing, the wiring is required to compose from a pallet of domain abstractions. But secondly, and more importantly, you do not want the knowledge that the wiring represents to disappear into the abstractions themselves, not even as meta-data. That would destroy the abstractions.

In ALA, the explicit wiring can't be XML or JSON, even if it can be modified at run-time. Usually, because a network structure will be required, the explicit wiring must be a diagram. However, it can be a projection editor, so that the structure is entered in text form (preferably not XML or JSON) and live viewed in graphical form.  

In ALA, abstraction pairs don't have their own interfaces for their instances to communicate. So we don't have the situation where class A has a dependency on class B, and so an object of class B (or one of its subclasses) is injected into class A. Similarly, we wouldn't have the situation where class A requires an interface that is implemented by class B.

In ALA the dependencies can only be on paradigm interfaces, which are a whole abstraction layer more abstract. So we need to be thinking that if class A accepts or implements a certain paradigm interface, there could be any number of other abstraction instances that could be attached. Furthermore, we could build arbitrarily large assemblies - composability. Or we don't have to connect an instance at all. So it doesn't really make sense to call what we are injecting 'dependencies'. We just think of it as wiring things up, like electronic components.


=== Component Based Software Engineering

ALA uses many of the same methods found in component based engineering or the Components and Connector architectural style.


===== Similarities

* Components are Abstractions.

* Reusable software artefacts.

* Connection ports for I/O.

* Composability

* Both instantiate components, specialize them by configuration, and compose them together to make a specific system.

* ALA's 3rd layer has interfaces used to wire abstractions in the 2nd layer, so at a lower level (more abstract) level. They represent something more like programming paradigms. The equivalent pattern in components engineering is "Abstract Interactions".  

* The architecture itself is composed of a generic part and a specific part. The general part is the ALA reference architecture itself and the components or the connectors architectural style. The specific part is the wiring diagram of the full system.

===== Differences

* Component based engineering technologies such as CORBA primarily solve for platform and language interoperability in distributed system whereas ALA brings some of the resulting concepts and properties to everyday small-scale, non distributed development as well, where the only separation is logical.

* In ALA there is perhaps more particular emphasis on making components clearly more abstract than the systems they are used in, and making the interfaces clearly more abstract than the components. The components are pushed down a layer and the interfaces down to a layer below that. Then all dependencies must be strictly downwards in these layers. In component based engineering, this structure is not necessarily enforced. If the components are just a decomposition of the system, then the system, components and interfaces may all be at the same level of abstraction, making the system as a whole complex.

* ALA depends on the 'abstractness property' of components to get logical separation, and so calls them 'Abstractions' and not components to help them retain that property. Even if there will only be one use and one instance, it is still called an abstraction. This keeps them zero coupled and not collaborating with other abstractions they will be wired to.

* ALA layers are knowledge dependency layers.  Components may still be arranged in layers according to run-time dependencies, such as communication stacks. In ALA run-time dependencies are always implemented as explicit wiring inside another higher layer component.

* ALA's top layer must be a straight representation of the requirements, whereas components may tend to be decomposed pieces of the system.

* ALA's 2nd layer of components are designed for expressiveness of user stories or requirements, and provide DSL-like properties. ALA puts emphasis on the 2nd layer of components having the scope of a domain as the means of explicitly controlling the expressiveness of the pallet of components.

* ALA is not fractal. In ALA the components of components are abstractions that become more abstract and thus ubiquitous and reusable. ALA therefore uses abstraction layers rather than hierarchies.

* ALA forces decisions about which abstraction layers the software artefacts go into, and then controls knowledge (semantic) dependencies accordingly.

* ALA tries to make the abstraction layers discrete and separated by a good margin. 

* ALA puts greater emphasis on wiring being able to represent any programming paradigm that suits the expression of requirements, and the use of many different paradigms in the same wiring diagram.

* ALA emphasises the cohesion of functional parts of a system such as UI, logic and Data, by bringing them all together in one small diagram using domain level components

* Instead of 'required' interfaces, in ALA they are called 'accepts' interfaces. This is because the abstractions are more abstract and composable, so, as with Lego blocks, there isn't necessarily a connection to another instance.

==== Domain Driven Design

Domain Driven Design's "Bounded Contexts" and ALA's Domain Abstractions layer have the same goal, that of encapsulation of the domain specific knowledge.

Domain driven design appears to concentrate on common languages to allow  pairs of elements to communicate, which ALA explicitly avoids. ALA tries to abstract the languages so that they are more abstract and fundamental than the domain, and more like programming paradigms.

// TBD Discuss with a DDD expert the comparison between ALA and DDD.

=== Microservices

TBD


=== Hexagonal Architecture (Ports and Adapters)

ALA includes the basic idea of hexagonal architecture, but with modification using the Bridge Pattern to keep cohesive knowledge belonging to the application from being split. This was explained in an earlier section of this article. <<ComparisonHexagonal>>

=== Architecture evaluation methods

Methods such as ATAM tell us how to evaluate an architecture for quality attributes such as maintainability, for instance by giving it modification scenarios to test how difficult the modifications would be to implement. There are several scenarios based methods to do this such as ATAM. Using this we could, theoretically, iteratively search over the entire architecture design space to find a satisfactory solution. It's a bit analogous to numerically solving for the maxima of a complex algebraic formula. In contrast, ALA is analogous to an 'algebraic solution'. If the desired quality attributes, and all the software engineering topics listed above are the equations, ALA is the algebraic solution. It simplifies them down into a parameterised template architecture, ready for you to go ahead and express your requirements.


anchor:Monads[]

=== Monads

We have talked about monads a few times because they are an important example of composition of instances of abstractions. Also, like ALA, they use the concept of separating (in time) composition from execution. You can bind monads together, and it builds a structure that you can then execute. ALA is a generalisation of monads. In the same way, you can wire instances of domain abstractions together, and it builds a structure that you can later execute. In this respect they are similar. 

When you execute a monad structure (generally by calling a function on the last monad you binded), it (usually) terminates with its value (or values). It is only executes again if it is wired up again. An exception is when using hot observables, such as an IO monad. The monad structure stay in existence, and it executes whenever there is input or output. ALA is more similar to this second case. When you start execution of a wired ALA structure, it (usually) starts running continuously.

Each monad binding is restricted to a data-flow of a single type, and in a fixed direction. Each ALA wiring is arbitrary in its meaning, according to whatever is most useful to describe requirements. A single wired connection can carry data as needed in both, or the composition may be about something other than data-flow.  

Often when monads are used, the execution is done immediately following the binding. So the deferred nature of the execution is not always obvious.  I found that the separation between composition and execution of monads to be an important aspect to understand when comparing with ALA composition. In ALA all composition takes place at initialization time. There is a very clear separation between that and run-time. 

This much separation is not so common with monads. Monads use the separation primarily as a way to do composition with pure functions, and have all the dirty work contained and abstracted away in well tested reusable classes. 

Where you might compose (bind) IObservable or Task monads for almost immediate execution following, in ALA you would tend to compose (wire up) data streams or event sources at initialization time that can then execute many-times thereafter. 

Another difference is syntax. Monads are composed using a dot operator, a method call, and configured with lambda function passed to the method:

 source.Filter(x=>x>=0).Select(x=>sqrt(x))


This code filters out values from the source that are negative and then calculates the squareroots. In ALA, because composition is generalised, the syntax would look like this:

 source.WireIn(new Filter(x=>x>=0)).WireIn(new Select(x=>sqrt(x))

But usually this code is generated from a diagram.

In functional programming, the binding code that builds the structure is pure functions. When you ask the structure to 'execute' all the dirty code is contained inside these reusable abstractions called Monads. The code that constrauts a particular application is clean and free of side effects. ALA makes use of this same property of reuable abstractions, and its wiring code is pure functional. 

 
==== Understanding monads


Monads are notoriously hard to learn, but they are nice simple insight once you get there. Monads actually seem to have this property that you cannot understand any explanation of them until you first understand them. Thus it is a bootstrapping problem. Here is my experience of going through that bootstrapping process in case it is useful. I am not going to try to explain monads myself, because, even it was possible, others would do that far better than I would. 

. First understand that Monads are like physics. Physicists explain that you never really understand physics, you just get used it. Unless you are a mathematician or otherwise gifted, the same is true for monads. 

. The way to get used to new concepts is to read multiple web-sites on the topic. Read each one until you get lost then swap to another one. Keep going like this. For average concepts like design patterns I use this technique and it requires maybe five websites. For monads it took me maybe ten. You will need to return to some of them iteratively to get further each time.

. If you don't know Haskell, prefer the web sites that explain them in the language you already know.

. The common essential ideas in those websites will start to embed themselves in your brain.

. Eventually, and fairly suddenly, the simple insight that is monads will happen.

I thought few of the web-sites that I used adequately emphasised the monad property of separation (in time) of composition and execution. They did use examples of it such as IEnumerable and Task. They represent what they can do in the future, without actually doing it now. That's why the binding functions are called bind in the functional world, because it doesn't (necessarily) do anything except build a structure that can later be executed to actually do the work. 


=== Reactive Extensions

In ALA, when you wire together 




=== WPF's XAML

TBD

=== Functional programming

TBD

=== Functional programming with monads

TBD

=== Functional Reactive Programming

TBD

=== Multi-tier Architecture

TBD

=== Onion Architecture

TBD

=== Clean Architecture

TBD



== Chapter eight - Surrounding Topics

=== Recursive abstractions

ALA enforces a strictly layered (non-circular) knowledge dependency structure. It encourages a small number of  abstraction layers at discrete well separated levels of ubiquity as a framework for the knowledge dependencies. This would appear to exclude the possibility of the powerful abstraction composition technique of recursion, where the meaning of an abstraction is defined in terms of itself. (Or an abstraction implementation may need knowledge of another abstraction, which in its turn has an implementation that needs knowledge of the first abstraction. This appears to require circular knowledge dependencies.

Circular knowledge dependencies happen all the time in functional programming where recursion replaces iteration. This is generally when a function needs to call itself or a class needs to use 'new' on itself. For example, a recursive descent compiler will have a function, 'statement', which will implement specific statements such as 'compound statement', 'if statement' and so on, and in those there will be a recursive call to the function, 'statement'. The following Syntax diagram represents part of the implementation of function 'statement'.

[plantuml,file="diagram-24.png",title=Syntax Diagram showing implementation of statement using recursion]
--
@startdot

digraph foo {
node [fontname="Arial"]
// nodesep = 10
graph [rankdir=LR]
node [group=main]
Statement1 OpenBrace 
node [group=""]

OpenBrace [label="{"]
CloseBrace [label="}"]
OpenBracket [label="("]
CloseBracket [label=")"]
Semi [label=";"]
End1 [style=invis]
End2 [style=invis]
Statement1 [label=statement]
Statement2 [label=statement]
Statement3 [label=statement]

Statement1 -> OpenBrace -> Statement2 -> CloseBrace
Statement2:e -> Semi:e
Semi:w -> Statement2:w
CloseBrace -> End1 
{rank=same Statement2 Semi}

edge [len=0.1]
Statement1 -> if -> OpenBracket -> expression -> CloseBracket -> Statement3 -> End2
}
@enddot
--

In ALA, we want to preserve the idea of clear layers defining what knowledge is needed to understand what. Resolving this dilemma could get a bit philosophical. Since abstractions are the first class artefacts of the human brain, it may be best to think about how the brain does it. The brain must actually have two abstractions with the same name but at different levels. The first is analogous to a 'forward declaration' in a language to allow a compiler to know about something that will be referred to in a more abstract way before it finds out about it in a more specific way.

By this analogy, ALA sometimes requires the concept of a forward-declared-abstraction, something that is clearly more abstract than the concrete implementations. Therefore, we can put this forward declaration in the next layer down, just as we would a paradigm interface. In the recursive descent compiler example, we would first have the abstract concept of a statement, meaning a unit of executable code as an interface in a lower layer. Then the specific abstractions, compound statement, if statement and so on are in a higher layer. They both provide and accept the interface.

Another language example is that an expression is composed of terms, a term is composed of factors, and a factor can be composed of expressions (enclosed in round brackets). If we model these compositions as direct knowledge dependencies, we would have too many layers - and they would not be becoming more abstract as we go down. The existence of the recursion at the end reinforces that. It seems that all three, expressions, terms and factors, should have abstract interface versions at a lower level.

Not all cases of recursion would require these interfaces. If, for example, in your old way of doing things there is a long chain of function calls, with the last one calling the first one, all of them are probably run-time dependencies, not knowledge dependencies at all. So in ALA, they should all be changed to be wirable, and wired together by an abstraction in a higher layer. The paradigm interface that is used to allow them to be wired  may be,for example, data-flow. So recursion does not necessarily require different interfaces for each different abstraction involved in the circular dependency.

////
With that in mind, we return to expression - term - factor - expression example and ask ourselves if there are really knowledge dependencies involved at all. Do we think have to know about terms to understand what an expression is? The answer is probably no. Besides, adding terms is only one way of making an expression. What if we think of expressions, terms and factors as language elements that are wirable using a paradigm interface called 'can consists of'. That's probably more like how our brains think of it. We could even draw a diagram of the language using 'can consiste of' relationships between elements. The result is an Abstract Sytax tree instead of the Sytax diagram above.
////

=== Abstraction of Port I/O properties

This is an advanced topic that allows abstractions to be written without knowing details of the implementation of the communications. The idea is for the language to support logical or abstracted I/O ports that work for any type of technical communication properties such as described in the sections below. If we allow these properties to be binded late, say at compile-time, they can be changed independently of the domain abstractions. This allows tuning of performance or physical deployment of the abstractions to different processes or hardware. 

I have been looking into how this could be accomplished using a conventional language, but it seems quite hard.

==== Push or Pull

Say an abstraction has a single logical input that can be wired to and a single logical output that can be wired from. Both the input and the output could be used in either a push or a pull manner.

For the input, push means we will be called with the data.  Pull means we will call out to get the data.

For the output, push means we will call out with the data, and pull means that something will call us to get the data.

There are four combinations possible:

* push push : push through
* pull pull : pull through
* push pull : internally buffer the input or output
* pull push : active object

Let's imagine we have a function that processes the data inside the abstraction.

The four combinations would require the function to run as a result of a function call from the input, or a function call from the output. The function result may be put into an internal buffered or be pushed out. The function may need to receive its input from an input buffer or by pulling. The function may need to run via a 3rd input that is polled or called by a timer.

We could conceivably write an abstract I/O class with an output interface and an input interface and a configuration interface that allows it to be configured late on how to do the I/O. This abstract I/O object would call the function to do the work at the right time according to its configuration.

==== Synchronous or Asynchronous

==== Buffered or unbuffered

==== Shared memory or messaging

==== Exposed state plus notification

==== Synchronous Request/Response


=== Working with legacy code

In old (non-ALA) legacy code, abstractions, if they ever existed, have usually been destroyed by coupling. If there is no model left by the original designer, or it is out of date, I first create one. I usually have to 'reverse engineer' the model by doing many 'all files searches' and trying to build a mental picture of how everything fits together. It can quickly become mentally taxing if the user story is non-trivial. So I build a UML class diagram from the searches (their one useful application) as the background (using light lines), and a tree of method calls for the specific user story on top of it (using heavier lines). These diagrams can end up looking pretty horrific, because the knowledge of the user-story has become so scattered, especially when inheritance is involved. The tree of method calls will come into the base class but leave from a subclass method.

This process can take several hours to a day for a single user story.
Once the code for the single user story is understood, some acceptance tests are put in place for it, by putting in insertion points as close as practical to the inputs and outputs for the user story. 

The next step is to factor out the method call tree for the user story into a new abstraction. This typically contains a sequence of new abstract activities or data transformations. These new abstractions are pitched at the domain level. Sometimes, if in C#, I will use Reactive Extensions. The user story may become a single RX sequence. The abstractions are then implemented, with tests, by copying and pasting useful code snippets from the original classes into the new abstractions. The old classes are marked for deprecation. 

Conversion of user stories takes place iteratively.  



=== Writing tests architected in ALA

TBD

=== Debugging ALA programs

Because in ALA you can get multiple instances of the same class used in multiple places, and multiple implementations of the same interface used in different places, debugging is easier if the instances are able to identify themselves. For this reason I tend to have a local property in every class called Name. The property is immutable and set by the constructor.

=== ALA language features

One of my first hobby programming projects was a compiler for a C-like high level language for embedded systems. At the time I had lots of energy to write the compiler and optimize the object code (written in itself, the performance of both compiling and of object code execution beat the first C compilers to later appear by around a factor of ten) but I lacked a lifetime of experience to design a language. Forty years later, I feel as if it's partially the other way around, at least for language feature that would support good architecture. The language I should have implemented way back then should have been an ALA language - one that supported ALA architecture by having the needed constraints.

It would have had Abstractions and Instances as first class elements. The name Abstraction is to reinforce the obvious use of the only type of element that the brain uses at design-time for any kind of separation of concerns.

It would support a single type of relationship - a knowledge dependency. You would have to define your four layers, and keep them in separate folders so you would be forced to decide at what abstraction level any given piece of design-time knowledge would go. Of course, it would only allow knowledge dependency relationships from one layer to a lower layer. If you wanted to add an extra layer to the chain of dependencies, that would be a bad design decision. For example, if your application is getting too large, you could create a layer between it and the domain abstractions layer called 'plug-ins'. 

Instances would work like components in that they would have ports for I/O. Like interfaces, ports are defined in a lower layer. The only way of instantiating abstractions and connecting them together is inside an abstraction in a higher layer.

Abstractions would support multiple ports of the same interface. Current languages have the difficulty that you can only implement one interface of a given type, which we had to workaround by having connector objects.

Ports would support late configuration of all communication properties such as push, pull, asynchronous, synchronous (explained above) without changing the Abstraction. 

Such a language would overcome many of the problems of current languages that encourage non-ALA compliant practices. But the invention of good abstractions in the first sprint of any green-field project would still be a skilled phase requiring an innate ability to abstract.

////
TBD: Direct representation of diagrams as text. Can use symbolic references (that represent what would be lines on the equavalent diagram) within a  local scope only. The target of such symbolic references are not abstractions and therefore do not need to be moved to a lower layer. Typically there will be at most 2 or 3 connections to the element. e.g. local variables, a local struct definition, or a local function that you would ideally liked to have been anonymous. In fact in the equivalent diagram, these elements would be anonymous.
////



= Feedback

Any feedback about this article is welcomed. Please send to johnspray274<at>gmail<dot>com

